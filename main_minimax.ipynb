{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T20:21:37.188521Z",
     "start_time": "2023-11-07T20:21:28.626293Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lpott\\anaconda3\\envs\\survival\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\lpott\\anaconda3\\envs\\survival\\lib\\site-packages\\torch\\utils\\cpp_extension.py:23: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import packaging  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "from src.models import Exponential_Model\n",
    "from src.criterion import RightCensorWrapper,RankingWrapper,RHC_Ranking_Wrapper\n",
    "from src.load_data import load_datasets,load_dataframe\n",
    "from src.utils import train_robust,lower_bound\n",
    "from src.visualizations import *\n",
    "from src.metrics import concordance\n",
    "\n",
    "from torch.optim import Adam\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from lifelines import KaplanMeierFitter,CoxPHFitter,ExponentialFitter\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "from auto_LiRPA import BoundedModule, BoundedTensor\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import random\n",
    "# set seeds for random!!!\n",
    "torch.manual_seed(123)\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "torch.cuda.manual_seed_all(123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARGS(object):\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_wrapper(loss_wrapper):\n",
    "    if loss_wrapper == \"rank\":\n",
    "        return RankingWrapper\n",
    "    elif loss_wrapper == \"rhc\":\n",
    "        return RightCensorWrapper\n",
    "    elif loss_wrapper == \"rhc_rank\":\n",
    "        return RHC_Ranking_Wrapper\n",
    "    else:\n",
    "        raise Exception(\"not valid wrapper choice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ARGS()\n",
    "args.verify=False\n",
    "args.device=\"cpu\"\n",
    "\n",
    "args.seed = 123\n",
    "\n",
    "args.eps=0.5\n",
    "args.norm=np.inf\n",
    "args.bound_type = \"CROWN-IBP\"\n",
    "args.num_epochs=150\n",
    "args.lr = 5e-3\n",
    "args.batch_size= 128\n",
    "args.scheduler_name = \"SmoothedScheduler\"\n",
    "args.scheduler_opts = \"start=100,length=10\"\n",
    "args.hidden_dims = [50,50]\n",
    "args.pareto = [1.0,0.0]\n",
    "args.save_model = \"\"\n",
    "args.dataset = \"nwtco\"\n",
    "args.loss_wrapper=\"rhc_rank\"\n",
    "args.weight = 1 / args.batch_size\n",
    "args.sigma = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T20:21:37.272860Z",
     "start_time": "2023-11-07T20:21:37.188521Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# GOOD DATASETS\n",
    "# 1. TRACE\n",
    "# 2. divorce \n",
    "# 3. Dialysis\n",
    "# 3. Aids2\n",
    "# 4. Framingham\n",
    "# 5. rott2\n",
    "# 6. dataDIVAT1\n",
    "# 7. prostate\n",
    "# 8. support2\n",
    "dataset_train,dataset_test = load_datasets(args.dataset,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T20:21:37.295094Z",
     "start_time": "2023-11-07T20:21:37.272860Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "input_dims = dataset_train.tensors[0].shape[1]\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T20:21:37.321189Z",
     "start_time": "2023-11-07T20:21:37.297057Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3222, 14])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader_train = DataLoader(dataset_train,batch_size=args.batch_size,shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test,batch_size=args.batch_size,shuffle=False)\n",
    "\n",
    "dataloader_train.mean = dataloader_test.mean = dataset_train.mean\n",
    "dataloader_train.std = dataloader_test.std = dataset_train.std\n",
    "\n",
    "\n",
    "dataset_train.tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance with random weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1, 0.8, 0.7, 0.6, 0.5, 0.1, 0.07, 0.05, 0],\n",
       " array([0.29603413, 0.30422236, 0.31445765, 0.31651704, 0.32087012,\n",
       "        0.33439797, 0.33878804, 0.33970059, 0.33894835]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_robust = Exponential_Model(input_dim=input_dims,hidden_layers=args.hidden_dims)\n",
    "clf_fragile = Exponential_Model(input_dim=input_dims,hidden_layers=args.hidden_dims)\n",
    "clf_fragile.load_state_dict(deepcopy(clf_robust.state_dict()))\n",
    "\n",
    "epsilons = [1,.8,0.7,.6,0.5,0.1,0.07,0.05,0]\n",
    "print(\"Concordance with random weights\")\n",
    "concordance(clf_robust,dataloader_test,epsilons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = loss_wrapper(args.loss_wrapper)\n",
    "\n",
    "# # model = BoundedModule(clf, X_train)\n",
    "model_robust_wrap = BoundedModule(wrapper(clf_robust,weight=args.weight,sigma=args.sigma),dataloader_train.dataset.tensors)\n",
    "model_fragile_wrap = BoundedModule(wrapper(clf_fragile,weight=args.weight,sigma=args.sigma),dataloader_train.dataset.tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lpott\\anaconda3\\envs\\survival\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:371: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, learning rate [0.005]\n",
      "[ 1:   0]: eps=0.00000000 Loss=304177.4688 Time=0.0456\n",
      "[ 1:  10]: eps=0.00000000 Loss=145473.3310 Time=0.0111\n",
      "[ 1:  20]: eps=0.00000000 Loss=80142.1634 Time=0.0092\n",
      "[ 1:  25]: eps=0.00000000 Loss=66956.7883 Time=0.0087\n",
      "Epoch time: 0.2485, Total time: 0.2485\n",
      "Evaluating...\n",
      "[ 1:   6]: eps=0.00000000 Loss=321.6735 Time=0.0043\n",
      "Epoch 2, learning rate [0.005]\n",
      "[ 2:   0]: eps=0.00000000 Loss=287.2186 Time=0.0080\n",
      "[ 2:  10]: eps=0.00000000 Loss=253.7153 Time=0.0104\n",
      "[ 2:  20]: eps=0.00000000 Loss=233.9752 Time=0.0090\n",
      "[ 2:  25]: eps=0.00000000 Loss=232.0259 Time=0.0092\n",
      "Epoch time: 0.2678, Total time: 0.5163\n",
      "Evaluating...\n",
      "[ 2:   6]: eps=0.00000000 Loss=208.4452 Time=0.0057\n",
      "Epoch 3, learning rate [0.005]\n",
      "[ 3:   0]: eps=0.00000000 Loss=153.8224 Time=0.0099\n",
      "[ 3:  10]: eps=0.00000000 Loss=229.3283 Time=0.0081\n",
      "[ 3:  20]: eps=0.00000000 Loss=222.5834 Time=0.0084\n",
      "[ 3:  25]: eps=0.00000000 Loss=218.8052 Time=0.0079\n",
      "Epoch time: 0.2228, Total time: 0.7391\n",
      "Evaluating...\n",
      "[ 3:   6]: eps=0.00000000 Loss=208.0073 Time=0.0045\n",
      "Epoch 4, learning rate [0.005]\n",
      "[ 4:   0]: eps=0.00000000 Loss=228.0971 Time=0.0089\n",
      "[ 4:  10]: eps=0.00000000 Loss=227.2719 Time=0.0082\n",
      "[ 4:  20]: eps=0.00000000 Loss=223.3393 Time=0.0078\n",
      "[ 4:  25]: eps=0.00000000 Loss=216.2512 Time=0.0075\n",
      "Epoch time: 0.2118, Total time: 0.9509\n",
      "Evaluating...\n",
      "[ 4:   6]: eps=0.00000000 Loss=206.2152 Time=0.0043\n",
      "Epoch 5, learning rate [0.005]\n",
      "[ 5:   0]: eps=0.00000000 Loss=220.3362 Time=0.0090\n",
      "[ 5:  10]: eps=0.00000000 Loss=233.4678 Time=0.0079\n",
      "[ 5:  20]: eps=0.00000000 Loss=221.6677 Time=0.0093\n",
      "[ 5:  25]: eps=0.00000000 Loss=215.9041 Time=0.0090\n",
      "Epoch time: 0.2581, Total time: 1.2090\n",
      "Evaluating...\n",
      "[ 5:   6]: eps=0.00000000 Loss=204.4034 Time=0.0047\n",
      "Epoch 6, learning rate [0.005]\n",
      "[ 6:   0]: eps=0.00000000 Loss=179.0457 Time=0.0100\n",
      "[ 6:  10]: eps=0.00000000 Loss=227.2233 Time=0.0091\n",
      "[ 6:  20]: eps=0.00000000 Loss=219.8678 Time=0.0097\n",
      "[ 6:  25]: eps=0.00000000 Loss=214.8955 Time=0.0093\n",
      "Epoch time: 0.2690, Total time: 1.4781\n",
      "Evaluating...\n",
      "[ 6:   6]: eps=0.00000000 Loss=202.6716 Time=0.0038\n",
      "Epoch 7, learning rate [0.005]\n",
      "[ 7:   0]: eps=0.00000000 Loss=156.4897 Time=0.0079\n",
      "[ 7:  10]: eps=0.00000000 Loss=202.0227 Time=0.0075\n",
      "[ 7:  20]: eps=0.00000000 Loss=210.0779 Time=0.0083\n",
      "[ 7:  25]: eps=0.00000000 Loss=213.5018 Time=0.0086\n",
      "Epoch time: 0.2500, Total time: 1.7280\n",
      "Evaluating...\n",
      "[ 7:   6]: eps=0.00000000 Loss=201.1802 Time=0.0054\n",
      "Epoch 8, learning rate [0.005]\n",
      "[ 8:   0]: eps=0.00000000 Loss=189.6423 Time=0.0110\n",
      "[ 8:  10]: eps=0.00000000 Loss=212.3760 Time=0.0076\n",
      "[ 8:  20]: eps=0.00000000 Loss=211.1926 Time=0.0075\n",
      "[ 8:  25]: eps=0.00000000 Loss=212.1622 Time=0.0072\n",
      "Epoch time: 0.2019, Total time: 1.9300\n",
      "Evaluating...\n",
      "[ 8:   6]: eps=0.00000000 Loss=199.9750 Time=0.0044\n",
      "Epoch 9, learning rate [0.005]\n",
      "[ 9:   0]: eps=0.00000000 Loss=246.6397 Time=0.0116\n",
      "[ 9:  10]: eps=0.00000000 Loss=197.6040 Time=0.0078\n",
      "[ 9:  20]: eps=0.00000000 Loss=212.4363 Time=0.0085\n",
      "[ 9:  25]: eps=0.00000000 Loss=212.0938 Time=0.0081\n",
      "Epoch time: 0.2332, Total time: 2.1632\n",
      "Evaluating...\n",
      "[ 9:   6]: eps=0.00000000 Loss=198.7930 Time=0.0041\n",
      "Epoch 10, learning rate [0.005]\n",
      "[10:   0]: eps=0.00000000 Loss=217.1848 Time=0.0089\n",
      "[10:  10]: eps=0.00000000 Loss=219.3895 Time=0.0077\n",
      "[10:  20]: eps=0.00000000 Loss=213.7606 Time=0.0076\n",
      "[10:  25]: eps=0.00000000 Loss=209.1728 Time=0.0075\n",
      "Epoch time: 0.2150, Total time: 2.3782\n",
      "Evaluating...\n",
      "[10:   6]: eps=0.00000000 Loss=197.8981 Time=0.0039\n",
      "Epoch 11, learning rate [0.005]\n",
      "[11:   0]: eps=0.00000000 Loss=167.5222 Time=0.0090\n",
      "[11:  10]: eps=0.00000000 Loss=205.7761 Time=0.0076\n",
      "[11:  20]: eps=0.00000000 Loss=209.9079 Time=0.0078\n",
      "[11:  25]: eps=0.00000000 Loss=208.6739 Time=0.0076\n",
      "Epoch time: 0.2162, Total time: 2.5944\n",
      "Evaluating...\n",
      "[11:   6]: eps=0.00000000 Loss=197.2501 Time=0.0049\n",
      "Epoch 12, learning rate [0.005]\n",
      "[12:   0]: eps=0.00000000 Loss=255.8123 Time=0.0100\n",
      "[12:  10]: eps=0.00000000 Loss=215.7356 Time=0.0081\n",
      "[12:  20]: eps=0.00000000 Loss=217.1154 Time=0.0078\n",
      "[12:  25]: eps=0.00000000 Loss=208.7612 Time=0.0079\n",
      "Epoch time: 0.2278, Total time: 2.8222\n",
      "Evaluating...\n",
      "[12:   6]: eps=0.00000000 Loss=196.5970 Time=0.0060\n",
      "Epoch 13, learning rate [0.005]\n",
      "[13:   0]: eps=0.00000000 Loss=176.9258 Time=0.0100\n",
      "[13:  10]: eps=0.00000000 Loss=202.1194 Time=0.0080\n",
      "[13:  20]: eps=0.00000000 Loss=213.3840 Time=0.0078\n",
      "[13:  25]: eps=0.00000000 Loss=207.7736 Time=0.0074\n",
      "Epoch time: 0.2079, Total time: 3.0301\n",
      "Evaluating...\n",
      "[13:   6]: eps=0.00000000 Loss=196.1942 Time=0.0043\n",
      "Epoch 14, learning rate [0.005]\n",
      "[14:   0]: eps=0.00000000 Loss=226.8786 Time=0.0090\n",
      "[14:  10]: eps=0.00000000 Loss=205.7978 Time=0.0080\n",
      "[14:  20]: eps=0.00000000 Loss=205.8665 Time=0.0076\n",
      "[14:  25]: eps=0.00000000 Loss=206.7564 Time=0.0075\n",
      "Epoch time: 0.2180, Total time: 3.2481\n",
      "Evaluating...\n",
      "[14:   6]: eps=0.00000000 Loss=195.7674 Time=0.0047\n",
      "Epoch 15, learning rate [0.005]\n",
      "[15:   0]: eps=0.00000000 Loss=200.6353 Time=0.0094\n",
      "[15:  10]: eps=0.00000000 Loss=203.8945 Time=0.0083\n",
      "[15:  20]: eps=0.00000000 Loss=209.0309 Time=0.0087\n",
      "[15:  25]: eps=0.00000000 Loss=206.4489 Time=0.0084\n",
      "Epoch time: 0.2428, Total time: 3.4909\n",
      "Evaluating...\n",
      "[15:   6]: eps=0.00000000 Loss=195.3767 Time=0.0051\n",
      "Epoch 16, learning rate [0.005]\n",
      "[16:   0]: eps=0.00000000 Loss=224.3549 Time=0.0076\n",
      "[16:  10]: eps=0.00000000 Loss=208.2368 Time=0.0076\n",
      "[16:  20]: eps=0.00000000 Loss=206.8654 Time=0.0080\n",
      "[16:  25]: eps=0.00000000 Loss=206.3916 Time=0.0078\n",
      "Epoch time: 0.2222, Total time: 3.7132\n",
      "Evaluating...\n",
      "[16:   6]: eps=0.00000000 Loss=195.0785 Time=0.0047\n",
      "Epoch 17, learning rate [0.005]\n",
      "[17:   0]: eps=0.00000000 Loss=221.9164 Time=0.0100\n",
      "[17:  10]: eps=0.00000000 Loss=205.8185 Time=0.0082\n",
      "[17:  20]: eps=0.00000000 Loss=206.4244 Time=0.0076\n",
      "[17:  25]: eps=0.00000000 Loss=206.1846 Time=0.0074\n",
      "Epoch time: 0.2108, Total time: 3.9239\n",
      "Evaluating...\n",
      "[17:   6]: eps=0.00000000 Loss=194.7674 Time=0.0049\n",
      "Epoch 18, learning rate [0.005]\n",
      "[18:   0]: eps=0.00000000 Loss=135.9553 Time=0.0101\n",
      "[18:  10]: eps=0.00000000 Loss=214.2381 Time=0.0089\n",
      "[18:  20]: eps=0.00000000 Loss=208.8668 Time=0.0084\n",
      "[18:  25]: eps=0.00000000 Loss=204.9694 Time=0.0080\n",
      "Epoch time: 0.2242, Total time: 4.1481\n",
      "Evaluating...\n",
      "[18:   6]: eps=0.00000000 Loss=194.3761 Time=0.0043\n",
      "Epoch 19, learning rate [0.005]\n",
      "[19:   0]: eps=0.00000000 Loss=333.9011 Time=0.0070\n",
      "[19:  10]: eps=0.00000000 Loss=214.1955 Time=0.0072\n",
      "[19:  20]: eps=0.00000000 Loss=211.9797 Time=0.0077\n",
      "[19:  25]: eps=0.00000000 Loss=204.1650 Time=0.0074\n",
      "Epoch time: 0.2074, Total time: 4.3555\n",
      "Evaluating...\n",
      "[19:   6]: eps=0.00000000 Loss=194.2822 Time=0.0048\n",
      "Epoch 20, learning rate [0.005]\n",
      "[20:   0]: eps=0.00000000 Loss=146.5313 Time=0.0073\n",
      "[20:  10]: eps=0.00000000 Loss=194.0194 Time=0.0075\n",
      "[20:  20]: eps=0.00000000 Loss=207.4907 Time=0.0091\n",
      "[20:  25]: eps=0.00000000 Loss=204.4656 Time=0.0091\n",
      "Epoch time: 0.2582, Total time: 4.6137\n",
      "Evaluating...\n",
      "[20:   6]: eps=0.00000000 Loss=194.1001 Time=0.0056\n",
      "Epoch 21, learning rate [0.005]\n",
      "[21:   0]: eps=0.00000000 Loss=170.0672 Time=0.0089\n",
      "[21:  10]: eps=0.00000000 Loss=179.1042 Time=0.0085\n",
      "[21:  20]: eps=0.00000000 Loss=194.4327 Time=0.0080\n",
      "[21:  25]: eps=0.00000000 Loss=202.8475 Time=0.0078\n",
      "Epoch time: 0.2258, Total time: 4.8395\n",
      "Evaluating...\n",
      "[21:   6]: eps=0.00000000 Loss=193.9610 Time=0.0045\n",
      "Epoch 22, learning rate [0.005]\n",
      "[22:   0]: eps=0.00000000 Loss=194.9812 Time=0.0101\n",
      "[22:  10]: eps=0.00000000 Loss=188.7331 Time=0.0078\n",
      "[22:  20]: eps=0.00000000 Loss=202.2927 Time=0.0074\n",
      "[22:  25]: eps=0.00000000 Loss=203.7102 Time=0.0071\n",
      "Epoch time: 0.1998, Total time: 5.0393\n",
      "Evaluating...\n",
      "[22:   6]: eps=0.00000000 Loss=193.6276 Time=0.0048\n",
      "Epoch 23, learning rate [0.005]\n",
      "[23:   0]: eps=0.00000000 Loss=178.1960 Time=0.0090\n",
      "[23:  10]: eps=0.00000000 Loss=203.4777 Time=0.0076\n",
      "[23:  20]: eps=0.00000000 Loss=204.8545 Time=0.0076\n",
      "[23:  25]: eps=0.00000000 Loss=203.1818 Time=0.0075\n",
      "Epoch time: 0.2808, Total time: 5.3201\n",
      "Evaluating...\n",
      "[23:   6]: eps=0.00000000 Loss=193.6895 Time=0.0041\n",
      "Epoch 24, learning rate [0.005]\n",
      "[24:   0]: eps=0.00000000 Loss=239.9218 Time=0.0090\n",
      "[24:  10]: eps=0.00000000 Loss=204.6936 Time=0.0073\n",
      "[24:  20]: eps=0.00000000 Loss=202.9481 Time=0.0074\n",
      "[24:  25]: eps=0.00000000 Loss=203.2796 Time=0.0074\n",
      "Epoch time: 0.2093, Total time: 5.5294\n",
      "Evaluating...\n",
      "[24:   6]: eps=0.00000000 Loss=193.4323 Time=0.0039\n",
      "Epoch 25, learning rate [0.005]\n",
      "[25:   0]: eps=0.00000000 Loss=234.7846 Time=0.0079\n",
      "[25:  10]: eps=0.00000000 Loss=192.9571 Time=0.0073\n",
      "[25:  20]: eps=0.00000000 Loss=198.5925 Time=0.0077\n",
      "[25:  25]: eps=0.00000000 Loss=201.7953 Time=0.0074\n",
      "Epoch time: 0.2091, Total time: 5.7385\n",
      "Evaluating...\n",
      "[25:   6]: eps=0.00000000 Loss=193.3723 Time=0.0042\n",
      "Epoch 26, learning rate [0.005]\n",
      "[26:   0]: eps=0.00000000 Loss=162.2325 Time=0.0070\n",
      "[26:  10]: eps=0.00000000 Loss=200.7464 Time=0.0076\n",
      "[26:  20]: eps=0.00000000 Loss=203.5653 Time=0.0073\n",
      "[26:  25]: eps=0.00000000 Loss=201.9604 Time=0.0070\n",
      "Epoch time: 0.2051, Total time: 5.9436\n",
      "Evaluating...\n",
      "[26:   6]: eps=0.00000000 Loss=193.4291 Time=0.0050\n",
      "Epoch 27, learning rate [0.005]\n",
      "[27:   0]: eps=0.00000000 Loss=196.2491 Time=0.0080\n",
      "[27:  10]: eps=0.00000000 Loss=208.6633 Time=0.0080\n",
      "[27:  20]: eps=0.00000000 Loss=207.2307 Time=0.0079\n",
      "[27:  25]: eps=0.00000000 Loss=201.8563 Time=0.0077\n",
      "Epoch time: 0.2210, Total time: 6.1646\n",
      "Evaluating...\n",
      "[27:   6]: eps=0.00000000 Loss=193.1063 Time=0.0044\n",
      "Epoch 28, learning rate [0.005]\n",
      "[28:   0]: eps=0.00000000 Loss=213.5605 Time=0.0080\n",
      "[28:  10]: eps=0.00000000 Loss=206.0770 Time=0.0069\n",
      "[28:  20]: eps=0.00000000 Loss=205.4000 Time=0.0074\n",
      "[28:  25]: eps=0.00000000 Loss=202.4269 Time=0.0077\n",
      "Epoch time: 0.2223, Total time: 6.3869\n",
      "Evaluating...\n",
      "[28:   6]: eps=0.00000000 Loss=193.2239 Time=0.0051\n",
      "Epoch 29, learning rate [0.005]\n",
      "[29:   0]: eps=0.00000000 Loss=115.4739 Time=0.0100\n",
      "[29:  10]: eps=0.00000000 Loss=198.4971 Time=0.0081\n",
      "[29:  20]: eps=0.00000000 Loss=200.1909 Time=0.0074\n",
      "[29:  25]: eps=0.00000000 Loss=201.5981 Time=0.0072\n",
      "Epoch time: 0.2069, Total time: 6.5938\n",
      "Evaluating...\n",
      "[29:   6]: eps=0.00000000 Loss=193.1471 Time=0.0042\n",
      "Epoch 30, learning rate [0.005]\n",
      "[30:   0]: eps=0.00000000 Loss=233.2256 Time=0.0090\n",
      "[30:  10]: eps=0.00000000 Loss=198.4303 Time=0.0072\n",
      "[30:  20]: eps=0.00000000 Loss=197.7688 Time=0.0070\n",
      "[30:  25]: eps=0.00000000 Loss=202.1309 Time=0.0068\n",
      "Epoch time: 0.1942, Total time: 6.7880\n",
      "Evaluating...\n",
      "[30:   6]: eps=0.00000000 Loss=192.9747 Time=0.0040\n",
      "Epoch 31, learning rate [0.005]\n",
      "[31:   0]: eps=0.00000000 Loss=153.1304 Time=0.0082\n",
      "[31:  10]: eps=0.00000000 Loss=206.9511 Time=0.0070\n",
      "[31:  20]: eps=0.00000000 Loss=204.7484 Time=0.0072\n",
      "[31:  25]: eps=0.00000000 Loss=202.6008 Time=0.0070\n",
      "Epoch time: 0.2019, Total time: 6.9899\n",
      "Evaluating...\n",
      "[31:   6]: eps=0.00000000 Loss=192.8611 Time=0.0053\n",
      "Epoch 32, learning rate [0.005]\n",
      "[32:   0]: eps=0.00000000 Loss=190.5451 Time=0.0091\n",
      "[32:  10]: eps=0.00000000 Loss=214.6956 Time=0.0078\n",
      "[32:  20]: eps=0.00000000 Loss=208.6574 Time=0.0075\n",
      "[32:  25]: eps=0.00000000 Loss=200.7533 Time=0.0073\n",
      "Epoch time: 0.2117, Total time: 7.2016\n",
      "Evaluating...\n",
      "[32:   6]: eps=0.00000000 Loss=192.9766 Time=0.0044\n",
      "Epoch 33, learning rate [0.005]\n",
      "[33:   0]: eps=0.00000000 Loss=276.1053 Time=0.0079\n",
      "[33:  10]: eps=0.00000000 Loss=216.5528 Time=0.0076\n",
      "[33:  20]: eps=0.00000000 Loss=207.0854 Time=0.0080\n",
      "[33:  25]: eps=0.00000000 Loss=202.0268 Time=0.0077\n",
      "Epoch time: 0.2207, Total time: 7.4223\n",
      "Evaluating...\n",
      "[33:   6]: eps=0.00000000 Loss=192.6910 Time=0.0041\n",
      "Epoch 34, learning rate [0.005]\n",
      "[34:   0]: eps=0.00000000 Loss=206.1204 Time=0.0083\n",
      "[34:  10]: eps=0.00000000 Loss=206.5540 Time=0.0078\n",
      "[34:  20]: eps=0.00000000 Loss=203.6023 Time=0.0078\n",
      "[34:  25]: eps=0.00000000 Loss=200.4682 Time=0.0075\n",
      "Epoch time: 0.2156, Total time: 7.6379\n",
      "Evaluating...\n",
      "[34:   6]: eps=0.00000000 Loss=192.7108 Time=0.0041\n",
      "Epoch 35, learning rate [0.005]\n",
      "[35:   0]: eps=0.00000000 Loss=179.6264 Time=0.0110\n",
      "[35:  10]: eps=0.00000000 Loss=215.4997 Time=0.0082\n",
      "[35:  20]: eps=0.00000000 Loss=204.7555 Time=0.0078\n",
      "[35:  25]: eps=0.00000000 Loss=200.4076 Time=0.0076\n",
      "Epoch time: 0.2063, Total time: 7.8442\n",
      "Evaluating...\n",
      "[35:   6]: eps=0.00000000 Loss=192.8086 Time=0.0046\n",
      "Epoch 36, learning rate [0.005]\n",
      "[36:   0]: eps=0.00000000 Loss=218.5102 Time=0.0091\n",
      "[36:  10]: eps=0.00000000 Loss=204.3448 Time=0.0078\n",
      "[36:  20]: eps=0.00000000 Loss=198.2149 Time=0.0075\n",
      "[36:  25]: eps=0.00000000 Loss=200.7048 Time=0.0075\n",
      "Epoch time: 0.2120, Total time: 8.0562\n",
      "Evaluating...\n",
      "[36:   6]: eps=0.00000000 Loss=192.6094 Time=0.0049\n",
      "Epoch 37, learning rate [0.005]\n",
      "[37:   0]: eps=0.00000000 Loss=128.4830 Time=0.0080\n",
      "[37:  10]: eps=0.00000000 Loss=208.2231 Time=0.0076\n",
      "[37:  20]: eps=0.00000000 Loss=202.3094 Time=0.0081\n",
      "[37:  25]: eps=0.00000000 Loss=201.0305 Time=0.0081\n",
      "Epoch time: 0.2322, Total time: 8.2884\n",
      "Evaluating...\n",
      "[37:   6]: eps=0.00000000 Loss=192.5762 Time=0.0048\n",
      "Epoch 38, learning rate [0.005]\n",
      "[38:   0]: eps=0.00000000 Loss=211.0947 Time=0.0080\n",
      "[38:  10]: eps=0.00000000 Loss=216.9029 Time=0.0075\n",
      "[38:  20]: eps=0.00000000 Loss=203.2802 Time=0.0074\n",
      "[38:  25]: eps=0.00000000 Loss=201.4132 Time=0.0071\n",
      "Epoch time: 0.2038, Total time: 8.4922\n",
      "Evaluating...\n",
      "[38:   6]: eps=0.00000000 Loss=192.5909 Time=0.0042\n",
      "Epoch 39, learning rate [0.005]\n",
      "[39:   0]: eps=0.00000000 Loss=137.5979 Time=0.0080\n",
      "[39:  10]: eps=0.00000000 Loss=191.8056 Time=0.0072\n",
      "[39:  20]: eps=0.00000000 Loss=200.6133 Time=0.0078\n",
      "[39:  25]: eps=0.00000000 Loss=200.5893 Time=0.0078\n",
      "Epoch time: 0.2287, Total time: 8.7209\n",
      "Evaluating...\n",
      "[39:   6]: eps=0.00000000 Loss=192.5666 Time=0.0041\n",
      "Epoch 40, learning rate [0.005]\n",
      "[40:   0]: eps=0.00000000 Loss=151.2317 Time=0.0080\n",
      "[40:  10]: eps=0.00000000 Loss=194.1507 Time=0.0074\n",
      "[40:  20]: eps=0.00000000 Loss=199.7649 Time=0.0071\n",
      "[40:  25]: eps=0.00000000 Loss=200.5105 Time=0.0069\n",
      "Epoch time: 0.1958, Total time: 8.9167\n",
      "Evaluating...\n",
      "[40:   6]: eps=0.00000000 Loss=192.2226 Time=0.0049\n",
      "Epoch 41, learning rate [0.005]\n",
      "[41:   0]: eps=0.00000000 Loss=181.7203 Time=0.0098\n",
      "[41:  10]: eps=0.00000000 Loss=189.2693 Time=0.0074\n",
      "[41:  20]: eps=0.00000000 Loss=203.3863 Time=0.0073\n",
      "[41:  25]: eps=0.00000000 Loss=200.1004 Time=0.0071\n",
      "Epoch time: 0.2021, Total time: 9.1188\n",
      "Evaluating...\n",
      "[41:   6]: eps=0.00000000 Loss=192.4234 Time=0.0040\n",
      "Epoch 42, learning rate [0.005]\n",
      "[42:   0]: eps=0.00000000 Loss=169.8374 Time=0.0104\n",
      "[42:  10]: eps=0.00000000 Loss=201.8809 Time=0.0073\n",
      "[42:  20]: eps=0.00000000 Loss=204.5610 Time=0.0075\n",
      "[42:  25]: eps=0.00000000 Loss=199.8111 Time=0.0073\n",
      "Epoch time: 0.2080, Total time: 9.3268\n",
      "Evaluating...\n",
      "[42:   6]: eps=0.00000000 Loss=192.3699 Time=0.0052\n",
      "Epoch 43, learning rate [0.005]\n",
      "[43:   0]: eps=0.00000000 Loss=206.7900 Time=0.0092\n",
      "[43:  10]: eps=0.00000000 Loss=214.1505 Time=0.0070\n",
      "[43:  20]: eps=0.00000000 Loss=205.8923 Time=0.0069\n",
      "[43:  25]: eps=0.00000000 Loss=200.2976 Time=0.0068\n",
      "Epoch time: 0.1895, Total time: 9.5162\n",
      "Evaluating...\n",
      "[43:   6]: eps=0.00000000 Loss=192.3359 Time=0.0061\n",
      "Epoch 44, learning rate [0.005]\n",
      "[44:   0]: eps=0.00000000 Loss=172.3015 Time=0.0106\n",
      "[44:  10]: eps=0.00000000 Loss=202.2970 Time=0.0081\n",
      "[44:  20]: eps=0.00000000 Loss=198.2954 Time=0.0076\n",
      "[44:  25]: eps=0.00000000 Loss=200.5216 Time=0.0074\n",
      "Epoch time: 0.2102, Total time: 9.7264\n",
      "Evaluating...\n",
      "[44:   6]: eps=0.00000000 Loss=192.3789 Time=0.0044\n",
      "Epoch 45, learning rate [0.005]\n",
      "[45:   0]: eps=0.00000000 Loss=227.8854 Time=0.0090\n",
      "[45:  10]: eps=0.00000000 Loss=198.0869 Time=0.0079\n",
      "[45:  20]: eps=0.00000000 Loss=208.7626 Time=0.0094\n",
      "[45:  25]: eps=0.00000000 Loss=200.8226 Time=0.0089\n",
      "Epoch time: 0.2554, Total time: 9.9818\n",
      "Evaluating...\n",
      "[45:   6]: eps=0.00000000 Loss=192.3164 Time=0.0041\n",
      "Epoch 46, learning rate [0.005]\n",
      "[46:   0]: eps=0.00000000 Loss=247.5039 Time=0.0085\n",
      "[46:  10]: eps=0.00000000 Loss=193.7103 Time=0.0071\n",
      "[46:  20]: eps=0.00000000 Loss=196.1526 Time=0.0072\n",
      "[46:  25]: eps=0.00000000 Loss=199.8209 Time=0.0071\n",
      "Epoch time: 0.2040, Total time: 10.1858\n",
      "Evaluating...\n",
      "[46:   6]: eps=0.00000000 Loss=192.3353 Time=0.0048\n",
      "Epoch 47, learning rate [0.005]\n",
      "[47:   0]: eps=0.00000000 Loss=165.6919 Time=0.0080\n",
      "[47:  10]: eps=0.00000000 Loss=220.8365 Time=0.0072\n",
      "[47:  20]: eps=0.00000000 Loss=203.2972 Time=0.0071\n",
      "[47:  25]: eps=0.00000000 Loss=200.7278 Time=0.0069\n",
      "Epoch time: 0.1986, Total time: 10.3844\n",
      "Evaluating...\n",
      "[47:   6]: eps=0.00000000 Loss=192.2846 Time=0.0044\n",
      "Epoch 48, learning rate [0.005]\n",
      "[48:   0]: eps=0.00000000 Loss=205.6228 Time=0.0074\n",
      "[48:  10]: eps=0.00000000 Loss=227.8431 Time=0.0072\n",
      "[48:  20]: eps=0.00000000 Loss=202.0307 Time=0.0070\n",
      "[48:  25]: eps=0.00000000 Loss=198.8875 Time=0.0068\n",
      "Epoch time: 0.1939, Total time: 10.5783\n",
      "Evaluating...\n",
      "[48:   6]: eps=0.00000000 Loss=192.2275 Time=0.0039\n",
      "Epoch 49, learning rate [0.005]\n",
      "[49:   0]: eps=0.00000000 Loss=235.4698 Time=0.0076\n",
      "[49:  10]: eps=0.00000000 Loss=207.1412 Time=0.0068\n",
      "[49:  20]: eps=0.00000000 Loss=199.6180 Time=0.0067\n",
      "[49:  25]: eps=0.00000000 Loss=198.8875 Time=0.0066\n",
      "Epoch time: 0.1866, Total time: 10.7649\n",
      "Evaluating...\n",
      "[49:   6]: eps=0.00000000 Loss=192.3250 Time=0.0045\n",
      "Epoch 50, learning rate [0.005]\n",
      "[50:   0]: eps=0.00000000 Loss=197.3585 Time=0.0099\n",
      "[50:  10]: eps=0.00000000 Loss=195.8021 Time=0.0087\n",
      "[50:  20]: eps=0.00000000 Loss=198.7108 Time=0.0085\n",
      "[50:  25]: eps=0.00000000 Loss=199.4095 Time=0.0084\n",
      "Epoch time: 0.2409, Total time: 11.0057\n",
      "Evaluating...\n",
      "[50:   6]: eps=0.00000000 Loss=192.3849 Time=0.0051\n",
      "Epoch 51, learning rate [0.005]\n",
      "[51:   0]: eps=0.00000000 Loss=192.5538 Time=0.0120\n",
      "[51:  10]: eps=0.00000000 Loss=191.5430 Time=0.0080\n",
      "[51:  20]: eps=0.00000000 Loss=197.0942 Time=0.0078\n",
      "[51:  25]: eps=0.00000000 Loss=199.9450 Time=0.0074\n",
      "Epoch time: 0.2103, Total time: 11.2160\n",
      "Evaluating...\n",
      "[51:   6]: eps=0.00000000 Loss=192.1532 Time=0.0046\n",
      "Epoch 52, learning rate [0.005]\n",
      "[52:   0]: eps=0.00000000 Loss=164.7637 Time=0.0099\n",
      "[52:  10]: eps=0.00000000 Loss=201.2432 Time=0.0066\n",
      "[52:  20]: eps=0.00000000 Loss=200.3031 Time=0.0070\n",
      "[52:  25]: eps=0.00000000 Loss=200.1951 Time=0.0070\n",
      "Epoch time: 0.1980, Total time: 11.4140\n",
      "Evaluating...\n",
      "[52:   6]: eps=0.00000000 Loss=192.3228 Time=0.0047\n",
      "Epoch 53, learning rate [0.005]\n",
      "[53:   0]: eps=0.00000000 Loss=234.1334 Time=0.0080\n",
      "[53:  10]: eps=0.00000000 Loss=213.2649 Time=0.0070\n",
      "[53:  20]: eps=0.00000000 Loss=204.1018 Time=0.0079\n",
      "[53:  25]: eps=0.00000000 Loss=199.9905 Time=0.0082\n",
      "Epoch time: 0.2411, Total time: 11.6552\n",
      "Evaluating...\n",
      "[53:   6]: eps=0.00000000 Loss=192.1101 Time=0.0068\n",
      "Epoch 54, learning rate [0.005]\n",
      "[54:   0]: eps=0.00000000 Loss=169.2540 Time=0.0109\n",
      "[54:  10]: eps=0.00000000 Loss=199.7896 Time=0.0088\n",
      "[54:  20]: eps=0.00000000 Loss=200.3593 Time=0.0087\n",
      "[54:  25]: eps=0.00000000 Loss=200.0257 Time=0.0086\n",
      "Epoch time: 0.2504, Total time: 11.9056\n",
      "Evaluating...\n",
      "[54:   6]: eps=0.00000000 Loss=192.0983 Time=0.0047\n",
      "Epoch 55, learning rate [0.005]\n",
      "[55:   0]: eps=0.00000000 Loss=245.9262 Time=0.0090\n",
      "[55:  10]: eps=0.00000000 Loss=191.3105 Time=0.0076\n",
      "[55:  20]: eps=0.00000000 Loss=205.1386 Time=0.0082\n",
      "[55:  25]: eps=0.00000000 Loss=199.2213 Time=0.0080\n",
      "Epoch time: 0.2293, Total time: 12.1349\n",
      "Evaluating...\n",
      "[55:   6]: eps=0.00000000 Loss=191.8315 Time=0.0040\n",
      "Epoch 56, learning rate [0.005]\n",
      "[56:   0]: eps=0.00000000 Loss=198.2553 Time=0.0070\n",
      "[56:  10]: eps=0.00000000 Loss=203.5051 Time=0.0076\n",
      "[56:  20]: eps=0.00000000 Loss=200.0514 Time=0.0072\n",
      "[56:  25]: eps=0.00000000 Loss=200.2193 Time=0.0070\n",
      "Epoch time: 0.2007, Total time: 12.3356\n",
      "Evaluating...\n",
      "[56:   6]: eps=0.00000000 Loss=191.9558 Time=0.0047\n",
      "Epoch 57, learning rate [0.005]\n",
      "[57:   0]: eps=0.00000000 Loss=202.0919 Time=0.0080\n",
      "[57:  10]: eps=0.00000000 Loss=197.3928 Time=0.0075\n",
      "[57:  20]: eps=0.00000000 Loss=204.2596 Time=0.0076\n",
      "[57:  25]: eps=0.00000000 Loss=200.2425 Time=0.0074\n",
      "Epoch time: 0.2075, Total time: 12.5430\n",
      "Evaluating...\n",
      "[57:   6]: eps=0.00000000 Loss=192.0043 Time=0.0045\n",
      "Epoch 58, learning rate [0.005]\n",
      "[58:   0]: eps=0.00000000 Loss=165.4311 Time=0.0095\n",
      "[58:  10]: eps=0.00000000 Loss=214.5886 Time=0.0081\n",
      "[58:  20]: eps=0.00000000 Loss=200.5962 Time=0.0080\n",
      "[58:  25]: eps=0.00000000 Loss=198.9319 Time=0.0080\n",
      "Epoch time: 0.2300, Total time: 12.7730\n",
      "Evaluating...\n",
      "[58:   6]: eps=0.00000000 Loss=191.9411 Time=0.0065\n",
      "Epoch 59, learning rate [0.005]\n",
      "[59:   0]: eps=0.00000000 Loss=256.3041 Time=0.0090\n",
      "[59:  10]: eps=0.00000000 Loss=206.3226 Time=0.0075\n",
      "[59:  20]: eps=0.00000000 Loss=199.1685 Time=0.0072\n",
      "[59:  25]: eps=0.00000000 Loss=199.8435 Time=0.0070\n",
      "Epoch time: 0.2030, Total time: 12.9760\n",
      "Evaluating...\n",
      "[59:   6]: eps=0.00000000 Loss=192.1197 Time=0.0039\n",
      "Epoch 60, learning rate [0.005]\n",
      "[60:   0]: eps=0.00000000 Loss=186.9324 Time=0.0072\n",
      "[60:  10]: eps=0.00000000 Loss=206.1871 Time=0.0075\n",
      "[60:  20]: eps=0.00000000 Loss=204.7124 Time=0.0072\n",
      "[60:  25]: eps=0.00000000 Loss=198.6382 Time=0.0071\n",
      "Epoch time: 0.1993, Total time: 13.1753\n",
      "Evaluating...\n",
      "[60:   6]: eps=0.00000000 Loss=191.7628 Time=0.0042\n",
      "Epoch 61, learning rate [0.005]\n",
      "[61:   0]: eps=0.00000000 Loss=207.9915 Time=0.0080\n",
      "[61:  10]: eps=0.00000000 Loss=211.8442 Time=0.0074\n",
      "[61:  20]: eps=0.00000000 Loss=204.1487 Time=0.0071\n",
      "[61:  25]: eps=0.00000000 Loss=199.1032 Time=0.0069\n",
      "Epoch time: 0.1942, Total time: 13.3695\n",
      "Evaluating...\n",
      "[61:   6]: eps=0.00000000 Loss=192.0071 Time=0.0046\n",
      "Epoch 62, learning rate [0.005]\n",
      "[62:   0]: eps=0.00000000 Loss=156.0671 Time=0.0085\n",
      "[62:  10]: eps=0.00000000 Loss=179.9809 Time=0.0066\n",
      "[62:  20]: eps=0.00000000 Loss=199.6234 Time=0.0068\n",
      "[62:  25]: eps=0.00000000 Loss=199.1353 Time=0.0068\n",
      "Epoch time: 0.1978, Total time: 13.5673\n",
      "Evaluating...\n",
      "[62:   6]: eps=0.00000000 Loss=191.8958 Time=0.0042\n",
      "Epoch 63, learning rate [0.005]\n",
      "[63:   0]: eps=0.00000000 Loss=203.3219 Time=0.0089\n",
      "[63:  10]: eps=0.00000000 Loss=208.5416 Time=0.0078\n",
      "[63:  20]: eps=0.00000000 Loss=195.5639 Time=0.0073\n",
      "[63:  25]: eps=0.00000000 Loss=199.7036 Time=0.0071\n",
      "Epoch time: 0.2087, Total time: 13.7760\n",
      "Evaluating...\n",
      "[63:   6]: eps=0.00000000 Loss=192.0780 Time=0.0045\n",
      "Epoch 64, learning rate [0.005]\n",
      "[64:   0]: eps=0.00000000 Loss=211.7859 Time=0.0080\n",
      "[64:  10]: eps=0.00000000 Loss=188.7009 Time=0.0077\n",
      "[64:  20]: eps=0.00000000 Loss=205.1772 Time=0.0071\n",
      "[64:  25]: eps=0.00000000 Loss=199.2861 Time=0.0068\n",
      "Epoch time: 0.1957, Total time: 13.9717\n",
      "Evaluating...\n",
      "[64:   6]: eps=0.00000000 Loss=191.7360 Time=0.0040\n",
      "Epoch 65, learning rate [0.005]\n",
      "[65:   0]: eps=0.00000000 Loss=190.7716 Time=0.0089\n",
      "[65:  10]: eps=0.00000000 Loss=206.0051 Time=0.0070\n",
      "[65:  20]: eps=0.00000000 Loss=202.7277 Time=0.0071\n",
      "[65:  25]: eps=0.00000000 Loss=199.7116 Time=0.0072\n",
      "Epoch time: 0.2064, Total time: 14.1781\n",
      "Evaluating...\n",
      "[65:   6]: eps=0.00000000 Loss=191.9654 Time=0.0050\n",
      "Epoch 66, learning rate [0.005]\n",
      "[66:   0]: eps=0.00000000 Loss=238.1320 Time=0.0085\n",
      "[66:  10]: eps=0.00000000 Loss=211.8954 Time=0.0078\n",
      "[66:  20]: eps=0.00000000 Loss=198.2767 Time=0.0076\n",
      "[66:  25]: eps=0.00000000 Loss=199.5572 Time=0.0074\n",
      "Epoch time: 0.2077, Total time: 14.3858\n",
      "Evaluating...\n",
      "[66:   6]: eps=0.00000000 Loss=191.8303 Time=0.0044\n",
      "Epoch 67, learning rate [0.005]\n",
      "[67:   0]: eps=0.00000000 Loss=170.9777 Time=0.0090\n",
      "[67:  10]: eps=0.00000000 Loss=198.7829 Time=0.0089\n",
      "[67:  20]: eps=0.00000000 Loss=205.7214 Time=0.0086\n",
      "[67:  25]: eps=0.00000000 Loss=198.7044 Time=0.0082\n",
      "Epoch time: 0.2354, Total time: 14.6212\n",
      "Evaluating...\n",
      "[67:   6]: eps=0.00000000 Loss=191.9244 Time=0.0045\n",
      "Epoch 68, learning rate [0.005]\n",
      "[68:   0]: eps=0.00000000 Loss=154.5485 Time=0.0090\n",
      "[68:  10]: eps=0.00000000 Loss=187.1592 Time=0.0072\n",
      "[68:  20]: eps=0.00000000 Loss=195.1997 Time=0.0072\n",
      "[68:  25]: eps=0.00000000 Loss=199.8126 Time=0.0069\n",
      "Epoch time: 0.1970, Total time: 14.8182\n",
      "Evaluating...\n",
      "[68:   6]: eps=0.00000000 Loss=191.7874 Time=0.0044\n",
      "Epoch 69, learning rate [0.005]\n",
      "[69:   0]: eps=0.00000000 Loss=173.4731 Time=0.0081\n",
      "[69:  10]: eps=0.00000000 Loss=200.4066 Time=0.0077\n",
      "[69:  20]: eps=0.00000000 Loss=200.6256 Time=0.0076\n",
      "[69:  25]: eps=0.00000000 Loss=198.5327 Time=0.0074\n",
      "Epoch time: 0.2064, Total time: 15.0245\n",
      "Evaluating...\n",
      "[69:   6]: eps=0.00000000 Loss=191.5784 Time=0.0043\n",
      "Epoch 70, learning rate [0.005]\n",
      "[70:   0]: eps=0.00000000 Loss=119.0792 Time=0.0091\n",
      "[70:  10]: eps=0.00000000 Loss=195.5742 Time=0.0076\n",
      "[70:  20]: eps=0.00000000 Loss=201.7186 Time=0.0075\n",
      "[70:  25]: eps=0.00000000 Loss=198.6689 Time=0.0072\n",
      "Epoch time: 0.2086, Total time: 15.2331\n",
      "Evaluating...\n",
      "[70:   6]: eps=0.00000000 Loss=191.8451 Time=0.0045\n",
      "Epoch 71, learning rate [0.005]\n",
      "[71:   0]: eps=0.00000000 Loss=193.3060 Time=0.0090\n",
      "[71:  10]: eps=0.00000000 Loss=189.8834 Time=0.0073\n",
      "[71:  20]: eps=0.00000000 Loss=198.6447 Time=0.0071\n",
      "[71:  25]: eps=0.00000000 Loss=199.1042 Time=0.0069\n",
      "Epoch time: 0.1892, Total time: 15.4223\n",
      "Evaluating...\n",
      "[71:   6]: eps=0.00000000 Loss=191.8745 Time=0.0042\n",
      "Epoch 72, learning rate [0.005]\n",
      "[72:   0]: eps=0.00000000 Loss=161.6012 Time=0.0080\n",
      "[72:  10]: eps=0.00000000 Loss=200.2257 Time=0.0083\n",
      "[72:  20]: eps=0.00000000 Loss=203.7118 Time=0.0079\n",
      "[72:  25]: eps=0.00000000 Loss=199.4675 Time=0.0078\n",
      "Epoch time: 0.2173, Total time: 15.6396\n",
      "Evaluating...\n",
      "[72:   6]: eps=0.00000000 Loss=191.6924 Time=0.0056\n",
      "Epoch 73, learning rate [0.005]\n",
      "[73:   0]: eps=0.00000000 Loss=218.4881 Time=0.0080\n",
      "[73:  10]: eps=0.00000000 Loss=203.8074 Time=0.0075\n",
      "[73:  20]: eps=0.00000000 Loss=201.1321 Time=0.0071\n",
      "[73:  25]: eps=0.00000000 Loss=199.3494 Time=0.0071\n",
      "Epoch time: 0.2039, Total time: 15.8435\n",
      "Evaluating...\n",
      "[73:   6]: eps=0.00000000 Loss=191.8398 Time=0.0040\n",
      "Epoch 74, learning rate [0.005]\n",
      "[74:   0]: eps=0.00000000 Loss=204.6472 Time=0.0080\n",
      "[74:  10]: eps=0.00000000 Loss=202.5508 Time=0.0073\n",
      "[74:  20]: eps=0.00000000 Loss=206.0803 Time=0.0070\n",
      "[74:  25]: eps=0.00000000 Loss=199.4537 Time=0.0070\n",
      "Epoch time: 0.1983, Total time: 16.0418\n",
      "Evaluating...\n",
      "[74:   6]: eps=0.00000000 Loss=191.7684 Time=0.0044\n",
      "Epoch 75, learning rate [0.005]\n",
      "[75:   0]: eps=0.00000000 Loss=223.2848 Time=0.0074\n",
      "[75:  10]: eps=0.00000000 Loss=200.6727 Time=0.0080\n",
      "[75:  20]: eps=0.00000000 Loss=206.0563 Time=0.0074\n",
      "[75:  25]: eps=0.00000000 Loss=199.0759 Time=0.0071\n",
      "Epoch time: 0.2059, Total time: 16.2477\n",
      "Evaluating...\n",
      "[75:   6]: eps=0.00000000 Loss=191.9858 Time=0.0037\n",
      "Epoch 76, learning rate [0.005]\n",
      "[76:   0]: eps=0.00000000 Loss=239.6338 Time=0.0080\n",
      "[76:  10]: eps=0.00000000 Loss=194.9762 Time=0.0083\n",
      "[76:  20]: eps=0.00000000 Loss=202.9909 Time=0.0089\n",
      "[76:  25]: eps=0.00000000 Loss=199.5518 Time=0.0085\n",
      "Epoch time: 0.2478, Total time: 16.4955\n",
      "Evaluating...\n",
      "[76:   6]: eps=0.00000000 Loss=191.5020 Time=0.0043\n",
      "Epoch 77, learning rate [0.005]\n",
      "[77:   0]: eps=0.00000000 Loss=188.4854 Time=0.0075\n",
      "[77:  10]: eps=0.00000000 Loss=193.1936 Time=0.0072\n",
      "[77:  20]: eps=0.00000000 Loss=199.3615 Time=0.0068\n",
      "[77:  25]: eps=0.00000000 Loss=198.9946 Time=0.0068\n",
      "Epoch time: 0.1930, Total time: 16.6886\n",
      "Evaluating...\n",
      "[77:   6]: eps=0.00000000 Loss=191.7025 Time=0.0039\n",
      "Epoch 78, learning rate [0.005]\n",
      "[78:   0]: eps=0.00000000 Loss=201.0933 Time=0.0071\n",
      "[78:  10]: eps=0.00000000 Loss=205.8076 Time=0.0075\n",
      "[78:  20]: eps=0.00000000 Loss=199.9186 Time=0.0074\n",
      "[78:  25]: eps=0.00000000 Loss=197.9410 Time=0.0073\n",
      "Epoch time: 0.2051, Total time: 16.8937\n",
      "Evaluating...\n",
      "[78:   6]: eps=0.00000000 Loss=191.4983 Time=0.0059\n",
      "Epoch 79, learning rate [0.005]\n",
      "[79:   0]: eps=0.00000000 Loss=111.9875 Time=0.0090\n",
      "[79:  10]: eps=0.00000000 Loss=193.1178 Time=0.0079\n",
      "[79:  20]: eps=0.00000000 Loss=198.7733 Time=0.0074\n",
      "[79:  25]: eps=0.00000000 Loss=199.7435 Time=0.0072\n",
      "Epoch time: 0.2013, Total time: 17.0950\n",
      "Evaluating...\n",
      "[79:   6]: eps=0.00000000 Loss=191.5244 Time=0.0047\n",
      "Epoch 80, learning rate [0.005]\n",
      "[80:   0]: eps=0.00000000 Loss=162.1631 Time=0.0083\n",
      "[80:  10]: eps=0.00000000 Loss=192.8055 Time=0.0074\n",
      "[80:  20]: eps=0.00000000 Loss=193.2962 Time=0.0078\n",
      "[80:  25]: eps=0.00000000 Loss=199.1933 Time=0.0082\n",
      "Epoch time: 0.2345, Total time: 17.3294\n",
      "Evaluating...\n",
      "[80:   6]: eps=0.00000000 Loss=191.7131 Time=0.0051\n",
      "Epoch 81, learning rate [0.005]\n",
      "[81:   0]: eps=0.00000000 Loss=200.7266 Time=0.0090\n",
      "[81:  10]: eps=0.00000000 Loss=203.8824 Time=0.0074\n",
      "[81:  20]: eps=0.00000000 Loss=201.3349 Time=0.0076\n",
      "[81:  25]: eps=0.00000000 Loss=198.3570 Time=0.0074\n",
      "Epoch time: 0.2097, Total time: 17.5391\n",
      "Evaluating...\n",
      "[81:   6]: eps=0.00000000 Loss=191.6442 Time=0.0042\n",
      "Epoch 82, learning rate [0.005]\n",
      "[82:   0]: eps=0.00000000 Loss=135.0118 Time=0.0060\n",
      "[82:  10]: eps=0.00000000 Loss=189.7012 Time=0.0070\n",
      "[82:  20]: eps=0.00000000 Loss=194.8916 Time=0.0071\n",
      "[82:  25]: eps=0.00000000 Loss=198.4460 Time=0.0070\n",
      "Epoch time: 0.2018, Total time: 17.7409\n",
      "Evaluating...\n",
      "[82:   6]: eps=0.00000000 Loss=191.6903 Time=0.0043\n",
      "Epoch 83, learning rate [0.005]\n",
      "[83:   0]: eps=0.00000000 Loss=191.0207 Time=0.0070\n",
      "[83:  10]: eps=0.00000000 Loss=216.9233 Time=0.0073\n",
      "[83:  20]: eps=0.00000000 Loss=197.8721 Time=0.0087\n",
      "[83:  25]: eps=0.00000000 Loss=199.5217 Time=0.0085\n",
      "Epoch time: 0.2448, Total time: 17.9857\n",
      "Evaluating...\n",
      "[83:   6]: eps=0.00000000 Loss=191.8617 Time=0.0052\n",
      "Epoch 84, learning rate [0.005]\n",
      "[84:   0]: eps=0.00000000 Loss=283.8621 Time=0.0099\n",
      "[84:  10]: eps=0.00000000 Loss=196.2630 Time=0.0110\n",
      "[84:  20]: eps=0.00000000 Loss=203.3360 Time=0.0106\n",
      "[84:  25]: eps=0.00000000 Loss=198.8714 Time=0.0099\n",
      "Epoch time: 0.3730, Total time: 18.3587\n",
      "Evaluating...\n",
      "[84:   6]: eps=0.00000000 Loss=191.4126 Time=0.0049\n",
      "Epoch 85, learning rate [0.005]\n",
      "[85:   0]: eps=0.00000000 Loss=192.6690 Time=0.0081\n",
      "[85:  10]: eps=0.00000000 Loss=197.6719 Time=0.0088\n",
      "[85:  20]: eps=0.00000000 Loss=199.4620 Time=0.0081\n",
      "[85:  25]: eps=0.00000000 Loss=199.2789 Time=0.0077\n",
      "Epoch time: 0.2263, Total time: 18.5850\n",
      "Evaluating...\n",
      "[85:   6]: eps=0.00000000 Loss=191.3960 Time=0.0040\n",
      "Epoch 86, learning rate [0.005]\n",
      "[86:   0]: eps=0.00000000 Loss=179.4957 Time=0.0080\n",
      "[86:  10]: eps=0.00000000 Loss=193.8944 Time=0.0073\n",
      "[86:  20]: eps=0.00000000 Loss=205.9613 Time=0.0074\n",
      "[86:  25]: eps=0.00000000 Loss=199.5144 Time=0.0085\n",
      "Epoch time: 0.2435, Total time: 18.8285\n",
      "Evaluating...\n",
      "[86:   6]: eps=0.00000000 Loss=191.8097 Time=0.0056\n",
      "Epoch 87, learning rate [0.005]\n",
      "[87:   0]: eps=0.00000000 Loss=248.2521 Time=0.0100\n",
      "[87:  10]: eps=0.00000000 Loss=201.5314 Time=0.0081\n",
      "[87:  20]: eps=0.00000000 Loss=199.1376 Time=0.0083\n",
      "[87:  25]: eps=0.00000000 Loss=199.8398 Time=0.0084\n",
      "Epoch time: 0.2377, Total time: 19.0662\n",
      "Evaluating...\n",
      "[87:   6]: eps=0.00000000 Loss=191.6067 Time=0.0063\n",
      "Epoch 88, learning rate [0.005]\n",
      "[88:   0]: eps=0.00000000 Loss=167.9028 Time=0.0105\n",
      "[88:  10]: eps=0.00000000 Loss=214.9974 Time=0.0111\n",
      "[88:  20]: eps=0.00000000 Loss=201.8797 Time=0.0103\n",
      "[88:  25]: eps=0.00000000 Loss=198.9860 Time=0.0099\n",
      "Epoch time: 0.2900, Total time: 19.3562\n",
      "Evaluating...\n",
      "[88:   6]: eps=0.00000000 Loss=191.7753 Time=0.0048\n",
      "Epoch 89, learning rate [0.005]\n",
      "[89:   0]: eps=0.00000000 Loss=156.2439 Time=0.0100\n",
      "[89:  10]: eps=0.00000000 Loss=196.7605 Time=0.0091\n",
      "[89:  20]: eps=0.00000000 Loss=199.9266 Time=0.0093\n",
      "[89:  25]: eps=0.00000000 Loss=199.3384 Time=0.0092\n",
      "Epoch time: 0.2677, Total time: 19.6239\n",
      "Evaluating...\n",
      "[89:   6]: eps=0.00000000 Loss=191.6795 Time=0.0052\n",
      "Epoch 90, learning rate [0.005]\n",
      "[90:   0]: eps=0.00000000 Loss=99.0967 Time=0.0098\n",
      "[90:  10]: eps=0.00000000 Loss=206.8619 Time=0.0074\n",
      "[90:  20]: eps=0.00000000 Loss=201.8389 Time=0.0072\n",
      "[90:  25]: eps=0.00000000 Loss=198.7084 Time=0.0072\n",
      "Epoch time: 0.2107, Total time: 19.8346\n",
      "Evaluating...\n",
      "[90:   6]: eps=0.00000000 Loss=191.7445 Time=0.0040\n",
      "Epoch 91, learning rate [0.005]\n",
      "[91:   0]: eps=0.00000000 Loss=152.7296 Time=0.0080\n",
      "[91:  10]: eps=0.00000000 Loss=190.4976 Time=0.0079\n",
      "[91:  20]: eps=0.00000000 Loss=200.3277 Time=0.0082\n",
      "[91:  25]: eps=0.00000000 Loss=199.1760 Time=0.0080\n",
      "Epoch time: 0.2265, Total time: 20.0611\n",
      "Evaluating...\n",
      "[91:   6]: eps=0.00000000 Loss=191.5076 Time=0.0053\n",
      "Epoch 92, learning rate [0.005]\n",
      "[92:   0]: eps=0.00000000 Loss=224.9174 Time=0.0070\n",
      "[92:  10]: eps=0.00000000 Loss=189.3750 Time=0.0068\n",
      "[92:  20]: eps=0.00000000 Loss=197.4512 Time=0.0074\n",
      "[92:  25]: eps=0.00000000 Loss=198.0947 Time=0.0079\n",
      "Epoch time: 0.2347, Total time: 20.2958\n",
      "Evaluating...\n",
      "[92:   6]: eps=0.00000000 Loss=191.3245 Time=0.0068\n",
      "Epoch 93, learning rate [0.005]\n",
      "[93:   0]: eps=0.00000000 Loss=212.8561 Time=0.0120\n",
      "[93:  10]: eps=0.00000000 Loss=203.5856 Time=0.0100\n",
      "[93:  20]: eps=0.00000000 Loss=205.1967 Time=0.0094\n",
      "[93:  25]: eps=0.00000000 Loss=199.3793 Time=0.0090\n",
      "Epoch time: 0.2590, Total time: 20.5548\n",
      "Evaluating...\n",
      "[93:   6]: eps=0.00000000 Loss=191.2822 Time=0.0041\n",
      "Epoch 94, learning rate [0.005]\n",
      "[94:   0]: eps=0.00000000 Loss=166.3218 Time=0.0130\n",
      "[94:  10]: eps=0.00000000 Loss=200.7424 Time=0.0093\n",
      "[94:  20]: eps=0.00000000 Loss=200.2873 Time=0.0091\n",
      "[94:  25]: eps=0.00000000 Loss=198.8912 Time=0.0087\n",
      "Epoch time: 0.2562, Total time: 20.8110\n",
      "Evaluating...\n",
      "[94:   6]: eps=0.00000000 Loss=191.2813 Time=0.0041\n",
      "Epoch 95, learning rate [0.005]\n",
      "[95:   0]: eps=0.00000000 Loss=159.9323 Time=0.0080\n",
      "[95:  10]: eps=0.00000000 Loss=204.3892 Time=0.0075\n",
      "[95:  20]: eps=0.00000000 Loss=200.9714 Time=0.0071\n",
      "[95:  25]: eps=0.00000000 Loss=196.6313 Time=0.0073\n",
      "Epoch time: 0.2083, Total time: 21.0194\n",
      "Evaluating...\n",
      "[95:   6]: eps=0.00000000 Loss=191.6258 Time=0.0053\n",
      "Epoch 96, learning rate [0.005]\n",
      "[96:   0]: eps=0.00000000 Loss=127.7237 Time=0.0070\n",
      "[96:  10]: eps=0.00000000 Loss=189.8375 Time=0.0073\n",
      "[96:  20]: eps=0.00000000 Loss=192.7181 Time=0.0073\n",
      "[96:  25]: eps=0.00000000 Loss=198.0809 Time=0.0074\n",
      "Epoch time: 0.2106, Total time: 21.2300\n",
      "Evaluating...\n",
      "[96:   6]: eps=0.00000000 Loss=191.2847 Time=0.0050\n",
      "Epoch 97, learning rate [0.005]\n",
      "[97:   0]: eps=0.00000000 Loss=205.2382 Time=0.0079\n",
      "[97:  10]: eps=0.00000000 Loss=202.4795 Time=0.0073\n",
      "[97:  20]: eps=0.00000000 Loss=200.2512 Time=0.0088\n",
      "[97:  25]: eps=0.00000000 Loss=198.9643 Time=0.0088\n",
      "Epoch time: 0.2555, Total time: 21.4855\n",
      "Evaluating...\n",
      "[97:   6]: eps=0.00000000 Loss=191.3501 Time=0.0043\n",
      "Epoch 98, learning rate [0.005]\n",
      "[98:   0]: eps=0.00000000 Loss=257.2696 Time=0.0089\n",
      "[98:  10]: eps=0.00000000 Loss=218.9010 Time=0.0072\n",
      "[98:  20]: eps=0.00000000 Loss=205.6271 Time=0.0069\n",
      "[98:  25]: eps=0.00000000 Loss=199.3661 Time=0.0075\n",
      "Epoch time: 0.2093, Total time: 21.6948\n",
      "Evaluating...\n",
      "[98:   6]: eps=0.00000000 Loss=191.8817 Time=0.0053\n",
      "Epoch 99, learning rate [0.005]\n",
      "[99:   0]: eps=0.00000000 Loss=207.1013 Time=0.0100\n",
      "[99:  10]: eps=0.00000000 Loss=180.0893 Time=0.0082\n",
      "[99:  20]: eps=0.00000000 Loss=199.3245 Time=0.0085\n",
      "[99:  25]: eps=0.00000000 Loss=198.4561 Time=0.0087\n",
      "Epoch time: 0.2530, Total time: 21.9478\n",
      "Evaluating...\n",
      "[99:   6]: eps=0.00000000 Loss=191.5466 Time=0.0058\n",
      "Epoch 100, learning rate [0.005]\n",
      "[100:   0]: eps=0.00000000 Loss=218.2744 Time=0.0080\n",
      "[100:  10]: eps=0.00002155 Loss=194.0463 Time=0.0374 Robust_Loss=191.6244\n",
      "[100:  20]: eps=0.00034474 Loss=203.9570 Time=0.0426 Robust_Loss=203.2548\n",
      "[100:  25]: eps=0.00084165 Loss=198.6516 Time=0.0435 Robust_Loss=197.8664\n",
      "Epoch time: 1.1616, Total time: 23.1094\n",
      "Evaluating...\n",
      "[100:   6]: eps=0.00084165 Loss=191.3764 Robust_Loss=191.5109 Time=0.0277\n",
      "Epoch 101, learning rate [0.005]\n",
      "[101:   0]: eps=0.00098462 Loss=165.1619 Robust_Loss=165.3293 Time=0.0500\n",
      "[101:  10]: eps=0.00361896 Loss=194.8033 Robust_Loss=195.1841 Time=0.0503\n",
      "[101:  20]: eps=0.00964727 Loss=208.9268 Robust_Loss=209.9043 Time=0.0508\n",
      "[101:  25]: eps=0.01457652 Loss=200.3082 Robust_Loss=201.5825 Time=0.0497\n",
      "Epoch time: 1.3268, Total time: 24.4362\n",
      "Evaluating...\n",
      "[101:   6]: eps=0.01457652 Loss=196.0899 Robust_Loss=199.9011 Time=0.0283\n",
      "Epoch 102, learning rate [0.005]\n",
      "[102:   0]: eps=0.01575385 Loss=202.5372 Robust_Loss=207.0685 Time=0.0451\n",
      "[102:  10]: eps=0.03183758 Loss=194.6158 Robust_Loss=202.4853 Time=0.0442\n",
      "[102:  20]: eps=0.05502959 Loss=211.0360 Robust_Loss=225.6754 Time=0.0429\n",
      "[102:  25]: eps=0.06686391 Loss=217.5034 Robust_Loss=235.4957 Time=0.0416\n",
      "Epoch time: 1.1035, Total time: 25.5396\n",
      "Evaluating...\n",
      "[102:   6]: eps=0.06686391 Loss=232.2117 Robust_Loss=270.0694 Time=0.0209\n",
      "Epoch 103, learning rate [0.005]\n",
      "[103:   0]: eps=0.06923077 Loss=263.1556 Robust_Loss=308.3603 Time=0.0400\n",
      "[103:  10]: eps=0.09289941 Loss=248.0201 Robust_Loss=300.0133 Time=0.0394\n",
      "[103:  20]: eps=0.11656805 Loss=264.2961 Robust_Loss=325.2442 Time=0.0431\n",
      "[103:  25]: eps=0.12840237 Loss=271.8669 Robust_Loss=335.9677 Time=0.0419\n",
      "Epoch time: 1.1140, Total time: 26.6536\n",
      "Evaluating...\n",
      "[103:   6]: eps=0.12840237 Loss=289.0115 Robust_Loss=362.6194 Time=0.0214\n",
      "Epoch 104, learning rate [0.005]\n",
      "[104:   0]: eps=0.13076923 Loss=279.4599 Robust_Loss=354.6976 Time=0.0418\n",
      "[104:  10]: eps=0.15443787 Loss=321.7862 Robust_Loss=408.4674 Time=0.0447\n",
      "[104:  20]: eps=0.17810651 Loss=340.6530 Robust_Loss=434.6142 Time=0.0424\n",
      "[104:  25]: eps=0.18994083 Loss=329.5044 Robust_Loss=422.5599 Time=0.0423\n",
      "Epoch time: 1.1227, Total time: 27.7763\n",
      "Evaluating...\n",
      "[104:   6]: eps=0.18994083 Loss=349.1830 Robust_Loss=450.1860 Time=0.0222\n",
      "Epoch 105, learning rate [0.005]\n",
      "[105:   0]: eps=0.19230769 Loss=371.7800 Robust_Loss=483.8503 Time=0.0470\n",
      "[105:  10]: eps=0.21597633 Loss=386.1299 Robust_Loss=504.3413 Time=0.0419\n",
      "[105:  20]: eps=0.23964497 Loss=398.8924 Robust_Loss=519.2549 Time=0.0414\n",
      "[105:  25]: eps=0.25147929 Loss=392.0254 Robust_Loss=510.5646 Time=0.0408\n",
      "Epoch time: 1.0762, Total time: 28.8524\n",
      "Evaluating...\n",
      "[105:   6]: eps=0.25147929 Loss=393.8442 Robust_Loss=506.4327 Time=0.0222\n",
      "Epoch 106, learning rate [0.005]\n",
      "[106:   0]: eps=0.25384615 Loss=372.7095 Robust_Loss=482.7009 Time=0.0476\n",
      "[106:  10]: eps=0.27751479 Loss=431.4251 Robust_Loss=551.4244 Time=0.0391\n",
      "[106:  20]: eps=0.30118343 Loss=429.3124 Robust_Loss=542.8199 Time=0.0407\n",
      "[106:  25]: eps=0.31301775 Loss=425.4064 Robust_Loss=535.0550 Time=0.0402\n",
      "Epoch time: 1.0639, Total time: 29.9163\n",
      "Evaluating...\n",
      "[106:   6]: eps=0.31301775 Loss=424.8775 Robust_Loss=516.4449 Time=0.0230\n",
      "Epoch 107, learning rate [0.005]\n",
      "[107:   0]: eps=0.31538462 Loss=374.9452 Robust_Loss=466.6707 Time=0.0370\n",
      "[107:  10]: eps=0.33905325 Loss=458.7251 Robust_Loss=552.3327 Time=0.0412\n",
      "[107:  20]: eps=0.36272189 Loss=469.2358 Robust_Loss=558.3906 Time=0.0399\n",
      "[107:  25]: eps=0.37455621 Loss=462.5421 Robust_Loss=548.6345 Time=0.0393\n",
      "Epoch time: 1.0430, Total time: 30.9593\n",
      "Evaluating...\n",
      "[107:   6]: eps=0.37455621 Loss=459.0861 Robust_Loss=531.6838 Time=0.0220\n",
      "Epoch 108, learning rate [0.005]\n",
      "[108:   0]: eps=0.37692308 Loss=390.7973 Robust_Loss=439.5000 Time=0.0419\n",
      "[108:  10]: eps=0.40059172 Loss=457.8307 Robust_Loss=524.9224 Time=0.0430\n",
      "[108:  20]: eps=0.42426036 Loss=498.7476 Robust_Loss=562.9984 Time=0.0413\n",
      "[108:  25]: eps=0.43609467 Loss=494.9253 Robust_Loss=557.1886 Time=0.0402\n",
      "Epoch time: 1.0698, Total time: 32.0291\n",
      "Evaluating...\n",
      "[108:   6]: eps=0.43609467 Loss=484.5152 Robust_Loss=535.7445 Time=0.0223\n",
      "Epoch 109, learning rate [0.005]\n",
      "[109:   0]: eps=0.43846154 Loss=419.8094 Robust_Loss=472.7122 Time=0.0438\n",
      "[109:  10]: eps=0.46213018 Loss=440.6078 Robust_Loss=488.0425 Time=0.0404\n",
      "[109:  20]: eps=0.48579882 Loss=515.5612 Robust_Loss=555.9245 Time=0.0402\n",
      "[109:  25]: eps=0.49763314 Loss=512.8373 Robust_Loss=552.8760 Time=0.0397\n",
      "Epoch time: 1.0517, Total time: 33.0808\n",
      "Evaluating...\n",
      "[109:   6]: eps=0.49763314 Loss=497.7092 Robust_Loss=530.2612 Time=0.0255\n",
      "Epoch 110, learning rate [0.005]\n",
      "[110:   0]: eps=0.50000000 Loss=465.2721 Robust_Loss=491.9945 Time=0.0409\n",
      "[110:  10]: eps=0.50000000 Loss=523.6531 Robust_Loss=546.9918 Time=0.0434\n",
      "[110:  20]: eps=0.50000000 Loss=512.1303 Robust_Loss=532.1071 Time=0.0425\n",
      "[110:  25]: eps=0.50000000 Loss=511.6817 Robust_Loss=530.5743 Time=0.0413\n",
      "Epoch time: 1.1009, Total time: 34.1817\n",
      "Evaluating...\n",
      "[110:   6]: eps=0.50000000 Loss=491.9590 Robust_Loss=506.1114 Time=0.0231\n",
      "Epoch 111, learning rate [0.005]\n",
      "[111:   0]: eps=0.50000000 Loss=613.8071 Robust_Loss=632.3813 Time=0.0510\n",
      "[111:  10]: eps=0.50000000 Loss=514.4893 Robust_Loss=526.2573 Time=0.0440\n",
      "[111:  20]: eps=0.50000000 Loss=512.7744 Robust_Loss=523.4953 Time=0.0434\n",
      "[111:  25]: eps=0.50000000 Loss=509.1183 Robust_Loss=519.5181 Time=0.0423\n",
      "Epoch time: 1.1949, Total time: 35.3766\n",
      "Evaluating...\n",
      "[111:   6]: eps=0.50000000 Loss=492.8788 Robust_Loss=503.3125 Time=0.0224\n",
      "Epoch 112, learning rate [0.005]\n",
      "[112:   0]: eps=0.50000000 Loss=539.5608 Robust_Loss=544.8321 Time=0.0506\n",
      "[112:  10]: eps=0.50000000 Loss=538.1508 Robust_Loss=547.4745 Time=0.0420\n",
      "[112:  20]: eps=0.50000000 Loss=515.0030 Robust_Loss=522.9948 Time=0.0414\n",
      "[112:  25]: eps=0.50000000 Loss=509.7651 Robust_Loss=517.7692 Time=0.0407\n",
      "Epoch time: 1.0764, Total time: 36.4530\n",
      "Evaluating...\n",
      "[112:   6]: eps=0.50000000 Loss=493.6905 Robust_Loss=502.3980 Time=0.0285\n",
      "Epoch 113, learning rate [0.005]\n",
      "[113:   0]: eps=0.50000000 Loss=449.1315 Robust_Loss=459.1500 Time=0.0406\n",
      "[113:  10]: eps=0.50000000 Loss=536.2006 Robust_Loss=544.2225 Time=0.0440\n",
      "[113:  20]: eps=0.50000000 Loss=523.3809 Robust_Loss=530.4034 Time=0.0422\n",
      "[113:  25]: eps=0.50000000 Loss=508.3901 Robust_Loss=515.1562 Time=0.0413\n",
      "Epoch time: 1.0942, Total time: 37.5473\n",
      "Evaluating...\n",
      "[113:   6]: eps=0.50000000 Loss=494.3980 Robust_Loss=501.8903 Time=0.0226\n",
      "Epoch 114, learning rate [0.005]\n",
      "[114:   0]: eps=0.50000000 Loss=369.5122 Robust_Loss=373.1610 Time=0.0467\n",
      "[114:  10]: eps=0.50000000 Loss=505.2763 Robust_Loss=512.3265 Time=0.0454\n",
      "[114:  20]: eps=0.50000000 Loss=520.7007 Robust_Loss=527.1655 Time=0.0447\n",
      "[114:  25]: eps=0.50000000 Loss=511.5042 Robust_Loss=517.5070 Time=0.0441\n",
      "Epoch time: 1.1730, Total time: 38.7202\n",
      "Evaluating...\n",
      "[114:   6]: eps=0.50000000 Loss=494.9842 Robust_Loss=501.5604 Time=0.0235\n",
      "Epoch 115, learning rate [0.005]\n",
      "[115:   0]: eps=0.50000000 Loss=456.4936 Robust_Loss=458.1125 Time=0.0399\n",
      "[115:  10]: eps=0.50000000 Loss=522.0886 Robust_Loss=527.5641 Time=0.0407\n",
      "[115:  20]: eps=0.50000000 Loss=508.0496 Robust_Loss=513.3379 Time=0.0401\n",
      "[115:  25]: eps=0.50000000 Loss=511.9691 Robust_Loss=517.2329 Time=0.0396\n",
      "Epoch time: 1.0472, Total time: 39.7674\n",
      "Evaluating...\n",
      "[115:   6]: eps=0.50000000 Loss=495.5506 Robust_Loss=501.3263 Time=0.0220\n",
      "Epoch 116, learning rate [0.005]\n",
      "[116:   0]: eps=0.50000000 Loss=423.1423 Robust_Loss=429.3063 Time=0.0426\n",
      "[116:  10]: eps=0.50000000 Loss=499.1852 Robust_Loss=504.1821 Time=0.0425\n",
      "[116:  20]: eps=0.50000000 Loss=512.3363 Robust_Loss=517.1581 Time=0.0419\n",
      "[116:  25]: eps=0.50000000 Loss=509.4585 Robust_Loss=514.1818 Time=0.0407\n",
      "Epoch time: 1.0788, Total time: 40.8462\n",
      "Evaluating...\n",
      "[116:   6]: eps=0.50000000 Loss=496.0562 Robust_Loss=501.1511 Time=0.0226\n",
      "Epoch 117, learning rate [0.005]\n",
      "[117:   0]: eps=0.50000000 Loss=536.0101 Robust_Loss=542.8015 Time=0.0480\n",
      "[117:  10]: eps=0.50000000 Loss=504.0434 Robust_Loss=509.1801 Time=0.0460\n",
      "[117:  20]: eps=0.50000000 Loss=523.1258 Robust_Loss=527.8635 Time=0.0463\n",
      "[117:  25]: eps=0.50000000 Loss=514.4859 Robust_Loss=518.7457 Time=0.0448\n",
      "Epoch time: 1.1927, Total time: 42.0389\n",
      "Evaluating...\n",
      "[117:   6]: eps=0.50000000 Loss=496.5235 Robust_Loss=501.0156 Time=0.0250\n",
      "Epoch 118, learning rate [0.005]\n",
      "[118:   0]: eps=0.50000000 Loss=425.9440 Robust_Loss=429.3352 Time=0.0447\n",
      "[118:  10]: eps=0.50000000 Loss=500.1660 Robust_Loss=503.8764 Time=0.0431\n",
      "[118:  20]: eps=0.50000000 Loss=510.2019 Robust_Loss=514.2060 Time=0.0437\n",
      "[118:  25]: eps=0.50000000 Loss=510.1161 Robust_Loss=513.9239 Time=0.0431\n",
      "Epoch time: 1.1404, Total time: 43.1793\n",
      "Evaluating...\n",
      "[118:   6]: eps=0.50000000 Loss=496.9428 Robust_Loss=500.9083 Time=0.0253\n",
      "Epoch 119, learning rate [0.005]\n",
      "[119:   0]: eps=0.50000000 Loss=482.6136 Robust_Loss=486.1266 Time=0.0430\n",
      "[119:  10]: eps=0.50000000 Loss=472.8998 Robust_Loss=475.5408 Time=0.0433\n",
      "[119:  20]: eps=0.50000000 Loss=494.6068 Robust_Loss=497.9062 Time=0.0435\n",
      "[119:  25]: eps=0.50000000 Loss=512.2499 Robust_Loss=515.6611 Time=0.0419\n",
      "Epoch time: 1.1125, Total time: 44.2917\n",
      "Evaluating...\n",
      "[119:   6]: eps=0.50000000 Loss=497.3247 Robust_Loss=500.8204 Time=0.0244\n",
      "Epoch 120, learning rate [0.005]\n",
      "[120:   0]: eps=0.50000000 Loss=426.9402 Robust_Loss=428.8705 Time=0.0372\n",
      "[120:  10]: eps=0.50000000 Loss=482.3364 Robust_Loss=485.6967 Time=0.0400\n",
      "[120:  20]: eps=0.50000000 Loss=507.0216 Robust_Loss=509.9384 Time=0.0444\n",
      "[120:  25]: eps=0.50000000 Loss=513.4262 Robust_Loss=516.5083 Time=0.0444\n",
      "Epoch time: 1.1703, Total time: 45.4620\n",
      "Evaluating...\n",
      "[120:   6]: eps=0.50000000 Loss=497.6521 Robust_Loss=500.7475 Time=0.0218\n",
      "Epoch 121, learning rate [0.005]\n",
      "[121:   0]: eps=0.50000000 Loss=653.0344 Robust_Loss=656.2300 Time=0.0430\n",
      "[121:  10]: eps=0.50000000 Loss=501.1793 Robust_Loss=503.6491 Time=0.0441\n",
      "[121:  20]: eps=0.50000000 Loss=522.3008 Robust_Loss=524.7348 Time=0.0450\n",
      "[121:  25]: eps=0.50000000 Loss=512.7232 Robust_Loss=515.4898 Time=0.0449\n",
      "Epoch time: 1.1859, Total time: 46.6480\n",
      "Evaluating...\n",
      "[121:   6]: eps=0.50000000 Loss=497.9456 Robust_Loss=500.6858 Time=0.0239\n",
      "Epoch 122, learning rate [0.005]\n",
      "[122:   0]: eps=0.50000000 Loss=563.8383 Robust_Loss=570.9407 Time=0.0440\n",
      "[122:  10]: eps=0.50000000 Loss=529.2656 Robust_Loss=531.9737 Time=0.0464\n",
      "[122:  20]: eps=0.50000000 Loss=496.4416 Robust_Loss=498.9728 Time=0.0451\n",
      "[122:  25]: eps=0.50000000 Loss=511.0310 Robust_Loss=513.5378 Time=0.0437\n",
      "Epoch time: 1.1555, Total time: 47.8035\n",
      "Evaluating...\n",
      "[122:   6]: eps=0.50000000 Loss=498.1139 Robust_Loss=500.6330 Time=0.0276\n",
      "Epoch 123, learning rate [0.005]\n",
      "[123:   0]: eps=0.50000000 Loss=681.8772 Robust_Loss=684.8157 Time=0.0433\n",
      "[123:  10]: eps=0.50000000 Loss=550.2190 Robust_Loss=552.7016 Time=0.0479\n",
      "[123:  20]: eps=0.50000000 Loss=528.9077 Robust_Loss=531.4414 Time=0.0458\n",
      "[123:  25]: eps=0.50000000 Loss=513.9421 Robust_Loss=516.3394 Time=0.0441\n",
      "Epoch time: 1.1666, Total time: 48.9700\n",
      "Evaluating...\n",
      "[123:   6]: eps=0.50000000 Loss=498.2820 Robust_Loss=500.5876 Time=0.0232\n",
      "Epoch 124, learning rate [0.005]\n",
      "[124:   0]: eps=0.50000000 Loss=370.5562 Robust_Loss=371.0743 Time=0.0456\n",
      "[124:  10]: eps=0.50000000 Loss=475.3175 Robust_Loss=477.6498 Time=0.0465\n",
      "[124:  20]: eps=0.50000000 Loss=500.7770 Robust_Loss=502.9728 Time=0.0487\n",
      "[124:  25]: eps=0.50000000 Loss=513.0930 Robust_Loss=515.3246 Time=0.0467\n",
      "Epoch time: 1.2439, Total time: 50.2139\n",
      "Evaluating...\n",
      "[124:   6]: eps=0.50000000 Loss=498.4062 Robust_Loss=500.5478 Time=0.0233\n",
      "Epoch 125, learning rate [0.0049005]\n",
      "[125:   0]: eps=0.50000000 Loss=538.1581 Robust_Loss=542.4461 Time=0.0434\n",
      "[125:  10]: eps=0.50000000 Loss=527.0588 Robust_Loss=529.2392 Time=0.0425\n",
      "[125:  20]: eps=0.50000000 Loss=541.4245 Robust_Loss=543.4943 Time=0.0445\n",
      "[125:  25]: eps=0.50000000 Loss=516.0327 Robust_Loss=518.1274 Time=0.0434\n",
      "Epoch time: 1.1559, Total time: 51.3698\n",
      "Evaluating...\n",
      "[125:   6]: eps=0.50000000 Loss=498.5064 Robust_Loss=500.5139 Time=0.0265\n",
      "Epoch 126, learning rate [0.00495]\n",
      "[126:   0]: eps=0.50000000 Loss=456.6513 Robust_Loss=456.9683 Time=0.0431\n",
      "[126:  10]: eps=0.50000000 Loss=538.1752 Robust_Loss=539.5927 Time=0.0429\n",
      "[126:  20]: eps=0.50000000 Loss=537.5612 Robust_Loss=539.4481 Time=0.0450\n",
      "[126:  25]: eps=0.50000000 Loss=515.1858 Robust_Loss=517.1515 Time=0.0444\n",
      "Epoch time: 1.1723, Total time: 52.5421\n",
      "Evaluating...\n",
      "[126:   6]: eps=0.50000000 Loss=498.5956 Robust_Loss=500.4828 Time=0.0258\n",
      "Epoch 127, learning rate [0.00495]\n",
      "[127:   0]: eps=0.50000000 Loss=454.6422 Robust_Loss=456.8530 Time=0.0475\n",
      "[127:  10]: eps=0.50000000 Loss=498.9741 Robust_Loss=500.7417 Time=0.0406\n",
      "[127:  20]: eps=0.50000000 Loss=506.3986 Robust_Loss=508.2773 Time=0.0429\n",
      "[127:  25]: eps=0.50000000 Loss=514.3799 Robust_Loss=516.1961 Time=0.0421\n",
      "Epoch time: 1.1198, Total time: 53.6620\n",
      "Evaluating...\n",
      "[127:   6]: eps=0.50000000 Loss=498.6548 Robust_Loss=500.4556 Time=0.0221\n",
      "Epoch 128, learning rate [0.00495]\n",
      "[128:   0]: eps=0.50000000 Loss=541.6705 Robust_Loss=542.2540 Time=0.0475\n",
      "[128:  10]: eps=0.50000000 Loss=526.9789 Robust_Loss=529.0223 Time=0.0405\n",
      "[128:  20]: eps=0.50000000 Loss=517.3030 Robust_Loss=519.0031 Time=0.0423\n",
      "[128:  25]: eps=0.50000000 Loss=512.4494 Robust_Loss=514.2030 Time=0.0429\n",
      "Epoch time: 1.1339, Total time: 54.7958\n",
      "Evaluating...\n",
      "[128:   6]: eps=0.50000000 Loss=498.7140 Robust_Loss=500.4310 Time=0.0252\n",
      "Epoch 129, learning rate [0.00495]\n",
      "[129:   0]: eps=0.50000000 Loss=399.6400 Robust_Loss=399.8128 Time=0.0412\n",
      "[129:  10]: eps=0.50000000 Loss=527.5715 Robust_Loss=529.0227 Time=0.0431\n",
      "[129:  20]: eps=0.50000000 Loss=537.7075 Robust_Loss=539.3528 Time=0.0419\n",
      "[129:  25]: eps=0.50000000 Loss=514.4053 Robust_Loss=516.1369 Time=0.0416\n",
      "Epoch time: 1.0986, Total time: 55.8944\n",
      "Evaluating...\n",
      "[129:   6]: eps=0.50000000 Loss=498.7710 Robust_Loss=500.4089 Time=0.0236\n",
      "Epoch 130, learning rate [0.00495]\n",
      "[130:   0]: eps=0.50000000 Loss=513.6673 Robust_Loss=513.8356 Time=0.0436\n",
      "[130:  10]: eps=0.50000000 Loss=489.1616 Robust_Loss=490.2085 Time=0.0448\n",
      "[130:  20]: eps=0.50000000 Loss=518.5500 Robust_Loss=520.2603 Time=0.0433\n",
      "[130:  25]: eps=0.50000000 Loss=514.4169 Robust_Loss=516.0791 Time=0.0460\n",
      "Epoch time: 1.2232, Total time: 57.1176\n",
      "Evaluating...\n",
      "[130:   6]: eps=0.50000000 Loss=498.8285 Robust_Loss=500.3889 Time=0.0309\n",
      "Epoch 131, learning rate [0.00495]\n",
      "[131:   0]: eps=0.50000000 Loss=623.9560 Robust_Loss=626.6740 Time=0.0600\n",
      "[131:  10]: eps=0.50000000 Loss=506.4188 Robust_Loss=508.2796 Time=0.0516\n",
      "[131:  20]: eps=0.50000000 Loss=506.3952 Robust_Loss=508.1212 Time=0.0501\n",
      "[131:  25]: eps=0.50000000 Loss=512.6594 Robust_Loss=514.2080 Time=0.0487\n",
      "Epoch time: 1.2942, Total time: 58.4118\n",
      "Evaluating...\n",
      "[131:   6]: eps=0.50000000 Loss=498.8881 Robust_Loss=500.3708 Time=0.0230\n",
      "Epoch 132, learning rate [0.00495]\n",
      "[132:   0]: eps=0.50000000 Loss=371.4968 Robust_Loss=371.6810 Time=0.0456\n",
      "[132:  10]: eps=0.50000000 Loss=488.7447 Robust_Loss=490.3351 Time=0.0417\n",
      "[132:  20]: eps=0.50000000 Loss=517.3976 Robust_Loss=518.9268 Time=0.0443\n",
      "[132:  25]: eps=0.50000000 Loss=514.5064 Robust_Loss=516.0503 Time=0.0429\n",
      "Epoch time: 1.1409, Total time: 59.5527\n",
      "Evaluating...\n",
      "[132:   6]: eps=0.50000000 Loss=498.9348 Robust_Loss=500.3545 Time=0.0282\n",
      "Epoch 133, learning rate [0.00495]\n",
      "[133:   0]: eps=0.50000000 Loss=426.5841 Robust_Loss=428.2971 Time=0.0400\n",
      "[133:  10]: eps=0.50000000 Loss=514.8133 Robust_Loss=516.1657 Time=0.0432\n",
      "[133:  20]: eps=0.50000000 Loss=528.2244 Robust_Loss=529.8266 Time=0.0452\n",
      "[133:  25]: eps=0.50000000 Loss=514.5859 Robust_Loss=516.0770 Time=0.0443\n",
      "Epoch time: 1.1736, Total time: 60.7263\n",
      "Evaluating...\n",
      "[133:   6]: eps=0.50000000 Loss=498.9741 Robust_Loss=500.3393 Time=0.0245\n",
      "Epoch 134, learning rate [0.00495]\n",
      "[134:   0]: eps=0.50000000 Loss=540.1414 Robust_Loss=541.5454 Time=0.0386\n",
      "[134:  10]: eps=0.50000000 Loss=522.8869 Robust_Loss=523.7361 Time=0.0419\n",
      "[134:  20]: eps=0.50000000 Loss=513.3024 Robust_Loss=514.8195 Time=0.0452\n",
      "[134:  25]: eps=0.50000000 Loss=514.5863 Robust_Loss=516.0219 Time=0.0461\n",
      "Epoch time: 1.2846, Total time: 62.0109\n",
      "Evaluating...\n",
      "[134:   6]: eps=0.50000000 Loss=499.0144 Robust_Loss=500.3252 Time=0.0211\n",
      "Epoch 135, learning rate [0.00495]\n",
      "[135:   0]: eps=0.50000000 Loss=625.5190 Robust_Loss=627.1546 Time=0.0480\n",
      "[135:  10]: eps=0.50000000 Loss=522.1409 Robust_Loss=523.7912 Time=0.0493\n",
      "[135:  20]: eps=0.50000000 Loss=520.2769 Robust_Loss=521.6736 Time=0.0493\n",
      "[135:  25]: eps=0.50000000 Loss=513.6872 Robust_Loss=515.0760 Time=0.0467\n",
      "Epoch time: 1.2518, Total time: 63.2627\n",
      "Evaluating...\n",
      "[135:   6]: eps=0.50000000 Loss=499.0555 Robust_Loss=500.3124 Time=0.0228\n",
      "Epoch 136, learning rate [0.00495]\n",
      "[136:   0]: eps=0.50000000 Loss=395.6138 Robust_Loss=400.1838 Time=0.0400\n",
      "[136:  10]: eps=0.50000000 Loss=506.9628 Robust_Loss=508.2985 Time=0.0424\n",
      "[136:  20]: eps=0.50000000 Loss=509.2106 Robust_Loss=510.7353 Time=0.0462\n",
      "[136:  25]: eps=0.50000000 Loss=509.9381 Robust_Loss=511.2750 Time=0.0468\n",
      "Epoch time: 1.2443, Total time: 64.5070\n",
      "Evaluating...\n",
      "[136:   6]: eps=0.50000000 Loss=499.0953 Robust_Loss=500.3004 Time=0.0282\n",
      "Epoch 137, learning rate [0.00495]\n",
      "[137:   0]: eps=0.50000000 Loss=428.1145 Robust_Loss=428.2324 Time=0.0739\n",
      "[137:  10]: eps=0.50000000 Loss=520.0879 Robust_Loss=521.2379 Time=0.0543\n",
      "[137:  20]: eps=0.50000000 Loss=527.0348 Robust_Loss=528.4212 Time=0.0471\n",
      "[137:  25]: eps=0.50000000 Loss=515.6603 Robust_Loss=516.9482 Time=0.0456\n",
      "Epoch time: 1.2068, Total time: 65.7138\n",
      "Evaluating...\n",
      "[137:   6]: eps=0.50000000 Loss=499.1354 Robust_Loss=500.2893 Time=0.0232\n",
      "Epoch 138, learning rate [0.00495]\n",
      "[138:   0]: eps=0.50000000 Loss=283.3266 Robust_Loss=285.7625 Time=0.0554\n",
      "[138:  10]: eps=0.50000000 Loss=486.6057 Robust_Loss=487.5749 Time=0.0450\n",
      "[138:  20]: eps=0.50000000 Loss=510.9209 Robust_Loss=512.0761 Time=0.0431\n",
      "[138:  25]: eps=0.50000000 Loss=512.8353 Robust_Loss=514.0738 Time=0.0421\n",
      "Epoch time: 1.1253, Total time: 66.8391\n",
      "Evaluating...\n",
      "[138:   6]: eps=0.50000000 Loss=499.1762 Robust_Loss=500.2789 Time=0.0243\n",
      "Epoch 139, learning rate [0.00495]\n",
      "[139:   0]: eps=0.50000000 Loss=484.0751 Robust_Loss=485.0602 Time=0.0394\n",
      "[139:  10]: eps=0.50000000 Loss=491.2516 Robust_Loss=492.7163 Time=0.0437\n",
      "[139:  20]: eps=0.50000000 Loss=501.2808 Robust_Loss=502.6322 Time=0.0427\n",
      "[139:  25]: eps=0.50000000 Loss=511.9713 Robust_Loss=513.1671 Time=0.0414\n",
      "Epoch time: 1.1035, Total time: 67.9426\n",
      "Evaluating...\n",
      "[139:   6]: eps=0.50000000 Loss=499.2141 Robust_Loss=500.2695 Time=0.0197\n",
      "Epoch 140, learning rate [0.004851495]\n",
      "[140:   0]: eps=0.50000000 Loss=712.8096 Robust_Loss=712.9296 Time=0.0379\n",
      "[140:  10]: eps=0.50000000 Loss=522.8267 Robust_Loss=523.8463 Time=0.0426\n",
      "[140:  20]: eps=0.50000000 Loss=528.4890 Robust_Loss=529.6729 Time=0.0489\n",
      "[140:  25]: eps=0.50000000 Loss=513.8697 Robust_Loss=515.0183 Time=0.0478\n",
      "Epoch time: 1.2703, Total time: 69.2129\n",
      "Evaluating...\n",
      "[140:   6]: eps=0.50000000 Loss=499.2500 Robust_Loss=500.2606 Time=0.0235\n",
      "Epoch 141, learning rate [0.0049005]\n",
      "[141:   0]: eps=0.50000000 Loss=739.2912 Robust_Loss=740.6055 Time=0.0410\n",
      "[141:  10]: eps=0.50000000 Loss=512.7185 Robust_Loss=513.3885 Time=0.0462\n",
      "[141:  20]: eps=0.50000000 Loss=512.3188 Robust_Loss=513.4291 Time=0.0468\n",
      "[141:  25]: eps=0.50000000 Loss=513.8897 Robust_Loss=514.9950 Time=0.0451\n",
      "Epoch time: 1.2010, Total time: 70.4139\n",
      "Evaluating...\n",
      "[141:   6]: eps=0.50000000 Loss=499.2869 Robust_Loss=500.2522 Time=0.0226\n",
      "Epoch 142, learning rate [0.0049005]\n",
      "[142:   0]: eps=0.50000000 Loss=426.9734 Robust_Loss=428.4188 Time=0.0376\n",
      "[142:  10]: eps=0.50000000 Loss=551.4210 Robust_Loss=552.3538 Time=0.0409\n",
      "[142:  20]: eps=0.50000000 Loss=524.5836 Robust_Loss=525.6540 Time=0.0403\n",
      "[142:  25]: eps=0.50000000 Loss=513.9533 Robust_Loss=515.0180 Time=0.0397\n",
      "Epoch time: 1.0578, Total time: 71.4717\n",
      "Evaluating...\n",
      "[142:   6]: eps=0.50000000 Loss=499.3228 Robust_Loss=500.2444 Time=0.0220\n",
      "Epoch 143, learning rate [0.0049005]\n",
      "[143:   0]: eps=0.50000000 Loss=455.5258 Robust_Loss=456.9000 Time=0.0435\n",
      "[143:  10]: eps=0.50000000 Loss=458.1472 Robust_Loss=459.2061 Time=0.0489\n",
      "[143:  20]: eps=0.50000000 Loss=513.7945 Robust_Loss=514.7375 Time=0.0460\n",
      "[143:  25]: eps=0.50000000 Loss=514.9194 Robust_Loss=515.9421 Time=0.0465\n",
      "Epoch time: 1.2415, Total time: 72.7132\n",
      "Evaluating...\n",
      "[143:   6]: eps=0.50000000 Loss=499.3579 Robust_Loss=500.2370 Time=0.0223\n",
      "Epoch 144, learning rate [0.0049005]\n",
      "[144:   0]: eps=0.50000000 Loss=655.5884 Robust_Loss=655.6946 Time=0.0487\n",
      "[144:  10]: eps=0.50000000 Loss=502.4120 Robust_Loss=503.1361 Time=0.0461\n",
      "[144:  20]: eps=0.50000000 Loss=513.8255 Robust_Loss=514.7535 Time=0.0446\n",
      "[144:  25]: eps=0.50000000 Loss=513.0655 Robust_Loss=514.0265 Time=0.0442\n",
      "Epoch time: 1.1727, Total time: 73.8859\n",
      "Evaluating...\n",
      "[144:   6]: eps=0.50000000 Loss=499.3925 Robust_Loss=500.2301 Time=0.0200\n",
      "Epoch 145, learning rate [0.0049005]\n",
      "[145:   0]: eps=0.50000000 Loss=510.5067 Robust_Loss=513.0972 Time=0.0393\n",
      "[145:  10]: eps=0.50000000 Loss=537.9279 Robust_Loss=539.0960 Time=0.0393\n",
      "[145:  20]: eps=0.50000000 Loss=539.4290 Robust_Loss=540.4383 Time=0.0421\n",
      "[145:  25]: eps=0.50000000 Loss=514.9320 Robust_Loss=515.8792 Time=0.0435\n",
      "Epoch time: 1.1589, Total time: 75.0449\n",
      "Evaluating...\n",
      "[145:   6]: eps=0.50000000 Loss=499.4261 Robust_Loss=500.2236 Time=0.0217\n",
      "Epoch 146, learning rate [0.0049005]\n",
      "[146:   0]: eps=0.50000000 Loss=371.2182 Robust_Loss=371.2956 Time=0.0392\n",
      "[146:  10]: eps=0.50000000 Loss=499.9440 Robust_Loss=500.5539 Time=0.0450\n",
      "[146:  20]: eps=0.50000000 Loss=511.0835 Robust_Loss=512.0505 Time=0.0425\n",
      "[146:  25]: eps=0.50000000 Loss=515.9907 Robust_Loss=516.8966 Time=0.0412\n",
      "Epoch time: 1.0957, Total time: 76.1406\n",
      "Evaluating...\n",
      "[146:   6]: eps=0.50000000 Loss=499.4593 Robust_Loss=500.2174 Time=0.0210\n",
      "Epoch 147, learning rate [0.0049005]\n",
      "[147:   0]: eps=0.50000000 Loss=623.4964 Robust_Loss=626.8158 Time=0.0408\n",
      "[147:  10]: eps=0.50000000 Loss=478.6551 Robust_Loss=479.7097 Time=0.0389\n",
      "[147:  20]: eps=0.50000000 Loss=516.5622 Robust_Loss=517.4181 Time=0.0419\n",
      "[147:  25]: eps=0.50000000 Loss=514.0746 Robust_Loss=514.9440 Time=0.0414\n",
      "Epoch time: 1.1019, Total time: 77.2425\n",
      "Evaluating...\n",
      "[147:   6]: eps=0.50000000 Loss=499.4928 Robust_Loss=500.2116 Time=0.0229\n",
      "Epoch 148, learning rate [0.0049005]\n",
      "[148:   0]: eps=0.50000000 Loss=711.1171 Robust_Loss=712.2725 Time=0.0425\n",
      "[148:  10]: eps=0.50000000 Loss=543.6580 Robust_Loss=544.5112 Time=0.0449\n",
      "[148:  20]: eps=0.50000000 Loss=516.5811 Robust_Loss=517.4918 Time=0.0422\n",
      "[148:  25]: eps=0.50000000 Loss=510.3824 Robust_Loss=511.2150 Time=0.0404\n",
      "Epoch time: 1.0747, Total time: 78.3171\n",
      "Evaluating...\n",
      "[148:   6]: eps=0.50000000 Loss=499.5252 Robust_Loss=500.2061 Time=0.0197\n",
      "Epoch 149, learning rate [0.0049005]\n",
      "[149:   0]: eps=0.50000000 Loss=682.5171 Robust_Loss=683.9725 Time=0.0399\n",
      "[149:  10]: eps=0.50000000 Loss=494.6175 Robust_Loss=495.3613 Time=0.0429\n",
      "[149:  20]: eps=0.50000000 Loss=523.3636 Robust_Loss=524.2075 Time=0.0417\n",
      "[149:  25]: eps=0.50000000 Loss=515.1053 Robust_Loss=515.9029 Time=0.0404\n",
      "Epoch time: 1.0811, Total time: 79.3983\n",
      "Evaluating...\n",
      "[149:   6]: eps=0.50000000 Loss=499.5563 Robust_Loss=500.2008 Time=0.0219\n",
      "Epoch 150, learning rate [0.0049005]\n",
      "[150:   0]: eps=0.50000000 Loss=342.6236 Robust_Loss=342.6984 Time=0.0447\n",
      "[150:  10]: eps=0.50000000 Loss=520.4515 Robust_Loss=521.1507 Time=0.0464\n",
      "[150:  20]: eps=0.50000000 Loss=512.6235 Robust_Loss=513.4057 Time=0.0467\n",
      "[150:  25]: eps=0.50000000 Loss=515.1648 Robust_Loss=515.9265 Time=0.0449\n",
      "Epoch time: 1.2010, Total time: 80.5993\n",
      "Evaluating...\n",
      "[150:   6]: eps=0.50000000 Loss=499.5891 Robust_Loss=500.1958 Time=0.0239\n"
     ]
    }
   ],
   "source": [
    "train_robust(model_robust_wrap,dataloader_train,dataloader_test,method=\"robust\",args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, learning rate [0.005]\n",
      "[ 1:   0]: eps=0.00000000 Loss=304177.4688 Time=0.0272\n",
      "[ 1:  10]: eps=0.00000000 Loss=145473.3310 Time=0.0112\n",
      "[ 1:  20]: eps=0.00000000 Loss=80142.1634 Time=0.0095\n",
      "[ 1:  25]: eps=0.00000000 Loss=66956.7883 Time=0.0090\n",
      "Epoch time: 0.2660, Total time: 0.2660\n",
      "Evaluating...\n",
      "[ 1:   6]: eps=0.00000000 Loss=321.6735 Time=0.0042\n",
      "Epoch 2, learning rate [0.005]\n",
      "[ 2:   0]: eps=0.00000000 Loss=287.2186 Time=0.0085\n",
      "[ 2:  10]: eps=0.00000000 Loss=253.7153 Time=0.0068\n",
      "[ 2:  20]: eps=0.00000000 Loss=233.9752 Time=0.0071\n",
      "[ 2:  25]: eps=0.00000000 Loss=232.0259 Time=0.0068\n",
      "Epoch time: 0.1942, Total time: 0.4602\n",
      "Evaluating...\n",
      "[ 2:   6]: eps=0.00000000 Loss=208.4452 Time=0.0047\n",
      "Epoch 3, learning rate [0.005]\n",
      "[ 3:   0]: eps=0.00000000 Loss=153.8224 Time=0.0101\n",
      "[ 3:  10]: eps=0.00000000 Loss=229.3283 Time=0.0077\n",
      "[ 3:  20]: eps=0.00000000 Loss=222.5834 Time=0.0072\n",
      "[ 3:  25]: eps=0.00000000 Loss=218.8052 Time=0.0070\n",
      "Epoch time: 0.2077, Total time: 0.6679\n",
      "Evaluating...\n",
      "[ 3:   6]: eps=0.00000000 Loss=208.0073 Time=0.0037\n",
      "Epoch 4, learning rate [0.005]\n",
      "[ 4:   0]: eps=0.00000000 Loss=228.0971 Time=0.0090\n",
      "[ 4:  10]: eps=0.00000000 Loss=227.2719 Time=0.0090\n",
      "[ 4:  20]: eps=0.00000000 Loss=223.3393 Time=0.0090\n",
      "[ 4:  25]: eps=0.00000000 Loss=216.2512 Time=0.0089\n",
      "Epoch time: 0.2517, Total time: 0.9196\n",
      "Evaluating...\n",
      "[ 4:   6]: eps=0.00000000 Loss=206.2152 Time=0.0051\n",
      "Epoch 5, learning rate [0.005]\n",
      "[ 5:   0]: eps=0.00000000 Loss=220.3362 Time=0.0098\n",
      "[ 5:  10]: eps=0.00000000 Loss=233.4678 Time=0.0093\n",
      "[ 5:  20]: eps=0.00000000 Loss=221.6677 Time=0.0089\n",
      "[ 5:  25]: eps=0.00000000 Loss=215.9041 Time=0.0088\n",
      "Epoch time: 0.2575, Total time: 1.1771\n",
      "Evaluating...\n",
      "[ 5:   6]: eps=0.00000000 Loss=204.4034 Time=0.0039\n",
      "Epoch 6, learning rate [0.005]\n",
      "[ 6:   0]: eps=0.00000000 Loss=179.0457 Time=0.0080\n",
      "[ 6:  10]: eps=0.00000000 Loss=227.2233 Time=0.0074\n",
      "[ 6:  20]: eps=0.00000000 Loss=219.8678 Time=0.0073\n",
      "[ 6:  25]: eps=0.00000000 Loss=214.8955 Time=0.0073\n",
      "Epoch time: 0.2047, Total time: 1.3818\n",
      "Evaluating...\n",
      "[ 6:   6]: eps=0.00000000 Loss=202.6716 Time=0.0046\n",
      "Epoch 7, learning rate [0.005]\n",
      "[ 7:   0]: eps=0.00000000 Loss=156.4897 Time=0.0080\n",
      "[ 7:  10]: eps=0.00000000 Loss=202.0227 Time=0.0069\n",
      "[ 7:  20]: eps=0.00000000 Loss=210.0779 Time=0.0065\n",
      "[ 7:  25]: eps=0.00000000 Loss=213.5018 Time=0.0064\n",
      "Epoch time: 0.1842, Total time: 1.5660\n",
      "Evaluating...\n",
      "[ 7:   6]: eps=0.00000000 Loss=201.1802 Time=0.0045\n",
      "Epoch 8, learning rate [0.005]\n",
      "[ 8:   0]: eps=0.00000000 Loss=189.6423 Time=0.0072\n",
      "[ 8:  10]: eps=0.00000000 Loss=212.3760 Time=0.0093\n",
      "[ 8:  20]: eps=0.00000000 Loss=211.1926 Time=0.0092\n",
      "[ 8:  25]: eps=0.00000000 Loss=212.1622 Time=0.0086\n",
      "Epoch time: 0.3126, Total time: 1.8785\n",
      "Evaluating...\n",
      "[ 8:   6]: eps=0.00000000 Loss=199.9750 Time=0.0049\n",
      "Epoch 9, learning rate [0.005]\n",
      "[ 9:   0]: eps=0.00000000 Loss=246.6397 Time=0.0085\n",
      "[ 9:  10]: eps=0.00000000 Loss=197.6040 Time=0.0072\n",
      "[ 9:  20]: eps=0.00000000 Loss=212.4363 Time=0.0071\n",
      "[ 9:  25]: eps=0.00000000 Loss=212.0938 Time=0.0072\n",
      "Epoch time: 0.2121, Total time: 2.0907\n",
      "Evaluating...\n",
      "[ 9:   6]: eps=0.00000000 Loss=198.7930 Time=0.0046\n",
      "Epoch 10, learning rate [0.005]\n",
      "[10:   0]: eps=0.00000000 Loss=217.1848 Time=0.0088\n",
      "[10:  10]: eps=0.00000000 Loss=219.3895 Time=0.0078\n",
      "[10:  20]: eps=0.00000000 Loss=213.7606 Time=0.0075\n",
      "[10:  25]: eps=0.00000000 Loss=209.1728 Time=0.0071\n",
      "Epoch time: 0.2040, Total time: 2.2946\n",
      "Evaluating...\n",
      "[10:   6]: eps=0.00000000 Loss=197.8981 Time=0.0039\n",
      "Epoch 11, learning rate [0.005]\n",
      "[11:   0]: eps=0.00000000 Loss=167.5222 Time=0.0081\n",
      "[11:  10]: eps=0.00000000 Loss=205.7761 Time=0.0068\n",
      "[11:  20]: eps=0.00000000 Loss=209.9079 Time=0.0070\n",
      "[11:  25]: eps=0.00000000 Loss=208.6739 Time=0.0071\n",
      "Epoch time: 0.2059, Total time: 2.5006\n",
      "Evaluating...\n",
      "[11:   6]: eps=0.00000000 Loss=197.2501 Time=0.0052\n",
      "Epoch 12, learning rate [0.005]\n",
      "[12:   0]: eps=0.00000000 Loss=255.8123 Time=0.0098\n",
      "[12:  10]: eps=0.00000000 Loss=215.7356 Time=0.0086\n",
      "[12:  20]: eps=0.00000000 Loss=217.1154 Time=0.0092\n",
      "[12:  25]: eps=0.00000000 Loss=208.7612 Time=0.0092\n",
      "Epoch time: 0.2659, Total time: 2.7665\n",
      "Evaluating...\n",
      "[12:   6]: eps=0.00000000 Loss=196.5970 Time=0.0048\n",
      "Epoch 13, learning rate [0.005]\n",
      "[13:   0]: eps=0.00000000 Loss=176.9258 Time=0.0070\n",
      "[13:  10]: eps=0.00000000 Loss=202.1194 Time=0.0076\n",
      "[13:  20]: eps=0.00000000 Loss=213.3840 Time=0.0074\n",
      "[13:  25]: eps=0.00000000 Loss=207.7736 Time=0.0075\n",
      "Epoch time: 0.2176, Total time: 2.9841\n",
      "Evaluating...\n",
      "[13:   6]: eps=0.00000000 Loss=196.1942 Time=0.0051\n",
      "Epoch 14, learning rate [0.005]\n",
      "[14:   0]: eps=0.00000000 Loss=226.8786 Time=0.0089\n",
      "[14:  10]: eps=0.00000000 Loss=205.7978 Time=0.0072\n",
      "[14:  20]: eps=0.00000000 Loss=205.8665 Time=0.0081\n",
      "[14:  25]: eps=0.00000000 Loss=206.7564 Time=0.0081\n",
      "Epoch time: 0.2346, Total time: 3.2187\n",
      "Evaluating...\n",
      "[14:   6]: eps=0.00000000 Loss=195.7674 Time=0.0041\n",
      "Epoch 15, learning rate [0.005]\n",
      "[15:   0]: eps=0.00000000 Loss=200.6353 Time=0.0060\n",
      "[15:  10]: eps=0.00000000 Loss=203.8945 Time=0.0069\n",
      "[15:  20]: eps=0.00000000 Loss=209.0309 Time=0.0069\n",
      "[15:  25]: eps=0.00000000 Loss=206.4489 Time=0.0068\n",
      "Epoch time: 0.1984, Total time: 3.4171\n",
      "Evaluating...\n",
      "[15:   6]: eps=0.00000000 Loss=195.3767 Time=0.0042\n",
      "Epoch 16, learning rate [0.005]\n",
      "[16:   0]: eps=0.00000000 Loss=224.3549 Time=0.0062\n",
      "[16:  10]: eps=0.00000000 Loss=208.2368 Time=0.0070\n",
      "[16:  20]: eps=0.00000000 Loss=206.8654 Time=0.0074\n",
      "[16:  25]: eps=0.00000000 Loss=206.3916 Time=0.0075\n",
      "Epoch time: 0.2144, Total time: 3.6315\n",
      "Evaluating...\n",
      "[16:   6]: eps=0.00000000 Loss=195.0785 Time=0.0064\n",
      "Epoch 17, learning rate [0.005]\n",
      "[17:   0]: eps=0.00000000 Loss=221.9164 Time=0.0114\n",
      "[17:  10]: eps=0.00000000 Loss=205.8185 Time=0.0071\n",
      "[17:  20]: eps=0.00000000 Loss=206.4244 Time=0.0074\n",
      "[17:  25]: eps=0.00000000 Loss=206.1846 Time=0.0072\n",
      "Epoch time: 0.2018, Total time: 3.8333\n",
      "Evaluating...\n",
      "[17:   6]: eps=0.00000000 Loss=194.7674 Time=0.0041\n",
      "Epoch 18, learning rate [0.005]\n",
      "[18:   0]: eps=0.00000000 Loss=135.9553 Time=0.0082\n",
      "[18:  10]: eps=0.00000000 Loss=214.2381 Time=0.0079\n",
      "[18:  20]: eps=0.00000000 Loss=208.8668 Time=0.0084\n",
      "[18:  25]: eps=0.00000000 Loss=204.9694 Time=0.0087\n",
      "Epoch time: 0.2394, Total time: 4.0727\n",
      "Evaluating...\n",
      "[18:   6]: eps=0.00000000 Loss=194.3761 Time=0.0061\n",
      "Epoch 19, learning rate [0.005]\n",
      "[19:   0]: eps=0.00000000 Loss=333.9011 Time=0.0113\n",
      "[19:  10]: eps=0.00000000 Loss=214.1955 Time=0.0080\n",
      "[19:  20]: eps=0.00000000 Loss=211.9797 Time=0.0091\n",
      "[19:  25]: eps=0.00000000 Loss=204.1650 Time=0.0090\n",
      "Epoch time: 0.2647, Total time: 4.3375\n",
      "Evaluating...\n",
      "[19:   6]: eps=0.00000000 Loss=194.2822 Time=0.0048\n",
      "Epoch 20, learning rate [0.005]\n",
      "[20:   0]: eps=0.00000000 Loss=146.5313 Time=0.0070\n",
      "[20:  10]: eps=0.00000000 Loss=194.0194 Time=0.0065\n",
      "[20:  20]: eps=0.00000000 Loss=207.4907 Time=0.0065\n",
      "[20:  25]: eps=0.00000000 Loss=204.4656 Time=0.0065\n",
      "Epoch time: 0.1818, Total time: 4.5192\n",
      "Evaluating...\n",
      "[20:   6]: eps=0.00000000 Loss=194.1001 Time=0.0042\n",
      "Epoch 21, learning rate [0.005]\n",
      "[21:   0]: eps=0.00000000 Loss=170.0672 Time=0.0060\n",
      "[21:  10]: eps=0.00000000 Loss=179.1042 Time=0.0061\n",
      "[21:  20]: eps=0.00000000 Loss=194.4327 Time=0.0060\n",
      "[21:  25]: eps=0.00000000 Loss=202.8475 Time=0.0060\n",
      "Epoch time: 0.1733, Total time: 4.6925\n",
      "Evaluating...\n",
      "[21:   6]: eps=0.00000000 Loss=193.9610 Time=0.0039\n",
      "Epoch 22, learning rate [0.005]\n",
      "[22:   0]: eps=0.00000000 Loss=194.9812 Time=0.0059\n",
      "[22:  10]: eps=0.00000000 Loss=188.7331 Time=0.0066\n",
      "[22:  20]: eps=0.00000000 Loss=202.2927 Time=0.0075\n",
      "[22:  25]: eps=0.00000000 Loss=203.7102 Time=0.0071\n",
      "Epoch time: 0.2091, Total time: 4.9016\n",
      "Evaluating...\n",
      "[22:   6]: eps=0.00000000 Loss=193.6276 Time=0.0038\n",
      "Epoch 23, learning rate [0.005]\n",
      "[23:   0]: eps=0.00000000 Loss=178.1960 Time=0.0073\n",
      "[23:  10]: eps=0.00000000 Loss=203.4777 Time=0.0068\n",
      "[23:  20]: eps=0.00000000 Loss=204.8545 Time=0.0067\n",
      "[23:  25]: eps=0.00000000 Loss=203.1818 Time=0.0065\n",
      "Epoch time: 0.1850, Total time: 5.0867\n",
      "Evaluating...\n",
      "[23:   6]: eps=0.00000000 Loss=193.6895 Time=0.0047\n",
      "Epoch 24, learning rate [0.005]\n",
      "[24:   0]: eps=0.00000000 Loss=239.9218 Time=0.0081\n",
      "[24:  10]: eps=0.00000000 Loss=204.6936 Time=0.0071\n",
      "[24:  20]: eps=0.00000000 Loss=202.9481 Time=0.0081\n",
      "[24:  25]: eps=0.00000000 Loss=203.2796 Time=0.0076\n",
      "Epoch time: 0.2220, Total time: 5.3087\n",
      "Evaluating...\n",
      "[24:   6]: eps=0.00000000 Loss=193.4323 Time=0.0040\n",
      "Epoch 25, learning rate [0.005]\n",
      "[25:   0]: eps=0.00000000 Loss=234.7846 Time=0.0073\n",
      "[25:  10]: eps=0.00000000 Loss=192.9571 Time=0.0067\n",
      "[25:  20]: eps=0.00000000 Loss=198.5925 Time=0.0066\n",
      "[25:  25]: eps=0.00000000 Loss=201.7953 Time=0.0066\n",
      "Epoch time: 0.1850, Total time: 5.4937\n",
      "Evaluating...\n",
      "[25:   6]: eps=0.00000000 Loss=193.3723 Time=0.0035\n",
      "Epoch 26, learning rate [0.005]\n",
      "[26:   0]: eps=0.00000000 Loss=162.2325 Time=0.0063\n",
      "[26:  10]: eps=0.00000000 Loss=200.7464 Time=0.0068\n",
      "[26:  20]: eps=0.00000000 Loss=203.5653 Time=0.0067\n",
      "[26:  25]: eps=0.00000000 Loss=201.9604 Time=0.0076\n",
      "Epoch time: 0.2198, Total time: 5.7135\n",
      "Evaluating...\n",
      "[26:   6]: eps=0.00000000 Loss=193.4291 Time=0.0056\n",
      "Epoch 27, learning rate [0.005]\n",
      "[27:   0]: eps=0.00000000 Loss=196.2491 Time=0.0070\n",
      "[27:  10]: eps=0.00000000 Loss=208.6633 Time=0.0065\n",
      "[27:  20]: eps=0.00000000 Loss=207.2307 Time=0.0065\n",
      "[27:  25]: eps=0.00000000 Loss=201.8563 Time=0.0071\n",
      "Epoch time: 0.2050, Total time: 5.9184\n",
      "Evaluating...\n",
      "[27:   6]: eps=0.00000000 Loss=193.1063 Time=0.0044\n",
      "Epoch 28, learning rate [0.005]\n",
      "[28:   0]: eps=0.00000000 Loss=213.5605 Time=0.0071\n",
      "[28:  10]: eps=0.00000000 Loss=206.0770 Time=0.0076\n",
      "[28:  20]: eps=0.00000000 Loss=205.4000 Time=0.0074\n",
      "[28:  25]: eps=0.00000000 Loss=202.4269 Time=0.0080\n",
      "Epoch time: 0.2284, Total time: 6.1468\n",
      "Evaluating...\n",
      "[28:   6]: eps=0.00000000 Loss=193.2239 Time=0.0074\n",
      "Epoch 29, learning rate [0.005]\n",
      "[29:   0]: eps=0.00000000 Loss=115.4739 Time=0.0072\n",
      "[29:  10]: eps=0.00000000 Loss=198.4971 Time=0.0069\n",
      "[29:  20]: eps=0.00000000 Loss=200.1909 Time=0.0068\n",
      "[29:  25]: eps=0.00000000 Loss=201.5981 Time=0.0070\n",
      "Epoch time: 0.2050, Total time: 6.3517\n",
      "Evaluating...\n",
      "[29:   6]: eps=0.00000000 Loss=193.1471 Time=0.0047\n",
      "Epoch 30, learning rate [0.005]\n",
      "[30:   0]: eps=0.00000000 Loss=233.2256 Time=0.0151\n",
      "[30:  10]: eps=0.00000000 Loss=198.4303 Time=0.0068\n",
      "[30:  20]: eps=0.00000000 Loss=197.7688 Time=0.0068\n",
      "[30:  25]: eps=0.00000000 Loss=202.1309 Time=0.0065\n",
      "Epoch time: 0.1855, Total time: 6.5372\n",
      "Evaluating...\n",
      "[30:   6]: eps=0.00000000 Loss=192.9747 Time=0.0037\n",
      "Epoch 31, learning rate [0.005]\n",
      "[31:   0]: eps=0.00000000 Loss=153.1304 Time=0.0064\n",
      "[31:  10]: eps=0.00000000 Loss=206.9511 Time=0.0066\n",
      "[31:  20]: eps=0.00000000 Loss=204.7484 Time=0.0068\n",
      "[31:  25]: eps=0.00000000 Loss=202.6008 Time=0.0069\n",
      "Epoch time: 0.2025, Total time: 6.7398\n",
      "Evaluating...\n",
      "[31:   6]: eps=0.00000000 Loss=192.8611 Time=0.0045\n",
      "Epoch 32, learning rate [0.005]\n",
      "[32:   0]: eps=0.00000000 Loss=190.5451 Time=0.0088\n",
      "[32:  10]: eps=0.00000000 Loss=214.6956 Time=0.0071\n",
      "[32:  20]: eps=0.00000000 Loss=208.6574 Time=0.0072\n",
      "[32:  25]: eps=0.00000000 Loss=200.7533 Time=0.0071\n",
      "Epoch time: 0.2037, Total time: 6.9434\n",
      "Evaluating...\n",
      "[32:   6]: eps=0.00000000 Loss=192.9766 Time=0.0042\n",
      "Epoch 33, learning rate [0.005]\n",
      "[33:   0]: eps=0.00000000 Loss=276.1053 Time=0.0066\n",
      "[33:  10]: eps=0.00000000 Loss=216.5528 Time=0.0065\n",
      "[33:  20]: eps=0.00000000 Loss=207.0854 Time=0.0065\n",
      "[33:  25]: eps=0.00000000 Loss=202.0268 Time=0.0065\n",
      "Epoch time: 0.1834, Total time: 7.1268\n",
      "Evaluating...\n",
      "[33:   6]: eps=0.00000000 Loss=192.6910 Time=0.0041\n",
      "Epoch 34, learning rate [0.005]\n",
      "[34:   0]: eps=0.00000000 Loss=206.1204 Time=0.0060\n",
      "[34:  10]: eps=0.00000000 Loss=206.5540 Time=0.0088\n",
      "[34:  20]: eps=0.00000000 Loss=203.6023 Time=0.0083\n",
      "[34:  25]: eps=0.00000000 Loss=200.4682 Time=0.0080\n",
      "Epoch time: 0.2359, Total time: 7.3627\n",
      "Evaluating...\n",
      "[34:   6]: eps=0.00000000 Loss=192.7108 Time=0.0051\n",
      "Epoch 35, learning rate [0.005]\n",
      "[35:   0]: eps=0.00000000 Loss=179.6264 Time=0.0102\n",
      "[35:  10]: eps=0.00000000 Loss=215.4997 Time=0.0087\n",
      "[35:  20]: eps=0.00000000 Loss=204.7555 Time=0.0079\n",
      "[35:  25]: eps=0.00000000 Loss=200.4076 Time=0.0077\n",
      "Epoch time: 0.2187, Total time: 7.5814\n",
      "Evaluating...\n",
      "[35:   6]: eps=0.00000000 Loss=192.8086 Time=0.0034\n",
      "Epoch 36, learning rate [0.005]\n",
      "[36:   0]: eps=0.00000000 Loss=218.5102 Time=0.0071\n",
      "[36:  10]: eps=0.00000000 Loss=204.3448 Time=0.0068\n",
      "[36:  20]: eps=0.00000000 Loss=198.2149 Time=0.0069\n",
      "[36:  25]: eps=0.00000000 Loss=200.7048 Time=0.0067\n",
      "Epoch time: 0.1931, Total time: 7.7745\n",
      "Evaluating...\n",
      "[36:   6]: eps=0.00000000 Loss=192.6094 Time=0.0041\n",
      "Epoch 37, learning rate [0.005]\n",
      "[37:   0]: eps=0.00000000 Loss=128.4830 Time=0.0073\n",
      "[37:  10]: eps=0.00000000 Loss=208.2231 Time=0.0101\n",
      "[37:  20]: eps=0.00000000 Loss=202.3094 Time=0.0089\n",
      "[37:  25]: eps=0.00000000 Loss=201.0305 Time=0.0091\n",
      "Epoch time: 0.2631, Total time: 8.0376\n",
      "Evaluating...\n",
      "[37:   6]: eps=0.00000000 Loss=192.5762 Time=0.0049\n",
      "Epoch 38, learning rate [0.005]\n",
      "[38:   0]: eps=0.00000000 Loss=211.0947 Time=0.0070\n",
      "[38:  10]: eps=0.00000000 Loss=216.9029 Time=0.0064\n",
      "[38:  20]: eps=0.00000000 Loss=203.2802 Time=0.0070\n",
      "[38:  25]: eps=0.00000000 Loss=201.4132 Time=0.0076\n",
      "Epoch time: 0.2849, Total time: 8.3225\n",
      "Evaluating...\n",
      "[38:   6]: eps=0.00000000 Loss=192.5909 Time=0.0052\n",
      "Epoch 39, learning rate [0.005]\n",
      "[39:   0]: eps=0.00000000 Loss=137.5979 Time=0.0080\n",
      "[39:  10]: eps=0.00000000 Loss=191.8056 Time=0.0083\n",
      "[39:  20]: eps=0.00000000 Loss=200.6133 Time=0.0079\n",
      "[39:  25]: eps=0.00000000 Loss=200.5893 Time=0.0076\n",
      "Epoch time: 0.2190, Total time: 8.5415\n",
      "Evaluating...\n",
      "[39:   6]: eps=0.00000000 Loss=192.5666 Time=0.0044\n",
      "Epoch 40, learning rate [0.005]\n",
      "[40:   0]: eps=0.00000000 Loss=151.2317 Time=0.0070\n",
      "[40:  10]: eps=0.00000000 Loss=194.1507 Time=0.0073\n",
      "[40:  20]: eps=0.00000000 Loss=199.7649 Time=0.0068\n",
      "[40:  25]: eps=0.00000000 Loss=200.5105 Time=0.0073\n",
      "Epoch time: 0.2148, Total time: 8.7563\n",
      "Evaluating...\n",
      "[40:   6]: eps=0.00000000 Loss=192.2226 Time=0.0036\n",
      "Epoch 41, learning rate [0.005]\n",
      "[41:   0]: eps=0.00000000 Loss=181.7203 Time=0.0070\n",
      "[41:  10]: eps=0.00000000 Loss=189.2693 Time=0.0067\n",
      "[41:  20]: eps=0.00000000 Loss=203.3863 Time=0.0065\n",
      "[41:  25]: eps=0.00000000 Loss=200.1004 Time=0.0064\n",
      "Epoch time: 0.1776, Total time: 8.9339\n",
      "Evaluating...\n",
      "[41:   6]: eps=0.00000000 Loss=192.4234 Time=0.0042\n",
      "Epoch 42, learning rate [0.005]\n",
      "[42:   0]: eps=0.00000000 Loss=169.8374 Time=0.0070\n",
      "[42:  10]: eps=0.00000000 Loss=201.8809 Time=0.0082\n",
      "[42:  20]: eps=0.00000000 Loss=204.5610 Time=0.0085\n",
      "[42:  25]: eps=0.00000000 Loss=199.8111 Time=0.0080\n",
      "Epoch time: 0.2313, Total time: 9.1651\n",
      "Evaluating...\n",
      "[42:   6]: eps=0.00000000 Loss=192.3699 Time=0.0045\n",
      "Epoch 43, learning rate [0.005]\n",
      "[43:   0]: eps=0.00000000 Loss=206.7900 Time=0.0071\n",
      "[43:  10]: eps=0.00000000 Loss=214.1505 Time=0.0065\n",
      "[43:  20]: eps=0.00000000 Loss=205.8923 Time=0.0065\n",
      "[43:  25]: eps=0.00000000 Loss=200.2976 Time=0.0064\n",
      "Epoch time: 0.1828, Total time: 9.3479\n",
      "Evaluating...\n",
      "[43:   6]: eps=0.00000000 Loss=192.3359 Time=0.0041\n",
      "Epoch 44, learning rate [0.005]\n",
      "[44:   0]: eps=0.00000000 Loss=172.3015 Time=0.0059\n",
      "[44:  10]: eps=0.00000000 Loss=202.2970 Time=0.0065\n",
      "[44:  20]: eps=0.00000000 Loss=198.2954 Time=0.0063\n",
      "[44:  25]: eps=0.00000000 Loss=200.5216 Time=0.0063\n",
      "Epoch time: 0.1800, Total time: 9.5279\n",
      "Evaluating...\n",
      "[44:   6]: eps=0.00000000 Loss=192.3789 Time=0.0041\n",
      "Epoch 45, learning rate [0.005]\n",
      "[45:   0]: eps=0.00000000 Loss=227.8854 Time=0.0089\n",
      "[45:  10]: eps=0.00000000 Loss=198.0869 Time=0.0089\n",
      "[45:  20]: eps=0.00000000 Loss=208.7626 Time=0.0083\n",
      "[45:  25]: eps=0.00000000 Loss=200.8226 Time=0.0080\n",
      "Epoch time: 0.2287, Total time: 9.7566\n",
      "Evaluating...\n",
      "[45:   6]: eps=0.00000000 Loss=192.3164 Time=0.0053\n",
      "Epoch 46, learning rate [0.005]\n",
      "[46:   0]: eps=0.00000000 Loss=247.5039 Time=0.0083\n",
      "[46:  10]: eps=0.00000000 Loss=193.7103 Time=0.0069\n",
      "[46:  20]: eps=0.00000000 Loss=196.1526 Time=0.0078\n",
      "[46:  25]: eps=0.00000000 Loss=199.8209 Time=0.0075\n",
      "Epoch time: 0.2206, Total time: 9.9772\n",
      "Evaluating...\n",
      "[46:   6]: eps=0.00000000 Loss=192.3353 Time=0.0061\n",
      "Epoch 47, learning rate [0.005]\n",
      "[47:   0]: eps=0.00000000 Loss=165.6919 Time=0.0084\n",
      "[47:  10]: eps=0.00000000 Loss=220.8365 Time=0.0069\n",
      "[47:  20]: eps=0.00000000 Loss=203.2972 Time=0.0068\n",
      "[47:  25]: eps=0.00000000 Loss=200.7278 Time=0.0065\n",
      "Epoch time: 0.1877, Total time: 10.1650\n",
      "Evaluating...\n",
      "[47:   6]: eps=0.00000000 Loss=192.2846 Time=0.0046\n",
      "Epoch 48, learning rate [0.005]\n",
      "[48:   0]: eps=0.00000000 Loss=205.6228 Time=0.0086\n",
      "[48:  10]: eps=0.00000000 Loss=227.8431 Time=0.0075\n",
      "[48:  20]: eps=0.00000000 Loss=202.0307 Time=0.0080\n",
      "[48:  25]: eps=0.00000000 Loss=198.8875 Time=0.0077\n",
      "Epoch time: 0.2157, Total time: 10.3806\n",
      "Evaluating...\n",
      "[48:   6]: eps=0.00000000 Loss=192.2275 Time=0.0049\n",
      "Epoch 49, learning rate [0.005]\n",
      "[49:   0]: eps=0.00000000 Loss=235.4698 Time=0.0070\n",
      "[49:  10]: eps=0.00000000 Loss=207.1412 Time=0.0077\n",
      "[49:  20]: eps=0.00000000 Loss=199.6180 Time=0.0080\n",
      "[49:  25]: eps=0.00000000 Loss=198.8875 Time=0.0091\n",
      "Epoch time: 0.2616, Total time: 10.6422\n",
      "Evaluating...\n",
      "[49:   6]: eps=0.00000000 Loss=192.3250 Time=0.0050\n",
      "Epoch 50, learning rate [0.005]\n",
      "[50:   0]: eps=0.00000000 Loss=197.3585 Time=0.0070\n",
      "[50:  10]: eps=0.00000000 Loss=195.8021 Time=0.0074\n",
      "[50:  20]: eps=0.00000000 Loss=198.7108 Time=0.0068\n",
      "[50:  25]: eps=0.00000000 Loss=199.4095 Time=0.0068\n",
      "Epoch time: 0.1931, Total time: 10.8354\n",
      "Evaluating...\n",
      "[50:   6]: eps=0.00000000 Loss=192.3849 Time=0.0044\n",
      "Epoch 51, learning rate [0.005]\n",
      "[51:   0]: eps=0.00000000 Loss=192.5538 Time=0.0079\n",
      "[51:  10]: eps=0.00000000 Loss=191.5430 Time=0.0068\n",
      "[51:  20]: eps=0.00000000 Loss=197.0942 Time=0.0070\n",
      "[51:  25]: eps=0.00000000 Loss=199.9450 Time=0.0067\n",
      "Epoch time: 0.1948, Total time: 11.0302\n",
      "Evaluating...\n",
      "[51:   6]: eps=0.00000000 Loss=192.1532 Time=0.0041\n",
      "Epoch 52, learning rate [0.005]\n",
      "[52:   0]: eps=0.00000000 Loss=164.7637 Time=0.0073\n",
      "[52:  10]: eps=0.00000000 Loss=201.2432 Time=0.0081\n",
      "[52:  20]: eps=0.00000000 Loss=200.3031 Time=0.0073\n",
      "[52:  25]: eps=0.00000000 Loss=200.1951 Time=0.0069\n",
      "Epoch time: 0.2029, Total time: 11.2331\n",
      "Evaluating...\n",
      "[52:   6]: eps=0.00000000 Loss=192.3228 Time=0.0044\n",
      "Epoch 53, learning rate [0.005]\n",
      "[53:   0]: eps=0.00000000 Loss=234.1334 Time=0.0069\n",
      "[53:  10]: eps=0.00000000 Loss=213.2649 Time=0.0075\n",
      "[53:  20]: eps=0.00000000 Loss=204.1018 Time=0.0077\n",
      "[53:  25]: eps=0.00000000 Loss=199.9905 Time=0.0076\n",
      "Epoch time: 0.2215, Total time: 11.4546\n",
      "Evaluating...\n",
      "[53:   6]: eps=0.00000000 Loss=192.1101 Time=0.0041\n",
      "Epoch 54, learning rate [0.005]\n",
      "[54:   0]: eps=0.00000000 Loss=169.2540 Time=0.0070\n",
      "[54:  10]: eps=0.00000000 Loss=199.7896 Time=0.0067\n",
      "[54:  20]: eps=0.00000000 Loss=200.3593 Time=0.0066\n",
      "[54:  25]: eps=0.00000000 Loss=200.0257 Time=0.0066\n",
      "Epoch time: 0.1883, Total time: 11.6428\n",
      "Evaluating...\n",
      "[54:   6]: eps=0.00000000 Loss=192.0983 Time=0.0037\n",
      "Epoch 55, learning rate [0.005]\n",
      "[55:   0]: eps=0.00000000 Loss=245.9262 Time=0.0090\n",
      "[55:  10]: eps=0.00000000 Loss=191.3105 Time=0.0078\n",
      "[55:  20]: eps=0.00000000 Loss=205.1386 Time=0.0081\n",
      "[55:  25]: eps=0.00000000 Loss=199.2213 Time=0.0079\n",
      "Epoch time: 0.2251, Total time: 11.8680\n",
      "Evaluating...\n",
      "[55:   6]: eps=0.00000000 Loss=191.8315 Time=0.0041\n",
      "Epoch 56, learning rate [0.005]\n",
      "[56:   0]: eps=0.00000000 Loss=198.2553 Time=0.0072\n",
      "[56:  10]: eps=0.00000000 Loss=203.5051 Time=0.0069\n",
      "[56:  20]: eps=0.00000000 Loss=200.0514 Time=0.0068\n",
      "[56:  25]: eps=0.00000000 Loss=200.2193 Time=0.0066\n",
      "Epoch time: 0.1924, Total time: 12.0604\n",
      "Evaluating...\n",
      "[56:   6]: eps=0.00000000 Loss=191.9558 Time=0.0041\n",
      "Epoch 57, learning rate [0.005]\n",
      "[57:   0]: eps=0.00000000 Loss=202.0919 Time=0.0072\n",
      "[57:  10]: eps=0.00000000 Loss=197.3928 Time=0.0069\n",
      "[57:  20]: eps=0.00000000 Loss=204.2596 Time=0.0067\n",
      "[57:  25]: eps=0.00000000 Loss=200.2425 Time=0.0065\n",
      "Epoch time: 0.1893, Total time: 12.2497\n",
      "Evaluating...\n",
      "[57:   6]: eps=0.00000000 Loss=192.0043 Time=0.0041\n",
      "Epoch 58, learning rate [0.005]\n",
      "[58:   0]: eps=0.00000000 Loss=165.4311 Time=0.0060\n",
      "[58:  10]: eps=0.00000000 Loss=214.5886 Time=0.0065\n",
      "[58:  20]: eps=0.00000000 Loss=200.5962 Time=0.0067\n",
      "[58:  25]: eps=0.00000000 Loss=198.9319 Time=0.0065\n",
      "Epoch time: 0.1933, Total time: 12.4431\n",
      "Evaluating...\n",
      "[58:   6]: eps=0.00000000 Loss=191.9411 Time=0.0038\n",
      "Epoch 59, learning rate [0.005]\n",
      "[59:   0]: eps=0.00000000 Loss=256.3041 Time=0.0069\n",
      "[59:  10]: eps=0.00000000 Loss=206.3226 Time=0.0078\n",
      "[59:  20]: eps=0.00000000 Loss=199.1685 Time=0.0072\n",
      "[59:  25]: eps=0.00000000 Loss=199.8435 Time=0.0070\n",
      "Epoch time: 0.2020, Total time: 12.6450\n",
      "Evaluating...\n",
      "[59:   6]: eps=0.00000000 Loss=192.1197 Time=0.0048\n",
      "Epoch 60, learning rate [0.005]\n",
      "[60:   0]: eps=0.00000000 Loss=186.9324 Time=0.0088\n",
      "[60:  10]: eps=0.00000000 Loss=206.1871 Time=0.0067\n",
      "[60:  20]: eps=0.00000000 Loss=204.7124 Time=0.0068\n",
      "[60:  25]: eps=0.00000000 Loss=198.6382 Time=0.0066\n",
      "Epoch time: 0.1875, Total time: 12.8325\n",
      "Evaluating...\n",
      "[60:   6]: eps=0.00000000 Loss=191.7628 Time=0.0047\n",
      "Epoch 61, learning rate [0.005]\n",
      "[61:   0]: eps=0.00000000 Loss=207.9915 Time=0.0077\n",
      "[61:  10]: eps=0.00000000 Loss=211.8442 Time=0.0081\n",
      "[61:  20]: eps=0.00000000 Loss=204.1487 Time=0.0072\n",
      "[61:  25]: eps=0.00000000 Loss=199.1032 Time=0.0069\n",
      "Epoch time: 0.1932, Total time: 13.0257\n",
      "Evaluating...\n",
      "[61:   6]: eps=0.00000000 Loss=192.0071 Time=0.0040\n",
      "Epoch 62, learning rate [0.005]\n",
      "[62:   0]: eps=0.00000000 Loss=156.0671 Time=0.0073\n",
      "[62:  10]: eps=0.00000000 Loss=179.9809 Time=0.0065\n",
      "[62:  20]: eps=0.00000000 Loss=199.6234 Time=0.0065\n",
      "[62:  25]: eps=0.00000000 Loss=199.1353 Time=0.0067\n",
      "Epoch time: 0.1921, Total time: 13.2178\n",
      "Evaluating...\n",
      "[62:   6]: eps=0.00000000 Loss=191.8958 Time=0.0042\n",
      "Epoch 63, learning rate [0.005]\n",
      "[63:   0]: eps=0.00000000 Loss=203.3219 Time=0.0117\n",
      "[63:  10]: eps=0.00000000 Loss=208.5416 Time=0.0081\n",
      "[63:  20]: eps=0.00000000 Loss=195.5639 Time=0.0073\n",
      "[63:  25]: eps=0.00000000 Loss=199.7036 Time=0.0072\n",
      "Epoch time: 0.2031, Total time: 13.4209\n",
      "Evaluating...\n",
      "[63:   6]: eps=0.00000000 Loss=192.0780 Time=0.0044\n",
      "Epoch 64, learning rate [0.005]\n",
      "[64:   0]: eps=0.00000000 Loss=211.7859 Time=0.0071\n",
      "[64:  10]: eps=0.00000000 Loss=188.7009 Time=0.0059\n",
      "[64:  20]: eps=0.00000000 Loss=205.1772 Time=0.0065\n",
      "[64:  25]: eps=0.00000000 Loss=199.2861 Time=0.0064\n",
      "Epoch time: 0.1853, Total time: 13.6063\n",
      "Evaluating...\n",
      "[64:   6]: eps=0.00000000 Loss=191.7360 Time=0.0035\n",
      "Epoch 65, learning rate [0.005]\n",
      "[65:   0]: eps=0.00000000 Loss=190.7716 Time=0.0057\n",
      "[65:  10]: eps=0.00000000 Loss=206.0051 Time=0.0070\n",
      "[65:  20]: eps=0.00000000 Loss=202.7277 Time=0.0075\n",
      "[65:  25]: eps=0.00000000 Loss=199.7116 Time=0.0071\n",
      "Epoch time: 0.2007, Total time: 13.8070\n",
      "Evaluating...\n",
      "[65:   6]: eps=0.00000000 Loss=191.9654 Time=0.0042\n",
      "Epoch 66, learning rate [0.005]\n",
      "[66:   0]: eps=0.00000000 Loss=238.1320 Time=0.0070\n",
      "[66:  10]: eps=0.00000000 Loss=211.8954 Time=0.0064\n",
      "[66:  20]: eps=0.00000000 Loss=198.2767 Time=0.0068\n",
      "[66:  25]: eps=0.00000000 Loss=199.5572 Time=0.0065\n",
      "Epoch time: 0.1932, Total time: 14.0002\n",
      "Evaluating...\n",
      "[66:   6]: eps=0.00000000 Loss=191.8303 Time=0.0044\n",
      "Epoch 67, learning rate [0.005]\n",
      "[67:   0]: eps=0.00000000 Loss=170.9777 Time=0.0063\n",
      "[67:  10]: eps=0.00000000 Loss=198.7829 Time=0.0062\n",
      "[67:  20]: eps=0.00000000 Loss=205.7214 Time=0.0068\n",
      "[67:  25]: eps=0.00000000 Loss=198.7044 Time=0.0067\n",
      "Epoch time: 0.1903, Total time: 14.1905\n",
      "Evaluating...\n",
      "[67:   6]: eps=0.00000000 Loss=191.9244 Time=0.0038\n",
      "Epoch 68, learning rate [0.005]\n",
      "[68:   0]: eps=0.00000000 Loss=154.5485 Time=0.0070\n",
      "[68:  10]: eps=0.00000000 Loss=187.1592 Time=0.0070\n",
      "[68:  20]: eps=0.00000000 Loss=195.1997 Time=0.0071\n",
      "[68:  25]: eps=0.00000000 Loss=199.8126 Time=0.0069\n",
      "Epoch time: 0.1942, Total time: 14.3847\n",
      "Evaluating...\n",
      "[68:   6]: eps=0.00000000 Loss=191.7874 Time=0.0050\n",
      "Epoch 69, learning rate [0.005]\n",
      "[69:   0]: eps=0.00000000 Loss=173.4731 Time=0.0070\n",
      "[69:  10]: eps=0.00000000 Loss=200.4066 Time=0.0080\n",
      "[69:  20]: eps=0.00000000 Loss=200.6256 Time=0.0074\n",
      "[69:  25]: eps=0.00000000 Loss=198.5327 Time=0.0071\n",
      "Epoch time: 0.1995, Total time: 14.5842\n",
      "Evaluating...\n",
      "[69:   6]: eps=0.00000000 Loss=191.5784 Time=0.0043\n",
      "Epoch 70, learning rate [0.005]\n",
      "[70:   0]: eps=0.00000000 Loss=119.0792 Time=0.0082\n",
      "[70:  10]: eps=0.00000000 Loss=195.5742 Time=0.0069\n",
      "[70:  20]: eps=0.00000000 Loss=201.7186 Time=0.0079\n",
      "[70:  25]: eps=0.00000000 Loss=198.6689 Time=0.0079\n",
      "Epoch time: 0.2279, Total time: 14.8121\n",
      "Evaluating...\n",
      "[70:   6]: eps=0.00000000 Loss=191.8451 Time=0.0049\n",
      "Epoch 71, learning rate [0.005]\n",
      "[71:   0]: eps=0.00000000 Loss=193.3060 Time=0.0083\n",
      "[71:  10]: eps=0.00000000 Loss=189.8834 Time=0.0078\n",
      "[71:  20]: eps=0.00000000 Loss=198.6447 Time=0.0073\n",
      "[71:  25]: eps=0.00000000 Loss=199.1042 Time=0.0073\n",
      "Epoch time: 0.2098, Total time: 15.0219\n",
      "Evaluating...\n",
      "[71:   6]: eps=0.00000000 Loss=191.8745 Time=0.0039\n",
      "Epoch 72, learning rate [0.005]\n",
      "[72:   0]: eps=0.00000000 Loss=161.6012 Time=0.0072\n",
      "[72:  10]: eps=0.00000000 Loss=200.2257 Time=0.0072\n",
      "[72:  20]: eps=0.00000000 Loss=203.7118 Time=0.0080\n",
      "[72:  25]: eps=0.00000000 Loss=199.4675 Time=0.0079\n",
      "Epoch time: 0.2327, Total time: 15.2546\n",
      "Evaluating...\n",
      "[72:   6]: eps=0.00000000 Loss=191.6924 Time=0.0045\n",
      "Epoch 73, learning rate [0.005]\n",
      "[73:   0]: eps=0.00000000 Loss=218.4881 Time=0.0078\n",
      "[73:  10]: eps=0.00000000 Loss=203.8074 Time=0.0075\n",
      "[73:  20]: eps=0.00000000 Loss=201.1321 Time=0.0075\n",
      "[73:  25]: eps=0.00000000 Loss=199.3494 Time=0.0072\n",
      "Epoch time: 0.2088, Total time: 15.4634\n",
      "Evaluating...\n",
      "[73:   6]: eps=0.00000000 Loss=191.8398 Time=0.0043\n",
      "Epoch 74, learning rate [0.005]\n",
      "[74:   0]: eps=0.00000000 Loss=204.6472 Time=0.0070\n",
      "[74:  10]: eps=0.00000000 Loss=202.5508 Time=0.0065\n",
      "[74:  20]: eps=0.00000000 Loss=206.0803 Time=0.0065\n",
      "[74:  25]: eps=0.00000000 Loss=199.4537 Time=0.0062\n",
      "Epoch time: 0.1790, Total time: 15.6424\n",
      "Evaluating...\n",
      "[74:   6]: eps=0.00000000 Loss=191.7684 Time=0.0040\n",
      "Epoch 75, learning rate [0.005]\n",
      "[75:   0]: eps=0.00000000 Loss=223.2848 Time=0.0063\n",
      "[75:  10]: eps=0.00000000 Loss=200.6727 Time=0.0062\n",
      "[75:  20]: eps=0.00000000 Loss=206.0563 Time=0.0063\n",
      "[75:  25]: eps=0.00000000 Loss=199.0759 Time=0.0062\n",
      "Epoch time: 0.1779, Total time: 15.8203\n",
      "Evaluating...\n",
      "[75:   6]: eps=0.00000000 Loss=191.9858 Time=0.0036\n",
      "Epoch 76, learning rate [0.005]\n",
      "[76:   0]: eps=0.00000000 Loss=239.6338 Time=0.0070\n",
      "[76:  10]: eps=0.00000000 Loss=194.9762 Time=0.0080\n",
      "[76:  20]: eps=0.00000000 Loss=202.9909 Time=0.0076\n",
      "[76:  25]: eps=0.00000000 Loss=199.5518 Time=0.0075\n",
      "Epoch time: 0.2171, Total time: 16.0374\n",
      "Evaluating...\n",
      "[76:   6]: eps=0.00000000 Loss=191.5020 Time=0.0056\n",
      "Epoch 77, learning rate [0.005]\n",
      "[77:   0]: eps=0.00000000 Loss=188.4854 Time=0.0086\n",
      "[77:  10]: eps=0.00000000 Loss=193.1936 Time=0.0078\n",
      "[77:  20]: eps=0.00000000 Loss=199.3615 Time=0.0078\n",
      "[77:  25]: eps=0.00000000 Loss=198.9946 Time=0.0076\n",
      "Epoch time: 0.2179, Total time: 16.2553\n",
      "Evaluating...\n",
      "[77:   6]: eps=0.00000000 Loss=191.7025 Time=0.0051\n",
      "Epoch 78, learning rate [0.005]\n",
      "[78:   0]: eps=0.00000000 Loss=201.0933 Time=0.0067\n",
      "[78:  10]: eps=0.00000000 Loss=205.8076 Time=0.0063\n",
      "[78:  20]: eps=0.00000000 Loss=199.9186 Time=0.0062\n",
      "[78:  25]: eps=0.00000000 Loss=197.9410 Time=0.0061\n",
      "Epoch time: 0.1753, Total time: 16.4306\n",
      "Evaluating...\n",
      "[78:   6]: eps=0.00000000 Loss=191.4983 Time=0.0040\n",
      "Epoch 79, learning rate [0.005]\n",
      "[79:   0]: eps=0.00000000 Loss=111.9875 Time=0.0070\n",
      "[79:  10]: eps=0.00000000 Loss=193.1178 Time=0.0072\n",
      "[79:  20]: eps=0.00000000 Loss=198.7733 Time=0.0071\n",
      "[79:  25]: eps=0.00000000 Loss=199.7435 Time=0.0071\n",
      "Epoch time: 0.2014, Total time: 16.6320\n",
      "Evaluating...\n",
      "[79:   6]: eps=0.00000000 Loss=191.5244 Time=0.0045\n",
      "Epoch 80, learning rate [0.005]\n",
      "[80:   0]: eps=0.00000000 Loss=162.1631 Time=0.0069\n",
      "[80:  10]: eps=0.00000000 Loss=192.8055 Time=0.0093\n",
      "[80:  20]: eps=0.00000000 Loss=193.2962 Time=0.0086\n",
      "[80:  25]: eps=0.00000000 Loss=199.1933 Time=0.0084\n",
      "Epoch time: 0.2445, Total time: 16.8765\n",
      "Evaluating...\n",
      "[80:   6]: eps=0.00000000 Loss=191.7131 Time=0.0039\n",
      "Epoch 81, learning rate [0.005]\n",
      "[81:   0]: eps=0.00000000 Loss=200.7266 Time=0.0065\n",
      "[81:  10]: eps=0.00000000 Loss=203.8824 Time=0.0061\n",
      "[81:  20]: eps=0.00000000 Loss=201.3349 Time=0.0061\n",
      "[81:  25]: eps=0.00000000 Loss=198.3570 Time=0.0060\n",
      "Epoch time: 0.1703, Total time: 17.0469\n",
      "Evaluating...\n",
      "[81:   6]: eps=0.00000000 Loss=191.6442 Time=0.0043\n",
      "Epoch 82, learning rate [0.005]\n",
      "[82:   0]: eps=0.00000000 Loss=135.0118 Time=0.0070\n",
      "[82:  10]: eps=0.00000000 Loss=189.7012 Time=0.0067\n",
      "[82:  20]: eps=0.00000000 Loss=194.8916 Time=0.0064\n",
      "[82:  25]: eps=0.00000000 Loss=198.4460 Time=0.0064\n",
      "Epoch time: 0.1857, Total time: 17.2325\n",
      "Evaluating...\n",
      "[82:   6]: eps=0.00000000 Loss=191.6903 Time=0.0032\n",
      "Epoch 83, learning rate [0.005]\n",
      "[83:   0]: eps=0.00000000 Loss=191.0207 Time=0.0060\n",
      "[83:  10]: eps=0.00000000 Loss=216.9233 Time=0.0068\n",
      "[83:  20]: eps=0.00000000 Loss=197.8721 Time=0.0067\n",
      "[83:  25]: eps=0.00000000 Loss=199.5217 Time=0.0065\n",
      "Epoch time: 0.1925, Total time: 17.4250\n",
      "Evaluating...\n",
      "[83:   6]: eps=0.00000000 Loss=191.8617 Time=0.0036\n",
      "Epoch 84, learning rate [0.005]\n",
      "[84:   0]: eps=0.00000000 Loss=283.8621 Time=0.0058\n",
      "[84:  10]: eps=0.00000000 Loss=196.2630 Time=0.0059\n",
      "[84:  20]: eps=0.00000000 Loss=203.3360 Time=0.0060\n",
      "[84:  25]: eps=0.00000000 Loss=198.8714 Time=0.0063\n",
      "Epoch time: 0.1844, Total time: 17.6094\n",
      "Evaluating...\n",
      "[84:   6]: eps=0.00000000 Loss=191.4126 Time=0.0041\n",
      "Epoch 85, learning rate [0.005]\n",
      "[85:   0]: eps=0.00000000 Loss=192.6690 Time=0.0070\n",
      "[85:  10]: eps=0.00000000 Loss=197.6719 Time=0.0065\n",
      "[85:  20]: eps=0.00000000 Loss=199.4620 Time=0.0064\n",
      "[85:  25]: eps=0.00000000 Loss=199.2789 Time=0.0066\n",
      "Epoch time: 0.1902, Total time: 17.7996\n",
      "Evaluating...\n",
      "[85:   6]: eps=0.00000000 Loss=191.3960 Time=0.0046\n",
      "Epoch 86, learning rate [0.005]\n",
      "[86:   0]: eps=0.00000000 Loss=179.4957 Time=0.0082\n",
      "[86:  10]: eps=0.00000000 Loss=193.8944 Time=0.0068\n",
      "[86:  20]: eps=0.00000000 Loss=205.9613 Time=0.0066\n",
      "[86:  25]: eps=0.00000000 Loss=199.5144 Time=0.0064\n",
      "Epoch time: 0.1850, Total time: 17.9847\n",
      "Evaluating...\n",
      "[86:   6]: eps=0.00000000 Loss=191.8097 Time=0.0040\n",
      "Epoch 87, learning rate [0.005]\n",
      "[87:   0]: eps=0.00000000 Loss=248.2521 Time=0.0079\n",
      "[87:  10]: eps=0.00000000 Loss=201.5314 Time=0.0090\n",
      "[87:  20]: eps=0.00000000 Loss=199.1376 Time=0.0080\n",
      "[87:  25]: eps=0.00000000 Loss=199.8398 Time=0.0077\n",
      "Epoch time: 0.2209, Total time: 18.2056\n",
      "Evaluating...\n",
      "[87:   6]: eps=0.00000000 Loss=191.6067 Time=0.0039\n",
      "Epoch 88, learning rate [0.005]\n",
      "[88:   0]: eps=0.00000000 Loss=167.9028 Time=0.0063\n",
      "[88:  10]: eps=0.00000000 Loss=214.9974 Time=0.0062\n",
      "[88:  20]: eps=0.00000000 Loss=201.8797 Time=0.0065\n",
      "[88:  25]: eps=0.00000000 Loss=198.9860 Time=0.0063\n",
      "Epoch time: 0.1778, Total time: 18.3833\n",
      "Evaluating...\n",
      "[88:   6]: eps=0.00000000 Loss=191.7753 Time=0.0040\n",
      "Epoch 89, learning rate [0.005]\n",
      "[89:   0]: eps=0.00000000 Loss=156.2439 Time=0.0061\n",
      "[89:  10]: eps=0.00000000 Loss=196.7605 Time=0.0057\n",
      "[89:  20]: eps=0.00000000 Loss=199.9266 Time=0.0066\n",
      "[89:  25]: eps=0.00000000 Loss=199.3384 Time=0.0066\n",
      "Epoch time: 0.1924, Total time: 18.5758\n",
      "Evaluating...\n",
      "[89:   6]: eps=0.00000000 Loss=191.6795 Time=0.0050\n",
      "Epoch 90, learning rate [0.005]\n",
      "[90:   0]: eps=0.00000000 Loss=99.0967 Time=0.0109\n",
      "[90:  10]: eps=0.00000000 Loss=206.8619 Time=0.0080\n",
      "[90:  20]: eps=0.00000000 Loss=201.8389 Time=0.0081\n",
      "[90:  25]: eps=0.00000000 Loss=198.7084 Time=0.0080\n",
      "Epoch time: 0.2325, Total time: 18.8083\n",
      "Evaluating...\n",
      "[90:   6]: eps=0.00000000 Loss=191.7445 Time=0.0038\n",
      "Epoch 91, learning rate [0.005]\n",
      "[91:   0]: eps=0.00000000 Loss=152.7296 Time=0.0059\n",
      "[91:  10]: eps=0.00000000 Loss=190.4976 Time=0.0063\n",
      "[91:  20]: eps=0.00000000 Loss=200.3277 Time=0.0070\n",
      "[91:  25]: eps=0.00000000 Loss=199.1760 Time=0.0069\n",
      "Epoch time: 0.1971, Total time: 19.0054\n",
      "Evaluating...\n",
      "[91:   6]: eps=0.00000000 Loss=191.5076 Time=0.0042\n",
      "Epoch 92, learning rate [0.005]\n",
      "[92:   0]: eps=0.00000000 Loss=224.9174 Time=0.0068\n",
      "[92:  10]: eps=0.00000000 Loss=189.3750 Time=0.0064\n",
      "[92:  20]: eps=0.00000000 Loss=197.4512 Time=0.0066\n",
      "[92:  25]: eps=0.00000000 Loss=198.0947 Time=0.0067\n",
      "Epoch time: 0.1899, Total time: 19.1952\n",
      "Evaluating...\n",
      "[92:   6]: eps=0.00000000 Loss=191.3245 Time=0.0045\n",
      "Epoch 93, learning rate [0.005]\n",
      "[93:   0]: eps=0.00000000 Loss=212.8561 Time=0.0069\n",
      "[93:  10]: eps=0.00000000 Loss=203.5856 Time=0.0062\n",
      "[93:  20]: eps=0.00000000 Loss=205.1967 Time=0.0061\n",
      "[93:  25]: eps=0.00000000 Loss=199.3793 Time=0.0075\n",
      "Epoch time: 0.2171, Total time: 19.4124\n",
      "Evaluating...\n",
      "[93:   6]: eps=0.00000000 Loss=191.2822 Time=0.0048\n",
      "Epoch 94, learning rate [0.005]\n",
      "[94:   0]: eps=0.00000000 Loss=166.3218 Time=0.0080\n",
      "[94:  10]: eps=0.00000000 Loss=200.7424 Time=0.0066\n",
      "[94:  20]: eps=0.00000000 Loss=200.2873 Time=0.0069\n",
      "[94:  25]: eps=0.00000000 Loss=198.8912 Time=0.0068\n",
      "Epoch time: 0.2003, Total time: 19.6126\n",
      "Evaluating...\n",
      "[94:   6]: eps=0.00000000 Loss=191.2813 Time=0.0043\n",
      "Epoch 95, learning rate [0.005]\n",
      "[95:   0]: eps=0.00000000 Loss=159.9323 Time=0.0060\n",
      "[95:  10]: eps=0.00000000 Loss=204.3892 Time=0.0064\n",
      "[95:  20]: eps=0.00000000 Loss=200.9714 Time=0.0064\n",
      "[95:  25]: eps=0.00000000 Loss=196.6313 Time=0.0063\n",
      "Epoch time: 0.1847, Total time: 19.7974\n",
      "Evaluating...\n",
      "[95:   6]: eps=0.00000000 Loss=191.6258 Time=0.0038\n",
      "Epoch 96, learning rate [0.005]\n",
      "[96:   0]: eps=0.00000000 Loss=127.7237 Time=0.0070\n",
      "[96:  10]: eps=0.00000000 Loss=189.8375 Time=0.0073\n",
      "[96:  20]: eps=0.00000000 Loss=192.7181 Time=0.0071\n",
      "[96:  25]: eps=0.00000000 Loss=198.0809 Time=0.0069\n",
      "Epoch time: 0.1990, Total time: 19.9964\n",
      "Evaluating...\n",
      "[96:   6]: eps=0.00000000 Loss=191.2847 Time=0.0036\n",
      "Epoch 97, learning rate [0.005]\n",
      "[97:   0]: eps=0.00000000 Loss=205.2382 Time=0.0071\n",
      "[97:  10]: eps=0.00000000 Loss=202.4795 Time=0.0065\n",
      "[97:  20]: eps=0.00000000 Loss=200.2512 Time=0.0063\n",
      "[97:  25]: eps=0.00000000 Loss=198.9643 Time=0.0063\n",
      "Epoch time: 0.1719, Total time: 20.1683\n",
      "Evaluating...\n",
      "[97:   6]: eps=0.00000000 Loss=191.3501 Time=0.0047\n",
      "Epoch 98, learning rate [0.005]\n",
      "[98:   0]: eps=0.00000000 Loss=257.2696 Time=0.0070\n",
      "[98:  10]: eps=0.00000000 Loss=218.9010 Time=0.0083\n",
      "[98:  20]: eps=0.00000000 Loss=205.6271 Time=0.0077\n",
      "[98:  25]: eps=0.00000000 Loss=199.3661 Time=0.0075\n",
      "Epoch time: 0.2184, Total time: 20.3867\n",
      "Evaluating...\n",
      "[98:   6]: eps=0.00000000 Loss=191.8817 Time=0.0044\n",
      "Epoch 99, learning rate [0.005]\n",
      "[99:   0]: eps=0.00000000 Loss=207.1013 Time=0.0078\n",
      "[99:  10]: eps=0.00000000 Loss=180.0893 Time=0.0069\n",
      "[99:  20]: eps=0.00000000 Loss=199.3245 Time=0.0067\n",
      "[99:  25]: eps=0.00000000 Loss=198.4561 Time=0.0074\n",
      "Epoch time: 0.2136, Total time: 20.6003\n",
      "Evaluating...\n",
      "[99:   6]: eps=0.00000000 Loss=191.5466 Time=0.0052\n",
      "Epoch 100, learning rate [0.005]\n",
      "[100:   0]: eps=0.00000000 Loss=218.2744 Time=0.0111\n",
      "[100:  10]: eps=0.00000000 Loss=194.0454 Time=0.0078\n",
      "[100:  20]: eps=0.00000000 Loss=203.9440 Time=0.0075\n",
      "[100:  25]: eps=0.00000000 Loss=198.6259 Time=0.0073\n",
      "Epoch time: 0.2052, Total time: 20.8055\n",
      "Evaluating...\n",
      "[100:   6]: eps=0.00000000 Loss=191.2405 Time=0.0043\n",
      "Epoch 101, learning rate [0.005]\n",
      "[101:   0]: eps=0.00000000 Loss=164.9969 Time=0.0067\n",
      "[101:  10]: eps=0.00000000 Loss=194.4199 Time=0.0061\n",
      "[101:  20]: eps=0.00000000 Loss=207.9573 Time=0.0065\n",
      "[101:  25]: eps=0.00000000 Loss=199.0492 Time=0.0064\n",
      "Epoch time: 0.1831, Total time: 20.9886\n",
      "Evaluating...\n",
      "[101:   6]: eps=0.00000000 Loss=192.1088 Time=0.0043\n",
      "Epoch 102, learning rate [0.005]\n",
      "[102:   0]: eps=0.00000000 Loss=197.8416 Time=0.0083\n",
      "[102:  10]: eps=0.00000000 Loss=186.7532 Time=0.0076\n",
      "[102:  20]: eps=0.00000000 Loss=196.0497 Time=0.0071\n",
      "[102:  25]: eps=0.00000000 Loss=198.8456 Time=0.0070\n",
      "Epoch time: 0.2010, Total time: 21.1897\n",
      "Evaluating...\n",
      "[102:   6]: eps=0.00000000 Loss=191.5262 Time=0.0046\n",
      "Epoch 103, learning rate [0.005]\n",
      "[103:   0]: eps=0.00000000 Loss=215.1471 Time=0.0073\n",
      "[103:  10]: eps=0.00000000 Loss=192.3344 Time=0.0072\n",
      "[103:  20]: eps=0.00000000 Loss=196.2085 Time=0.0067\n",
      "[103:  25]: eps=0.00000000 Loss=198.2646 Time=0.0066\n",
      "Epoch time: 0.1862, Total time: 21.3758\n",
      "Evaluating...\n",
      "[103:   6]: eps=0.00000000 Loss=191.3760 Time=0.0052\n",
      "Epoch 104, learning rate [0.005]\n",
      "[104:   0]: eps=0.00000000 Loss=179.9806 Time=0.0080\n",
      "[104:  10]: eps=0.00000000 Loss=202.1260 Time=0.0074\n",
      "[104:  20]: eps=0.00000000 Loss=206.9946 Time=0.0071\n",
      "[104:  25]: eps=0.00000000 Loss=197.7261 Time=0.0071\n",
      "Epoch time: 0.2082, Total time: 21.5840\n",
      "Evaluating...\n",
      "[104:   6]: eps=0.00000000 Loss=191.7532 Time=0.0047\n",
      "Epoch 105, learning rate [0.005]\n",
      "[105:   0]: eps=0.00000000 Loss=198.5412 Time=0.0080\n",
      "[105:  10]: eps=0.00000000 Loss=200.8091 Time=0.0067\n",
      "[105:  20]: eps=0.00000000 Loss=202.6569 Time=0.0066\n",
      "[105:  25]: eps=0.00000000 Loss=198.1626 Time=0.0067\n",
      "Epoch time: 0.1916, Total time: 21.7756\n",
      "Evaluating...\n",
      "[105:   6]: eps=0.00000000 Loss=191.2578 Time=0.0062\n",
      "Epoch 106, learning rate [0.005]\n",
      "[106:   0]: eps=0.00000000 Loss=183.7102 Time=0.0117\n",
      "[106:  10]: eps=0.00000000 Loss=203.7198 Time=0.0083\n",
      "[106:  20]: eps=0.00000000 Loss=199.3881 Time=0.0077\n",
      "[106:  25]: eps=0.00000000 Loss=196.7818 Time=0.0077\n",
      "Epoch time: 0.2163, Total time: 21.9919\n",
      "Evaluating...\n",
      "[106:   6]: eps=0.00000000 Loss=191.6593 Time=0.0035\n",
      "Epoch 107, learning rate [0.005]\n",
      "[107:   0]: eps=0.00000000 Loss=174.6485 Time=0.0071\n",
      "[107:  10]: eps=0.00000000 Loss=200.9537 Time=0.0065\n",
      "[107:  20]: eps=0.00000000 Loss=202.4118 Time=0.0069\n",
      "[107:  25]: eps=0.00000000 Loss=198.7353 Time=0.0069\n",
      "Epoch time: 0.1954, Total time: 22.1873\n",
      "Evaluating...\n",
      "[107:   6]: eps=0.00000000 Loss=191.6675 Time=0.0035\n",
      "Epoch 108, learning rate [0.005]\n",
      "[108:   0]: eps=0.00000000 Loss=157.6818 Time=0.0067\n",
      "[108:  10]: eps=0.00000000 Loss=188.1314 Time=0.0062\n",
      "[108:  20]: eps=0.00000000 Loss=200.5297 Time=0.0065\n",
      "[108:  25]: eps=0.00000000 Loss=198.7500 Time=0.0066\n",
      "Epoch time: 0.1876, Total time: 22.3750\n",
      "Evaluating...\n",
      "[108:   6]: eps=0.00000000 Loss=191.0924 Time=0.0047\n",
      "Epoch 109, learning rate [0.005]\n",
      "[109:   0]: eps=0.00000000 Loss=163.0350 Time=0.0076\n",
      "[109:  10]: eps=0.00000000 Loss=172.4751 Time=0.0068\n",
      "[109:  20]: eps=0.00000000 Loss=200.0180 Time=0.0074\n",
      "[109:  25]: eps=0.00000000 Loss=198.5266 Time=0.0070\n",
      "Epoch time: 0.1963, Total time: 22.5713\n",
      "Evaluating...\n",
      "[109:   6]: eps=0.00000000 Loss=192.1122 Time=0.0042\n",
      "Epoch 110, learning rate [0.005]\n",
      "[110:   0]: eps=0.00000000 Loss=180.5599 Time=0.0070\n",
      "[110:  10]: eps=0.00000000 Loss=202.4197 Time=0.0071\n",
      "[110:  20]: eps=0.00000000 Loss=198.5717 Time=0.0067\n",
      "[110:  25]: eps=0.00000000 Loss=198.4519 Time=0.0066\n",
      "Epoch time: 0.1890, Total time: 22.7603\n",
      "Evaluating...\n",
      "[110:   6]: eps=0.00000000 Loss=191.2342 Time=0.0036\n",
      "Epoch 111, learning rate [0.005]\n",
      "[111:   0]: eps=0.00000000 Loss=232.6095 Time=0.0070\n",
      "[111:  10]: eps=0.00000000 Loss=198.3859 Time=0.0089\n",
      "[111:  20]: eps=0.00000000 Loss=198.4151 Time=0.0080\n",
      "[111:  25]: eps=0.00000000 Loss=198.6365 Time=0.0075\n",
      "Epoch time: 0.2155, Total time: 22.9758\n",
      "Evaluating...\n",
      "[111:   6]: eps=0.00000000 Loss=191.9107 Time=0.0039\n",
      "Epoch 112, learning rate [0.005]\n",
      "[112:   0]: eps=0.00000000 Loss=214.1123 Time=0.0075\n",
      "[112:  10]: eps=0.00000000 Loss=209.3819 Time=0.0067\n",
      "[112:  20]: eps=0.00000000 Loss=200.4616 Time=0.0066\n",
      "[112:  25]: eps=0.00000000 Loss=198.7453 Time=0.0066\n",
      "Epoch time: 0.1871, Total time: 23.1629\n",
      "Evaluating...\n",
      "[112:   6]: eps=0.00000000 Loss=191.1483 Time=0.0042\n",
      "Epoch 113, learning rate [0.005]\n",
      "[113:   0]: eps=0.00000000 Loss=179.0419 Time=0.0060\n",
      "[113:  10]: eps=0.00000000 Loss=208.9702 Time=0.0059\n",
      "[113:  20]: eps=0.00000000 Loss=203.3880 Time=0.0060\n",
      "[113:  25]: eps=0.00000000 Loss=198.0152 Time=0.0059\n",
      "Epoch time: 0.1706, Total time: 23.3335\n",
      "Evaluating...\n",
      "[113:   6]: eps=0.00000000 Loss=191.9203 Time=0.0039\n",
      "Epoch 114, learning rate [0.005]\n",
      "[114:   0]: eps=0.00000000 Loss=147.2647 Time=0.0072\n",
      "[114:  10]: eps=0.00000000 Loss=195.6956 Time=0.0065\n",
      "[114:  20]: eps=0.00000000 Loss=200.7985 Time=0.0062\n",
      "[114:  25]: eps=0.00000000 Loss=198.6818 Time=0.0061\n",
      "Epoch time: 0.1790, Total time: 23.5125\n",
      "Evaluating...\n",
      "[114:   6]: eps=0.00000000 Loss=191.0942 Time=0.0039\n",
      "Epoch 115, learning rate [0.005]\n",
      "[115:   0]: eps=0.00000000 Loss=177.1452 Time=0.0090\n",
      "[115:  10]: eps=0.00000000 Loss=202.7014 Time=0.0079\n",
      "[115:  20]: eps=0.00000000 Loss=197.8967 Time=0.0072\n",
      "[115:  25]: eps=0.00000000 Loss=198.8370 Time=0.0069\n",
      "Epoch time: 0.1969, Total time: 23.7094\n",
      "Evaluating...\n",
      "[115:   6]: eps=0.00000000 Loss=191.4185 Time=0.0037\n",
      "Epoch 116, learning rate [0.005]\n",
      "[116:   0]: eps=0.00000000 Loss=161.4830 Time=0.0080\n",
      "[116:  10]: eps=0.00000000 Loss=193.2179 Time=0.0067\n",
      "[116:  20]: eps=0.00000000 Loss=198.8492 Time=0.0067\n",
      "[116:  25]: eps=0.00000000 Loss=197.7668 Time=0.0068\n",
      "Epoch time: 0.1936, Total time: 23.9031\n",
      "Evaluating...\n",
      "[116:   6]: eps=0.00000000 Loss=191.5551 Time=0.0043\n",
      "Epoch 117, learning rate [0.005]\n",
      "[117:   0]: eps=0.00000000 Loss=211.4574 Time=0.0080\n",
      "[117:  10]: eps=0.00000000 Loss=194.9991 Time=0.0076\n",
      "[117:  20]: eps=0.00000000 Loss=201.9786 Time=0.0076\n",
      "[117:  25]: eps=0.00000000 Loss=199.3868 Time=0.0074\n",
      "Epoch time: 0.2130, Total time: 24.1161\n",
      "Evaluating...\n",
      "[117:   6]: eps=0.00000000 Loss=191.3840 Time=0.0034\n",
      "Epoch 118, learning rate [0.005]\n",
      "[118:   0]: eps=0.00000000 Loss=172.8874 Time=0.0068\n",
      "[118:  10]: eps=0.00000000 Loss=194.5974 Time=0.0065\n",
      "[118:  20]: eps=0.00000000 Loss=197.2657 Time=0.0064\n",
      "[118:  25]: eps=0.00000000 Loss=197.8478 Time=0.0064\n",
      "Epoch time: 0.1823, Total time: 24.2985\n",
      "Evaluating...\n",
      "[118:   6]: eps=0.00000000 Loss=190.9428 Time=0.0045\n",
      "Epoch 119, learning rate [0.005]\n",
      "[119:   0]: eps=0.00000000 Loss=187.4518 Time=0.0067\n",
      "[119:  10]: eps=0.00000000 Loss=184.7946 Time=0.0076\n",
      "[119:  20]: eps=0.00000000 Loss=191.6637 Time=0.0074\n",
      "[119:  25]: eps=0.00000000 Loss=198.5370 Time=0.0073\n",
      "Epoch time: 0.2066, Total time: 24.5050\n",
      "Evaluating...\n",
      "[119:   6]: eps=0.00000000 Loss=191.1156 Time=0.0039\n",
      "Epoch 120, learning rate [0.005]\n",
      "[120:   0]: eps=0.00000000 Loss=161.5728 Time=0.0090\n",
      "[120:  10]: eps=0.00000000 Loss=188.0422 Time=0.0070\n",
      "[120:  20]: eps=0.00000000 Loss=196.9394 Time=0.0067\n",
      "[120:  25]: eps=0.00000000 Loss=198.7075 Time=0.0064\n",
      "Epoch time: 0.1885, Total time: 24.6935\n",
      "Evaluating...\n",
      "[120:   6]: eps=0.00000000 Loss=191.1067 Time=0.0045\n",
      "Epoch 121, learning rate [0.005]\n",
      "[121:   0]: eps=0.00000000 Loss=251.7396 Time=0.0080\n",
      "[121:  10]: eps=0.00000000 Loss=196.7592 Time=0.0074\n",
      "[121:  20]: eps=0.00000000 Loss=202.6410 Time=0.0072\n",
      "[121:  25]: eps=0.00000000 Loss=198.4956 Time=0.0070\n",
      "Epoch time: 0.1956, Total time: 24.8892\n",
      "Evaluating...\n",
      "[121:   6]: eps=0.00000000 Loss=191.0021 Time=0.0045\n",
      "Epoch 122, learning rate [0.005]\n",
      "[122:   0]: eps=0.00000000 Loss=209.7736 Time=0.0059\n",
      "[122:  10]: eps=0.00000000 Loss=204.2481 Time=0.0066\n",
      "[122:  20]: eps=0.00000000 Loss=192.9423 Time=0.0064\n",
      "[122:  25]: eps=0.00000000 Loss=198.0365 Time=0.0066\n",
      "Epoch time: 0.1864, Total time: 25.0756\n",
      "Evaluating...\n",
      "[122:   6]: eps=0.00000000 Loss=192.2937 Time=0.0041\n",
      "Epoch 123, learning rate [0.005]\n",
      "[123:   0]: eps=0.00000000 Loss=260.3333 Time=0.0064\n",
      "[123:  10]: eps=0.00000000 Loss=213.1997 Time=0.0062\n",
      "[123:  20]: eps=0.00000000 Loss=204.0704 Time=0.0066\n",
      "[123:  25]: eps=0.00000000 Loss=198.6414 Time=0.0075\n",
      "Epoch time: 0.2184, Total time: 25.2940\n",
      "Evaluating...\n",
      "[123:   6]: eps=0.00000000 Loss=190.4609 Time=0.0050\n",
      "Epoch 124, learning rate [0.005]\n",
      "[124:   0]: eps=0.00000000 Loss=138.5863 Time=0.0070\n",
      "[124:  10]: eps=0.00000000 Loss=183.5798 Time=0.0073\n",
      "[124:  20]: eps=0.00000000 Loss=193.7742 Time=0.0074\n",
      "[124:  25]: eps=0.00000000 Loss=198.2767 Time=0.0071\n",
      "Epoch time: 0.2067, Total time: 25.5007\n",
      "Evaluating...\n",
      "[124:   6]: eps=0.00000000 Loss=192.4434 Time=0.0041\n",
      "Epoch 125, learning rate [0.005]\n",
      "[125:   0]: eps=0.00000000 Loss=201.1164 Time=0.0078\n",
      "[125:  10]: eps=0.00000000 Loss=201.0249 Time=0.0065\n",
      "[125:  20]: eps=0.00000000 Loss=208.2026 Time=0.0066\n",
      "[125:  25]: eps=0.00000000 Loss=199.5003 Time=0.0065\n",
      "Epoch time: 0.1814, Total time: 25.6821\n",
      "Evaluating...\n",
      "[125:   6]: eps=0.00000000 Loss=191.0552 Time=0.0036\n",
      "Epoch 126, learning rate [0.005]\n",
      "[126:   0]: eps=0.00000000 Loss=180.7586 Time=0.0069\n",
      "[126:  10]: eps=0.00000000 Loss=208.7604 Time=0.0066\n",
      "[126:  20]: eps=0.00000000 Loss=207.0783 Time=0.0064\n",
      "[126:  25]: eps=0.00000000 Loss=198.8932 Time=0.0065\n",
      "Epoch time: 0.1838, Total time: 25.8660\n",
      "Evaluating...\n",
      "[126:   6]: eps=0.00000000 Loss=191.1243 Time=0.0046\n",
      "Epoch 127, learning rate [0.005]\n",
      "[127:   0]: eps=0.00000000 Loss=174.6883 Time=0.0069\n",
      "[127:  10]: eps=0.00000000 Loss=193.9779 Time=0.0062\n",
      "[127:  20]: eps=0.00000000 Loss=195.1692 Time=0.0070\n",
      "[127:  25]: eps=0.00000000 Loss=198.7457 Time=0.0067\n",
      "Epoch time: 0.1937, Total time: 26.0597\n",
      "Evaluating...\n",
      "[127:   6]: eps=0.00000000 Loss=191.1451 Time=0.0037\n",
      "Epoch 128, learning rate [0.005]\n",
      "[128:   0]: eps=0.00000000 Loss=198.5074 Time=0.0072\n",
      "[128:  10]: eps=0.00000000 Loss=201.8041 Time=0.0065\n",
      "[128:  20]: eps=0.00000000 Loss=199.6917 Time=0.0069\n",
      "[128:  25]: eps=0.00000000 Loss=197.9074 Time=0.0067\n",
      "Epoch time: 0.1894, Total time: 26.2491\n",
      "Evaluating...\n",
      "[128:   6]: eps=0.00000000 Loss=191.0710 Time=0.0043\n",
      "Epoch 129, learning rate [0.005]\n",
      "[129:   0]: eps=0.00000000 Loss=153.5701 Time=0.0074\n",
      "[129:  10]: eps=0.00000000 Loss=203.1113 Time=0.0072\n",
      "[129:  20]: eps=0.00000000 Loss=207.7484 Time=0.0068\n",
      "[129:  25]: eps=0.00000000 Loss=198.7761 Time=0.0068\n",
      "Epoch time: 0.1965, Total time: 26.4456\n",
      "Evaluating...\n",
      "[129:   6]: eps=0.00000000 Loss=191.9091 Time=0.0045\n",
      "Epoch 130, learning rate [0.005]\n",
      "[130:   0]: eps=0.00000000 Loss=196.9496 Time=0.0070\n",
      "[130:  10]: eps=0.00000000 Loss=188.6248 Time=0.0066\n",
      "[130:  20]: eps=0.00000000 Loss=199.4047 Time=0.0075\n",
      "[130:  25]: eps=0.00000000 Loss=198.5490 Time=0.0074\n",
      "Epoch time: 0.2098, Total time: 26.6554\n",
      "Evaluating...\n",
      "[130:   6]: eps=0.00000000 Loss=190.9768 Time=0.0045\n",
      "Epoch 131, learning rate [0.005]\n",
      "[131:   0]: eps=0.00000000 Loss=239.8121 Time=0.0065\n",
      "[131:  10]: eps=0.00000000 Loss=196.1142 Time=0.0069\n",
      "[131:  20]: eps=0.00000000 Loss=195.2345 Time=0.0066\n",
      "[131:  25]: eps=0.00000000 Loss=197.9400 Time=0.0066\n",
      "Epoch time: 0.1881, Total time: 26.8435\n",
      "Evaluating...\n",
      "[131:   6]: eps=0.00000000 Loss=191.4822 Time=0.0038\n",
      "Epoch 132, learning rate [0.005]\n",
      "[132:   0]: eps=0.00000000 Loss=140.4126 Time=0.0058\n",
      "[132:  10]: eps=0.00000000 Loss=187.4052 Time=0.0060\n",
      "[132:  20]: eps=0.00000000 Loss=199.8316 Time=0.0063\n",
      "[132:  25]: eps=0.00000000 Loss=198.5521 Time=0.0064\n",
      "Epoch time: 0.1888, Total time: 27.0323\n",
      "Evaluating...\n",
      "[132:   6]: eps=0.00000000 Loss=191.2766 Time=0.0041\n",
      "Epoch 133, learning rate [0.005]\n",
      "[133:   0]: eps=0.00000000 Loss=177.5594 Time=0.0078\n",
      "[133:  10]: eps=0.00000000 Loss=200.8661 Time=0.0066\n",
      "[133:  20]: eps=0.00000000 Loss=202.7755 Time=0.0065\n",
      "[133:  25]: eps=0.00000000 Loss=198.6004 Time=0.0066\n",
      "Epoch time: 0.1895, Total time: 27.2218\n",
      "Evaluating...\n",
      "[133:   6]: eps=0.00000000 Loss=190.8641 Time=0.0044\n",
      "Epoch 134, learning rate [0.005]\n",
      "[134:   0]: eps=0.00000000 Loss=209.4835 Time=0.0069\n",
      "[134:  10]: eps=0.00000000 Loss=202.9620 Time=0.0076\n",
      "[134:  20]: eps=0.00000000 Loss=197.7727 Time=0.0077\n",
      "[134:  25]: eps=0.00000000 Loss=198.5709 Time=0.0076\n",
      "Epoch time: 0.2154, Total time: 27.4372\n",
      "Evaluating...\n",
      "[134:   6]: eps=0.00000000 Loss=190.6098 Time=0.0040\n",
      "Epoch 135, learning rate [0.005]\n",
      "[135:   0]: eps=0.00000000 Loss=237.2127 Time=0.0080\n",
      "[135:  10]: eps=0.00000000 Loss=200.8784 Time=0.0073\n",
      "[135:  20]: eps=0.00000000 Loss=200.6641 Time=0.0067\n",
      "[135:  25]: eps=0.00000000 Loss=198.1883 Time=0.0067\n",
      "Epoch time: 0.1986, Total time: 27.6358\n",
      "Evaluating...\n",
      "[135:   6]: eps=0.00000000 Loss=192.7333 Time=0.0037\n",
      "Epoch 136, learning rate [0.005]\n",
      "[136:   0]: eps=0.00000000 Loss=150.4417 Time=0.0069\n",
      "[136:  10]: eps=0.00000000 Loss=195.5124 Time=0.0069\n",
      "[136:  20]: eps=0.00000000 Loss=196.6204 Time=0.0069\n",
      "[136:  25]: eps=0.00000000 Loss=196.8761 Time=0.0066\n",
      "Epoch time: 0.1856, Total time: 27.8214\n",
      "Evaluating...\n",
      "[136:   6]: eps=0.00000000 Loss=191.4823 Time=0.0044\n",
      "Epoch 137, learning rate [0.005]\n",
      "[137:   0]: eps=0.00000000 Loss=168.7104 Time=0.0082\n",
      "[137:  10]: eps=0.00000000 Loss=199.9911 Time=0.0072\n",
      "[137:  20]: eps=0.00000000 Loss=202.9232 Time=0.0077\n",
      "[137:  25]: eps=0.00000000 Loss=198.8820 Time=0.0077\n",
      "Epoch time: 0.2242, Total time: 28.0456\n",
      "Evaluating...\n",
      "[137:   6]: eps=0.00000000 Loss=191.2432 Time=0.0046\n",
      "Epoch 138, learning rate [0.005]\n",
      "[138:   0]: eps=0.00000000 Loss=120.6105 Time=0.0072\n",
      "[138:  10]: eps=0.00000000 Loss=188.1171 Time=0.0068\n",
      "[138:  20]: eps=0.00000000 Loss=197.3281 Time=0.0067\n",
      "[138:  25]: eps=0.00000000 Loss=197.7363 Time=0.0065\n",
      "Epoch time: 0.1878, Total time: 28.2334\n",
      "Evaluating...\n",
      "[138:   6]: eps=0.00000000 Loss=190.8768 Time=0.0040\n",
      "Epoch 139, learning rate [0.005]\n",
      "[139:   0]: eps=0.00000000 Loss=197.2001 Time=0.0060\n",
      "[139:  10]: eps=0.00000000 Loss=192.3272 Time=0.0064\n",
      "[139:  20]: eps=0.00000000 Loss=194.2264 Time=0.0074\n",
      "[139:  25]: eps=0.00000000 Loss=197.7633 Time=0.0074\n",
      "Epoch time: 0.2113, Total time: 28.4447\n",
      "Evaluating...\n",
      "[139:   6]: eps=0.00000000 Loss=190.6431 Time=0.0041\n",
      "Epoch 140, learning rate [0.005]\n",
      "[140:   0]: eps=0.00000000 Loss=266.2543 Time=0.0070\n",
      "[140:  10]: eps=0.00000000 Loss=202.6629 Time=0.0069\n",
      "[140:  20]: eps=0.00000000 Loss=202.8605 Time=0.0065\n",
      "[140:  25]: eps=0.00000000 Loss=198.1553 Time=0.0062\n",
      "Epoch time: 0.1805, Total time: 28.6251\n",
      "Evaluating...\n",
      "[140:   6]: eps=0.00000000 Loss=191.2264 Time=0.0041\n",
      "Epoch 141, learning rate [0.005]\n",
      "[141:   0]: eps=0.00000000 Loss=281.7067 Time=0.0054\n",
      "[141:  10]: eps=0.00000000 Loss=197.4193 Time=0.0064\n",
      "[141:  20]: eps=0.00000000 Loss=197.3890 Time=0.0065\n",
      "[141:  25]: eps=0.00000000 Loss=197.9945 Time=0.0067\n",
      "Epoch time: 0.1916, Total time: 28.8167\n",
      "Evaluating...\n",
      "[141:   6]: eps=0.00000000 Loss=191.4320 Time=0.0051\n",
      "Epoch 142, learning rate [0.005]\n",
      "[142:   0]: eps=0.00000000 Loss=174.6511 Time=0.0098\n",
      "[142:  10]: eps=0.00000000 Loss=210.0284 Time=0.0073\n",
      "[142:  20]: eps=0.00000000 Loss=201.9519 Time=0.0069\n",
      "[142:  25]: eps=0.00000000 Loss=198.1674 Time=0.0069\n",
      "Epoch time: 0.2026, Total time: 29.0194\n",
      "Evaluating...\n",
      "[142:   6]: eps=0.00000000 Loss=192.4699 Time=0.0043\n",
      "Epoch 143, learning rate [0.005]\n",
      "[143:   0]: eps=0.00000000 Loss=176.5958 Time=0.0069\n",
      "[143:  10]: eps=0.00000000 Loss=177.9814 Time=0.0067\n",
      "[143:  20]: eps=0.00000000 Loss=197.9887 Time=0.0065\n",
      "[143:  25]: eps=0.00000000 Loss=198.7290 Time=0.0067\n",
      "Epoch time: 0.1887, Total time: 29.2081\n",
      "Evaluating...\n",
      "[143:   6]: eps=0.00000000 Loss=190.7788 Time=0.0044\n",
      "Epoch 144, learning rate [0.005]\n",
      "[144:   0]: eps=0.00000000 Loss=253.4220 Time=0.0060\n",
      "[144:  10]: eps=0.00000000 Loss=195.4080 Time=0.0074\n",
      "[144:  20]: eps=0.00000000 Loss=198.7917 Time=0.0077\n",
      "[144:  25]: eps=0.00000000 Loss=197.9027 Time=0.0075\n",
      "Epoch time: 0.2227, Total time: 29.4308\n",
      "Evaluating...\n",
      "[144:   6]: eps=0.00000000 Loss=190.6196 Time=0.0039\n",
      "Epoch 145, learning rate [0.005]\n",
      "[145:   0]: eps=0.00000000 Loss=194.9369 Time=0.0060\n",
      "[145:  10]: eps=0.00000000 Loss=208.0410 Time=0.0063\n",
      "[145:  20]: eps=0.00000000 Loss=206.5309 Time=0.0071\n",
      "[145:  25]: eps=0.00000000 Loss=198.7435 Time=0.0074\n",
      "Epoch time: 0.2133, Total time: 29.6441\n",
      "Evaluating...\n",
      "[145:   6]: eps=0.00000000 Loss=191.2112 Time=0.0043\n",
      "Epoch 146, learning rate [0.005]\n",
      "[146:   0]: eps=0.00000000 Loss=146.0862 Time=0.0084\n",
      "[146:  10]: eps=0.00000000 Loss=194.1418 Time=0.0066\n",
      "[146:  20]: eps=0.00000000 Loss=198.1376 Time=0.0065\n",
      "[146:  25]: eps=0.00000000 Loss=198.8698 Time=0.0065\n",
      "Epoch time: 0.1877, Total time: 29.8318\n",
      "Evaluating...\n",
      "[146:   6]: eps=0.00000000 Loss=190.8297 Time=0.0045\n",
      "Epoch 147, learning rate [0.005]\n",
      "[147:   0]: eps=0.00000000 Loss=236.3599 Time=0.0069\n",
      "[147:  10]: eps=0.00000000 Loss=186.6183 Time=0.0062\n",
      "[147:  20]: eps=0.00000000 Loss=199.2928 Time=0.0063\n",
      "[147:  25]: eps=0.00000000 Loss=198.0798 Time=0.0062\n",
      "Epoch time: 0.1841, Total time: 30.0159\n",
      "Evaluating...\n",
      "[147:   6]: eps=0.00000000 Loss=190.6235 Time=0.0039\n",
      "Epoch 148, learning rate [0.005]\n",
      "[148:   0]: eps=0.00000000 Loss=255.0724 Time=0.0074\n",
      "[148:  10]: eps=0.00000000 Loss=205.9482 Time=0.0075\n",
      "[148:  20]: eps=0.00000000 Loss=199.0181 Time=0.0075\n",
      "[148:  25]: eps=0.00000000 Loss=196.6927 Time=0.0073\n",
      "Epoch time: 0.2074, Total time: 30.2233\n",
      "Evaluating...\n",
      "[148:   6]: eps=0.00000000 Loss=192.3883 Time=0.0045\n",
      "Epoch 149, learning rate [0.005]\n",
      "[149:   0]: eps=0.00000000 Loss=251.3454 Time=0.0093\n",
      "[149:  10]: eps=0.00000000 Loss=190.4774 Time=0.0072\n",
      "[149:  20]: eps=0.00000000 Loss=201.4432 Time=0.0071\n",
      "[149:  25]: eps=0.00000000 Loss=198.4071 Time=0.0073\n",
      "Epoch time: 0.2114, Total time: 30.4346\n",
      "Evaluating...\n",
      "[149:   6]: eps=0.00000000 Loss=191.2311 Time=0.0051\n",
      "Epoch 150, learning rate [0.005]\n",
      "[150:   0]: eps=0.00000000 Loss=142.4504 Time=0.0075\n",
      "[150:  10]: eps=0.00000000 Loss=198.9005 Time=0.0078\n",
      "[150:  20]: eps=0.00000000 Loss=197.3848 Time=0.0077\n",
      "[150:  25]: eps=0.00000000 Loss=198.4406 Time=0.0071\n",
      "Epoch time: 0.2054, Total time: 30.6400\n",
      "Evaluating...\n",
      "[150:   6]: eps=0.00000000 Loss=190.9644 Time=0.0045\n"
     ]
    }
   ],
   "source": [
    "train_robust(model_fragile_wrap,dataloader_train,dataloader_test,method=\"natural\",args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,T_train,E_train = dataloader_train.dataset.tensors\n",
    "t = torch.linspace(0,T_train.max(),1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lifelines.ExponentialFitter:\"Exponential_estimate\", fitted with 3222 total observations, 2765 right-censored observations>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_exp = ExponentialFitter()\n",
    "clf_exp.fit(durations=T_train.ravel(),event_observed=E_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T20:21:57.396625Z",
     "start_time": "2023-11-07T20:21:56.638091Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:20: DeprecationWarning: invalid escape sequence '\\l'\n",
      "C:\\Users\\lpott\\AppData\\Local\\Temp\\ipykernel_23616\\671205530.py:20: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  plt.legend([\"Kaplan Meier Numerical\",f\"Exponential Fit $\\lambda$={np.round(1/clf_exp.params_[0],4)}\",\"Neural Network Normal\",\"Neural Network Robust\"])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "St_robust_x = clf_robust.survival_qdf(X_train,t).detach()\n",
    "St_fragile_x = clf_fragile.survival_qdf(X_train,t).detach()\n",
    "\n",
    "kmf = KaplanMeierFitter()\n",
    "kmf.fit(durations=T_train,event_observed=E_train)\n",
    "St_kmf  = kmf.predict(times=t.ravel().numpy())\n",
    "\n",
    "clf_exp = ExponentialFitter()\n",
    "clf_exp.fit(durations=T_train.ravel(),event_observed=E_train.ravel())\n",
    "St_exp = clf_exp.predict(times=t.ravel().numpy())\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(t,St_kmf)\n",
    "plt.plot(t,St_exp)\n",
    "plt.plot(t,St_fragile_x.mean(0))\n",
    "\n",
    "plt.plot(t,St_robust_x.mean(0))\n",
    "\n",
    "plt.ylabel(\"S(t)\"); plt.xlabel(\"Time\")\n",
    "plt.legend([\"Kaplan Meier Numerical\",f\"Exponential Fit $\\lambda$={np.round(1/clf_exp.params_[0],4)}\",\"Neural Network Normal\",\"Neural Network Robust\"])\n",
    "plt.title(\"Train Population Survival Curves\")\n",
    "plt.ylim([0,1.05])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exponential rate parameters:  6.208037540003017e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"Exponential rate parameters: \",1/clf_exp.params_.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rates = clf_robust(X_train).detach()\n",
    "rates = rates[rates < rates.quantile(0.95)]\n",
    "\n",
    "rates_ = clf_fragile(X_train).detach()\n",
    "rates_ = rates_[rates_ < rates_.quantile(0.95)]\n",
    "sns.histplot(rates)\n",
    "sns.histplot(rates_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_individual_lambda_histograms(clf_fragile,clf_robust,dataloader_train,suptitle=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_curve_distributions(clf_fragile,clf_robust,dataloader_train,suptitle=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_curve_distributions(clf_fragile,clf_robust,dataloader_test,suptitle=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_test = load_dataframe(ds_name=args.dataset,drop_first=True)\n",
    "from lifelines import WeibullAFTFitter\n",
    "clf_cph = WeibullAFTFitter()\n",
    "# clf_cph._scipy_fit_method = \"SLSQP\"\n",
    "clf_cph.fit(df=df_train,duration_col=\"time\",event_col=\"event\")\n",
    "kmf.plot()\n",
    "clf_cph.predict_survival_function(df_train).mean(1).plot(label=\"Weibull AFT\",figsize=(10,10))\n",
    "plt.legend()\n",
    "plt.ylim([0,1.05])\n",
    "plt.show()\n",
    "print(clf_cph.params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lifelines CPH Train CI: {:.3f}\".format(clf_cph.score(df_train,scoring_method=\"concordance_index\")))\n",
    "print(\"Lifelines CPH Test CI: {:.3f}\".format(clf_cph.score(df_test,scoring_method=\"concordance_index\")))\n",
    "\n",
    "# F_tr = 1-clf_exp.survival_function_at_times(times=T_train.ravel().numpy())\n",
    "# exp_ci_tr = concordance_index(event_times=T_train.ravel(),predicted_scores=F_tr,event_observed=E_train.ravel())\n",
    "# exp_ci_te = concordance_index(event_times=T_train.ravel(),predicted_scores=F_tr,event_observed=E_train.ravel())\n",
    "\n",
    "# print(\"Lifelines EXP Train CI: {:.3f}\".format(exp_ci_tr))\n",
    "# print(\"Lifelines EXP Test CI: {:.3f}\".format(exp_ci_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epsilons = [1,.8,0.7,.6,0.5,0.1,0.07,0.05,0]\n",
    "print(\"ROBUST CLF\")\n",
    "eps_,ci_ = concordance(clf_robust,dataloader_train,epsilons)\n",
    "plt.figure()\n",
    "plt.plot(eps_,ci_)\n",
    "plt.ylabel(\"CI\")\n",
    "plt.xlabel(\"$\\epsilon$\")\n",
    "print(\"NONROBUST CLF\")\n",
    "eps_,ci_ = concordance(clf_fragile,dataloader_train,epsilons)\n",
    "plt.plot(eps_,ci_)\n",
    "plt.ylabel(\"CI\")\n",
    "plt.xlabel(\"$\\epsilon$\")\n",
    "plt.legend([\"Robust\",\"Non Robust\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [1,.8,0.7,.6,0.5,0.1,0.07,0.05,0]\n",
    "print(\"ROBUST CLF\")\n",
    "eps_,ci_ = concordance(clf_robust,dataloader_test,epsilons)\n",
    "plt.figure()\n",
    "plt.plot(eps_,ci_)\n",
    "plt.ylabel(\"CI\")\n",
    "plt.xlabel(\"$\\epsilon$\")\n",
    "print(\"NONROBUST CLF\")\n",
    "eps_,ci_ = concordance(clf_fragile,dataloader_test,epsilons)\n",
    "plt.plot(eps_,ci_)\n",
    "plt.ylabel(\"CI\")\n",
    "plt.xlabel(\"$\\epsilon$\")\n",
    "plt.legend([\"Robust\",\"Non Robust\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [1,.8,0.7,.6,0.5,0.1,0.07,0.05]\n",
    "visualize_population_curves_attacked(clf_fragile,clf_robust,dataloader_train,epsilons=epsilons,suptitle=\"train\")\n",
    "visualize_population_curves_attacked(clf_fragile,clf_robust,dataloader_test,epsilons=epsilons,suptitle=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_individual_curves_changes(clf_robust,clf_fragile,dataloader_train,order=\"ascending\",test_cases=10)\n",
    "visualize_individual_curves_changes(clf_robust,clf_fragile,dataloader_train,order=\"descending\",test_cases=10)\n",
    "\n",
    "visualize_individual_curves_changes(clf_robust,clf_fragile,dataloader_test,order=\"ascending\",test_cases=10)\n",
    "visualize_individual_curves_changes(clf_robust,clf_fragile,dataloader_test,order=\"descending\",test_cases=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.3\n",
    "visualize_individual_curves_attacked(clf_robust,dataloader_train,epsilon=eps,order=\"descending\")\n",
    "visualize_individual_curves_attacked(clf_robust,dataloader_train,epsilon=eps,order=\"ascending\",test_cases=10)\n",
    "\n",
    "visualize_individual_curves_attacked(clf_robust,dataloader_test,epsilon=eps,order=\"descending\")\n",
    "visualize_individual_curves_attacked(clf_robust,dataloader_test,epsilon=eps,order=\"ascending\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "survival",
   "language": "python",
   "name": "survival"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
