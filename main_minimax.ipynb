{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T20:21:37.188521Z",
     "start_time": "2023-11-07T20:21:28.626293Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lpott\\anaconda3\\envs\\survival\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\lpott\\anaconda3\\envs\\survival\\lib\\site-packages\\torch\\utils\\cpp_extension.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import packaging  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "from src.models import Exponential_Model\n",
    "from src.criterion import right_censored,RightCensorWrapper\n",
    "from src.load_data import load_datasets,load_dataframe\n",
    "from src.utils import train_robust,lower_bound\n",
    "from src.visualizations import visualize_population_curves_attacked,visualize_individual_curves_attacked\n",
    "\n",
    "from torch.optim import Adam\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.utils import concordance_index\n",
    "from lifelines import CoxPHFitter\n",
    "\n",
    "from auto_LiRPA import BoundedModule, BoundedTensor\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARGS(object):\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ARGS()\n",
    "args.verify=False\n",
    "args.device=\"cpu\"\n",
    "\n",
    "args.seed = 123\n",
    "\n",
    "args.eps=0.5\n",
    "args.norm=np.inf\n",
    "args.bound_type = \"CROWN-IBP\"\n",
    "args.num_epochs=25\n",
    "args.lr = 1e-3\n",
    "args.batch_size= 128\n",
    "args.scheduler_name = \"SmoothedScheduler\"\n",
    "args.scheduler_opts = \"start=5,length=10\"\n",
    "args.hidden_dims = [15,15]\n",
    "args.save_model = \"\"\n",
    "args.dataset = \"Dialysis\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T20:21:37.272860Z",
     "start_time": "2023-11-07T20:21:37.188521Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# GOOD DATASETS\n",
    "# 1. TRACE\n",
    "# 2. divorce \n",
    "# 3. Dialysis\n",
    "dataset_train,dataset_test = load_datasets(args.dataset,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T20:21:37.295094Z",
     "start_time": "2023-11-07T20:21:37.272860Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "input_dims = dataset_train.tensors[0].shape[1]\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T20:21:37.321189Z",
     "start_time": "2023-11-07T20:21:37.297057Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5444, 74])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader_train = DataLoader(dataset_train,batch_size=args.batch_size,shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test,batch_size=args.batch_size,shuffle=False)\n",
    "\n",
    "dataloader_train.mean = dataloader_test.mean = dataset_train.mean\n",
    "dataloader_train.std = dataloader_test.std = dataset_train.std\n",
    "\n",
    "\n",
    "dataset_train.tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T20:21:37.986364Z",
     "start_time": "2023-11-07T20:21:37.318893Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "clf_robust = Exponential_Model(input_dim=input_dims,hidden_layers=args.hidden_dims)\n",
    "clf_fragile = Exponential_Model(input_dim=input_dims,hidden_layers=args.hidden_dims)\n",
    "clf_fragile.load_state_dict(deepcopy(clf_robust.state_dict()))\n",
    "\n",
    "\n",
    "# model = BoundedModule(clf, X_train)\n",
    "model_robust_wrap = BoundedModule(RightCensorWrapper(clf_robust),dataset_train.tensors)\n",
    "model_fragile_wrap = BoundedModule(RightCensorWrapper(clf_fragile),dataset_train.tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lpott\\anaconda3\\envs\\survival\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:371: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, learning rate [0.001]\n",
      "[ 1:   0]: eps=0.00000000 Loss=1850.1527 Time=0.0020\n",
      "[ 1:  10]: eps=0.00000000 Loss=1868.9953 Time=0.0023\n",
      "[ 1:  20]: eps=0.00000000 Loss=1794.7013 Time=0.0022\n",
      "[ 1:  30]: eps=0.00000000 Loss=1713.6873 Time=0.0022\n",
      "[ 1:  40]: eps=0.00000000 Loss=1631.3091 Time=0.0022\n",
      "[ 1:  42]: eps=0.00000000 Loss=1608.4964 Time=0.0021\n",
      "Epoch time: 0.1135, Total time: 0.1135\n",
      "Evaluating...\n",
      "[ 1:  10]: eps=0.00000000 Loss=1209.5594 Time=0.0010\n",
      "Epoch 2, learning rate [0.001]\n",
      "[ 2:   0]: eps=0.00000000 Loss=1068.3817 Time=0.0022\n",
      "[ 2:  10]: eps=0.00000000 Loss=1144.3256 Time=0.0021\n",
      "[ 2:  20]: eps=0.00000000 Loss=1043.7619 Time=0.0020\n",
      "[ 2:  30]: eps=0.00000000 Loss=949.4128 Time=0.0019\n",
      "[ 2:  40]: eps=0.00000000 Loss=856.8435 Time=0.0020\n",
      "[ 2:  42]: eps=0.00000000 Loss=838.6754 Time=0.0020\n",
      "Epoch time: 0.1073, Total time: 0.2208\n",
      "Evaluating...\n",
      "[ 2:  10]: eps=0.00000000 Loss=443.8868 Time=0.0012\n",
      "Epoch 3, learning rate [0.001]\n",
      "[ 3:   0]: eps=0.00000000 Loss=436.5890 Time=0.0021\n",
      "[ 3:  10]: eps=0.00000000 Loss=404.9032 Time=0.0021\n",
      "[ 3:  20]: eps=0.00000000 Loss=360.4840 Time=0.0021\n",
      "[ 3:  30]: eps=0.00000000 Loss=330.0954 Time=0.0021\n",
      "[ 3:  40]: eps=0.00000000 Loss=304.2630 Time=0.0020\n",
      "[ 3:  42]: eps=0.00000000 Loss=299.3275 Time=0.0020\n",
      "Epoch time: 0.1062, Total time: 0.3270\n",
      "Evaluating...\n",
      "[ 3:  10]: eps=0.00000000 Loss=197.2009 Time=0.0011\n",
      "Epoch 4, learning rate [0.001]\n",
      "[ 4:   0]: eps=0.00000000 Loss=200.2263 Time=0.0023\n",
      "[ 4:  10]: eps=0.00000000 Loss=191.2490 Time=0.0021\n",
      "[ 4:  20]: eps=0.00000000 Loss=183.2150 Time=0.0021\n",
      "[ 4:  30]: eps=0.00000000 Loss=178.2453 Time=0.0022\n",
      "[ 4:  40]: eps=0.00000000 Loss=176.6398 Time=0.0022\n",
      "[ 4:  42]: eps=0.00000000 Loss=175.5396 Time=0.0022\n",
      "Epoch time: 0.1163, Total time: 0.4432\n",
      "Evaluating...\n",
      "[ 4:  10]: eps=0.00000000 Loss=154.9636 Time=0.0013\n",
      "Epoch 5, learning rate [0.001]\n",
      "[ 5:   0]: eps=0.00000000 Loss=147.7418 Time=0.0020\n",
      "[ 5:  10]: eps=0.00000292 Loss=145.2777 Time=0.0407 Robust_Loss=145.0316\n",
      "[ 5:  20]: eps=0.00004668 Loss=149.5913 Time=0.0417 Robust_Loss=149.6877\n",
      "[ 5:  30]: eps=0.00023631 Loss=151.5586 Time=0.0421 Robust_Loss=151.7046\n",
      "[ 5:  40]: eps=0.00074686 Loss=152.6103 Time=0.0424 Robust_Loss=152.7897\n",
      "[ 5:  42]: eps=0.00090782 Loss=152.0194 Time=0.0422 Robust_Loss=152.1872\n",
      "Epoch time: 1.8486, Total time: 2.2918\n",
      "Evaluating...\n",
      "[ 5:  10]: eps=0.00090782 Loss=144.9341 Robust_Loss=145.2432 Time=0.0206\n",
      "Epoch 6, learning rate [0.001]\n",
      "[ 6:   0]: eps=0.00099741 Loss=155.5384 Robust_Loss=155.9094 Time=0.0443\n",
      "[ 6:  10]: eps=0.00230200 Loss=143.0742 Robust_Loss=143.6501 Time=0.0443\n",
      "[ 6:  20]: eps=0.00459582 Loss=149.6050 Robust_Loss=150.4888 Time=0.0440\n",
      "[ 6:  30]: eps=0.00828500 Loss=148.3500 Robust_Loss=149.7023 Time=0.0441\n",
      "[ 6:  40]: eps=0.01384565 Loss=148.6560 Robust_Loss=150.6940 Time=0.0436\n",
      "[ 6:  42]: eps=0.01522918 Loss=147.2346 Robust_Loss=149.3613 Time=0.0434\n",
      "Epoch time: 1.8948, Total time: 4.1866\n",
      "Evaluating...\n",
      "[ 6:  10]: eps=0.01522918 Loss=146.7862 Robust_Loss=152.3796 Time=0.0204\n",
      "Epoch 7, learning rate [0.001]\n",
      "[ 7:   0]: eps=0.01595860 Loss=138.2967 Robust_Loss=144.0572 Time=0.0402\n",
      "[ 7:  10]: eps=0.02477912 Loss=156.3666 Robust_Loss=164.5911 Time=0.0422\n",
      "[ 7:  20]: eps=0.03683193 Loss=155.7357 Robust_Loss=166.6341 Time=0.0422\n",
      "[ 7:  30]: eps=0.05110793 Loss=160.5433 Robust_Loss=176.2460 Time=0.0426\n",
      "[ 7:  40]: eps=0.06540386 Loss=167.1273 Robust_Loss=190.6837 Time=0.0427\n",
      "[ 7:  42]: eps=0.06826305 Loss=167.2283 Robust_Loss=191.9774 Time=0.0426\n",
      "Epoch time: 1.8630, Total time: 6.0496\n",
      "Evaluating...\n",
      "[ 7:  10]: eps=0.06826305 Loss=203.4396 Robust_Loss=267.2112 Time=0.0224\n",
      "Epoch 8, learning rate [0.001]\n",
      "[ 8:   0]: eps=0.06969264 Loss=216.5521 Robust_Loss=291.9614 Time=0.0465\n",
      "[ 8:  10]: eps=0.08398856 Loss=215.6914 Robust_Loss=294.0470 Time=0.0463\n",
      "[ 8:  20]: eps=0.09828449 Loss=232.5865 Robust_Loss=323.1859 Time=0.0452\n",
      "[ 8:  30]: eps=0.11258041 Loss=246.4272 Robust_Loss=348.0155 Time=0.0446\n",
      "[ 8:  40]: eps=0.12687634 Loss=251.2948 Robust_Loss=360.2857 Time=0.0444\n",
      "[ 8:  42]: eps=0.12973553 Loss=250.7490 Robust_Loss=360.1133 Time=0.0442\n",
      "Epoch time: 1.9333, Total time: 7.9829\n",
      "Evaluating...\n",
      "[ 8:  10]: eps=0.12973553 Loss=280.9254 Robust_Loss=422.9133 Time=0.0208\n",
      "Epoch 9, learning rate [0.001]\n",
      "[ 9:   0]: eps=0.13116512 Loss=266.5295 Robust_Loss=404.4690 Time=0.0465\n",
      "[ 9:  10]: eps=0.14546104 Loss=296.0360 Robust_Loss=452.6323 Time=0.0434\n",
      "[ 9:  20]: eps=0.15975697 Loss=313.4684 Robust_Loss=483.0940 Time=0.0431\n",
      "[ 9:  30]: eps=0.17405289 Loss=322.5765 Robust_Loss=501.6622 Time=0.0430\n",
      "[ 9:  40]: eps=0.18834882 Loss=330.4106 Robust_Loss=518.7627 Time=0.0422\n",
      "[ 9:  42]: eps=0.19120801 Loss=329.2842 Robust_Loss=517.7003 Time=0.0420\n",
      "Epoch time: 1.8338, Total time: 9.8167\n",
      "Evaluating...\n",
      "[ 9:  10]: eps=0.19120801 Loss=360.0422 Robust_Loss=581.1546 Time=0.0186\n",
      "Epoch 10, learning rate [0.001]\n",
      "[10:   0]: eps=0.19263760 Loss=446.4980 Robust_Loss=709.6628 Time=0.0382\n",
      "[10:  10]: eps=0.20693352 Loss=384.4866 Robust_Loss=626.9654 Time=0.0404\n",
      "[10:  20]: eps=0.22122945 Loss=386.8943 Robust_Loss=632.8989 Time=0.0400\n",
      "[10:  30]: eps=0.23552538 Loss=394.2596 Robust_Loss=646.5792 Time=0.0398\n",
      "[10:  40]: eps=0.24982130 Loss=400.0793 Robust_Loss=658.3846 Time=0.0398\n",
      "[10:  42]: eps=0.25268049 Loss=398.8220 Robust_Loss=656.4504 Time=0.0396\n",
      "Epoch time: 1.7354, Total time: 11.5521\n",
      "Evaluating...\n",
      "[10:  10]: eps=0.25268049 Loss=402.0582 Robust_Loss=664.6473 Time=0.0196\n",
      "Epoch 11, learning rate [0.001]\n",
      "[11:   0]: eps=0.25411008 Loss=383.5967 Robust_Loss=645.7348 Time=0.0373\n",
      "[11:  10]: eps=0.26840600 Loss=412.6157 Robust_Loss=684.4074 Time=0.0385\n",
      "[11:  20]: eps=0.28270193 Loss=424.0685 Robust_Loss=705.1021 Time=0.0385\n",
      "[11:  30]: eps=0.29699786 Loss=425.3669 Robust_Loss=709.0504 Time=0.0388\n",
      "[11:  40]: eps=0.31129378 Loss=428.1264 Robust_Loss=714.6445 Time=0.0389\n",
      "[11:  42]: eps=0.31415297 Loss=427.3661 Robust_Loss=713.2218 Time=0.0389\n",
      "Epoch time: 1.6933, Total time: 13.2454\n",
      "Evaluating...\n",
      "[11:  10]: eps=0.31415297 Loss=425.0432 Robust_Loss=710.1356 Time=0.0193\n",
      "Epoch 12, learning rate [0.001]\n",
      "[12:   0]: eps=0.31558256 Loss=406.9180 Robust_Loss=694.0367 Time=0.0391\n",
      "[12:  10]: eps=0.32987848 Loss=436.6122 Robust_Loss=738.0832 Time=0.0407\n",
      "[12:  20]: eps=0.34417441 Loss=441.8510 Robust_Loss=745.6851 Time=0.0402\n",
      "[12:  30]: eps=0.35847034 Loss=451.2981 Robust_Loss=760.3265 Time=0.0402\n",
      "[12:  40]: eps=0.37276626 Loss=455.1243 Robust_Loss=767.6927 Time=0.0400\n",
      "[12:  42]: eps=0.37562545 Loss=453.9704 Robust_Loss=765.7554 Time=0.0399\n",
      "Epoch time: 1.7472, Total time: 14.9926\n",
      "Evaluating...\n",
      "[12:  10]: eps=0.37562545 Loss=457.9504 Robust_Loss=775.1857 Time=0.0193\n",
      "Epoch 13, learning rate [0.001]\n",
      "[13:   0]: eps=0.37705504 Loss=476.4418 Robust_Loss=809.5333 Time=0.0386\n",
      "[13:  10]: eps=0.39135096 Loss=458.3976 Robust_Loss=781.9498 Time=0.0398\n",
      "[13:  20]: eps=0.40564689 Loss=471.2391 Robust_Loss=802.5284 Time=0.0398\n",
      "[13:  30]: eps=0.41994282 Loss=486.5916 Robust_Loss=830.3173 Time=0.0396\n",
      "[13:  40]: eps=0.43423874 Loss=491.1595 Robust_Loss=839.6944 Time=0.0398\n",
      "[13:  42]: eps=0.43709793 Loss=491.4198 Robust_Loss=840.0030 Time=0.0397\n",
      "Epoch time: 1.7425, Total time: 16.7351\n",
      "Evaluating...\n",
      "[13:  10]: eps=0.43709793 Loss=497.3446 Robust_Loss=853.0659 Time=0.0197\n",
      "Epoch 14, learning rate [0.001]\n",
      "[14:   0]: eps=0.43852752 Loss=459.1584 Robust_Loss=793.2056 Time=0.0400\n",
      "[14:  10]: eps=0.45282345 Loss=515.4780 Robust_Loss=886.8963 Time=0.0412\n",
      "[14:  20]: eps=0.46711937 Loss=529.2920 Robust_Loss=911.6105 Time=0.0409\n",
      "[14:  30]: eps=0.48141530 Loss=528.8667 Robust_Loss=912.8159 Time=0.0411\n",
      "[14:  40]: eps=0.49571122 Loss=531.9444 Robust_Loss=918.9436 Time=0.0409\n",
      "[14:  42]: eps=0.49857041 Loss=529.3722 Robust_Loss=914.7330 Time=0.0408\n",
      "Epoch time: 1.7833, Total time: 18.5184\n",
      "Evaluating...\n",
      "[14:  10]: eps=0.49857041 Loss=532.8271 Robust_Loss=922.6996 Time=0.0198\n",
      "Epoch 15, learning rate [0.001]\n",
      "[15:   0]: eps=0.50000000 Loss=593.5365 Robust_Loss=1017.6982 Time=0.0407\n",
      "[15:  10]: eps=0.50000000 Loss=549.0871 Robust_Loss=948.9556 Time=0.0401\n",
      "[15:  20]: eps=0.50000000 Loss=529.5245 Robust_Loss=915.2719 Time=0.0411\n",
      "[15:  30]: eps=0.50000000 Loss=529.1154 Robust_Loss=911.7651 Time=0.0428\n",
      "[15:  40]: eps=0.50000000 Loss=519.6027 Robust_Loss=893.9864 Time=0.0438\n",
      "[15:  42]: eps=0.50000000 Loss=515.0192 Robust_Loss=885.7434 Time=0.0436\n",
      "Epoch time: 1.9007, Total time: 20.4191\n",
      "Evaluating...\n",
      "[15:  10]: eps=0.50000000 Loss=482.4887 Robust_Loss=821.8241 Time=0.0194\n",
      "Epoch 16, learning rate [0.001]\n",
      "[16:   0]: eps=0.50000000 Loss=469.5465 Robust_Loss=799.2479 Time=0.0449\n",
      "[16:  10]: eps=0.50000000 Loss=481.4779 Robust_Loss=819.9866 Time=0.0422\n",
      "[16:  20]: eps=0.50000000 Loss=494.2721 Robust_Loss=839.6360 Time=0.0416\n",
      "[16:  30]: eps=0.50000000 Loss=479.7936 Robust_Loss=814.8384 Time=0.0412\n",
      "[16:  40]: eps=0.50000000 Loss=476.2152 Robust_Loss=807.5343 Time=0.0410\n",
      "[16:  42]: eps=0.50000000 Loss=472.5536 Robust_Loss=801.0635 Time=0.0408\n",
      "Epoch time: 1.7872, Total time: 22.2063\n",
      "Evaluating...\n",
      "[16:  10]: eps=0.50000000 Loss=450.6367 Robust_Loss=758.5717 Time=0.0193\n",
      "Epoch 17, learning rate [0.001]\n",
      "[17:   0]: eps=0.50000000 Loss=417.1362 Robust_Loss=710.6800 Time=0.0398\n",
      "[17:  10]: eps=0.50000000 Loss=468.3747 Robust_Loss=787.0912 Time=0.0396\n",
      "[17:  20]: eps=0.50000000 Loss=458.1625 Robust_Loss=769.4816 Time=0.0396\n",
      "[17:  30]: eps=0.50000000 Loss=457.1671 Robust_Loss=766.5590 Time=0.0402\n",
      "[17:  40]: eps=0.50000000 Loss=450.2655 Robust_Loss=754.9849 Time=0.0403\n",
      "[17:  42]: eps=0.50000000 Loss=445.5282 Robust_Loss=747.0745 Time=0.0403\n",
      "Epoch time: 1.7659, Total time: 23.9721\n",
      "Evaluating...\n",
      "[17:  10]: eps=0.50000000 Loss=427.5719 Robust_Loss=712.7485 Time=0.0186\n",
      "Epoch 18, learning rate [0.001]\n",
      "[18:   0]: eps=0.50000000 Loss=406.1389 Robust_Loss=687.5530 Time=0.0407\n",
      "[18:  10]: eps=0.50000000 Loss=431.7187 Robust_Loss=720.2722 Time=0.0415\n",
      "[18:  20]: eps=0.50000000 Loss=428.4494 Robust_Loss=713.9158 Time=0.0410\n",
      "[18:  30]: eps=0.50000000 Loss=433.4645 Robust_Loss=720.5988 Time=0.0409\n",
      "[18:  40]: eps=0.50000000 Loss=428.7361 Robust_Loss=712.5143 Time=0.0407\n",
      "[18:  42]: eps=0.50000000 Loss=424.6007 Robust_Loss=705.7663 Time=0.0406\n",
      "Epoch time: 1.7749, Total time: 25.7471\n",
      "Evaluating...\n",
      "[18:  10]: eps=0.50000000 Loss=410.5306 Robust_Loss=678.9448 Time=0.0200\n",
      "Epoch 19, learning rate [0.001]\n",
      "[19:   0]: eps=0.50000000 Loss=499.5482 Robust_Loss=818.0414 Time=0.0399\n",
      "[19:  10]: eps=0.50000000 Loss=434.2011 Robust_Loss=715.8823 Time=0.0400\n",
      "[19:  20]: eps=0.50000000 Loss=420.8991 Robust_Loss=693.9772 Time=0.0401\n"
     ]
    }
   ],
   "source": [
    "train_robust(model_robust_wrap,dataloader_train,dataloader_test,method=\"robust\",args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_robust(model_fragile_wrap,dataloader_train,dataloader_test,method=\"natural\",args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T20:21:57.396625Z",
     "start_time": "2023-11-07T20:21:56.638091Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_train,T_train,E_train = dataloader_train.dataset.tensors\n",
    "t = torch.linspace(0,T_train.max(),10000)\n",
    "\n",
    "St_robust_x = clf_robust.survival_qdf(X_train,t).detach()\n",
    "St_fragile_x = clf_fragile.survival_qdf(X_train,t).detach()\n",
    "\n",
    "kmf = KaplanMeierFitter()\n",
    "kmf.fit(durations=T_train,event_observed=E_train)\n",
    "St_kmf  = kmf.predict(times=t.ravel().numpy())\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(t,St_kmf)\n",
    "plt.plot(t,St_fragile_x.mean(0))\n",
    "plt.plot(t,St_robust_x.mean(0))\n",
    "\n",
    "plt.ylabel(\"S(t)\"); plt.xlabel(\"Time\")\n",
    "plt.legend([\"Kaplan Meier Numerical\",\"Neural Network Normal\",\"Neural Network Robust\"])\n",
    "plt.title(\"Train Population Survival Curves\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [1,.8,0.7,.6,0.5,0.1,0.07,0.05]\n",
    "visualize_population_curves_attacked(clf_fragile,clf_robust,dataloader_train,epsilons=epsilons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [1,.8,0.7,.6,0.5,0.1,0.07,0.05]\n",
    "visualize_population_curves_attacked(clf_fragile,clf_robust,dataloader_test,epsilons=epsilons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_individual_curves_attacked(clf_robust,dataloader_train,epsilon=0.3,order=\"ascending\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_individual_curves_attacked(clf_robust,dataloader_train,epsilon=0.3,order=\"descending\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_individual_curves_attacked(clf_robust,dataloader_test,epsilon=0.3,order=\"ascending\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_individual_curves_attacked(clf_robust,dataloader_test,epsilon=0.3,order=\"descending\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb,ub = lower_bound(clf_robust,dataset_test.,0.1)\n",
    "St_lb = torch.exp(-ub*t).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "\n",
    "St_robust_x = clf_robust.survival_qdf(X_train, t).detach()\n",
    "\n",
    "test_cases = 30\n",
    "\n",
    "colors = list(plt.cm.brg(np.linspace(0,1,test_cases))) + [\"crimson\", \"indigo\"]\n",
    "\n",
    "cases = np.argsort(torch.linalg.norm(St_lb - St_given_x,axis=1))[0:test_cases]\n",
    "print(torch.linalg.norm(St_lb - St_given_x,axis=1)[cases])\n",
    "\n",
    "for i,case in enumerate(tqdm(cases)):\n",
    "    plt.plot(t,St_given_x[case],color=colors[i])\n",
    "    plt.plot(t,St_lb[case],'--',color=colors[i])\n",
    "    \n",
    "plt.ylabel(\"S(t)\"); plt.xlabel(\"Time\")\n",
    "plt.title(\"Individual Survival Curves Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "# lb,ub = lower_bound(model,X_train,0.1)\n",
    "    \n",
    "test_cases = 30\n",
    "cases = torch.flip(np.argsort(torch.linalg.norm(St_lb - St_given_x,axis=1)),dims=(0,))[0:test_cases]\n",
    "print(torch.linalg.norm(St_lb - St_given_x,axis=1)[cases])\n",
    "for i,case in enumerate(tqdm(cases)):\n",
    "    plt.plot(t,St_given_x[case],color=colors[i])\n",
    "    plt.plot(t,St_lb[case],'--',color=colors[i])\n",
    "    \n",
    "plt.ylabel(\"S(t)\"); plt.xlabel(\"Time\")\n",
    "plt.title(\"Individual Survival Curves Train\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "survival",
   "language": "python",
   "name": "survival"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
