{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e065a4a9-2131-476d-8da5-02a43c1744e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1331ab-1ded-4f58-8250-001c66080009",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = \"crownibp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be64572-2a34-463b-b2cd-b6d34a38fd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = rf\"results\\{attack}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd347dbe-1270-4945-b60b-32c5739eb660",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\"baseline\",\"noise\",\"fgsm\",\"pgd\",\"crownibp\"]\n",
    "exclude_datasets = [\"Dialysis\",\"divorce\",\"Pbc3\",\"vlbw\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d10bf9-8e60-4753-98ea-7108bd93cab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CI , IBS , NegLL\n",
    "metric = \"CI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9251f37-53d4-41d0-81c2-a09a39320674",
   "metadata": {},
   "outputs": [],
   "source": [
    "ascending = False if metric==\"CI\" else True\n",
    "\n",
    " # aggregate all the CI files\n",
    "os.listdir(results_folder)\n",
    "excels = []\n",
    "for folder in os.listdir(results_folder):\n",
    "    glob_search = os.path.join(results_folder,folder,\"*\",f\"{metric}.xlsx\")\n",
    "    excels.extend(glob.glob(glob_search))\n",
    "\n",
    "for dataset in exclude_datasets:\n",
    "    for exceli in excels:\n",
    "        if dataset in exceli:\n",
    "            print(\"remove \",dataset)\n",
    "            excels.remove(exceli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f4016f-3baf-468c-8909-3654a94fb508",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(excels)/(len(algorithms)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a35883-e290-4a56-9052-77a5f9c1dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "N_datasets = len(excels)\n",
    "percentage_change = []\n",
    "# print(excels)\n",
    "for excel_i in excels:\n",
    "\n",
    "    temp_df = pd.read_excel(excel_i)\n",
    "    folder_name,dataset_name = excel_i.split(\"\\\\\")[-3:-1]\n",
    "    print(folder_name,dataset_name)\n",
    "    \n",
    "    temp_df.columns = [\"eps\"] + temp_df.columns[1:].to_list()\n",
    "    col_name = (dataset_name,re.sub(\"results_\",\"\",folder_name))\n",
    "    df[col_name] = temp_df[f\"Robust {metric}\"] #temp_df[\"Non Robust CI\"].round(3).astype(str) + \" / \" + temp_df[\"Robust CI\"].round(3).astype(str)\n",
    "\n",
    "    col_name = (dataset_name,\"baseline\")\n",
    "    df[col_name] = temp_df[f\"Non Robust {metric}\"]\n",
    "\n",
    "df.index = temp_df.eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acbf696-9d7d-4836-b1c5-2ee40ea9322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "micolumns = pd.MultiIndex.from_tuples(df.columns)\n",
    "dfmi = (\n",
    "    pd.DataFrame(\n",
    "        df.values,\n",
    "        index=df.index,\n",
    "        columns=micolumns,\n",
    "    )\n",
    "    .sort_index()\n",
    "    .sort_index(axis=1)\n",
    ")\n",
    "\n",
    "dfmi.sort_values(by=\"eps\",ascending=False,inplace=True)\n",
    "dfmi = dfmi.reindex(columns=algorithms, level=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af346d05-afc8-4d5e-8378-3f59e2272b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmi[dfmi==''] = np.NaN\n",
    "dfmi = dfmi.astype(float)\n",
    "dfmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c831718-05ef-4454-af78-6dc68792b04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfmi.T.groupby(axis=0,level=0).rank(axis=0,na_option='bottom',method=\"average\",ascending=ascending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac1dcc-6af4-454b-97c4-0e087966a5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,sub_df in dfmi.groupby(level=0,axis=1):\n",
    "#     print(sub_df,sub_df.columns)\n",
    "#     print(sub_df.rank(axis=1,ascending=ascending))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e1324d-b8e8-41dc-ba5e-a645bcf2a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_per_dataset_rank = dfmi.groupby(level=0,axis=1).rank(axis=0,na_option='bottom',method=\"average\",ascending=ascending)\n",
    "best_per_dataset_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6704e3a-5f62-4994-bc88-991e14b8d6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_per_dataset_rank.stack(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf5423e-ed95-4861-86e5-a7d3e29f1d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_per_dataset_avg_rank = best_per_dataset_rank.stack(level=1).mean(1).unstack(1).sort_values(by=\"eps\",ascending=False)\n",
    "best_per_dataset_avg_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcd1ec8-1873-423c-9a1d-71338024672b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not ascending:\n",
    "    best_per_dataset = dfmi.groupby(level=0,axis=1).idxmax(1)\n",
    "else:\n",
    "    best_per_dataset = dfmi.groupby(level=0,axis=1).idxmin(1)\n",
    "best_per_dataset.applymap(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1514074b-3ad9-4c71-8f50-ee17575a4d13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if metric != \"NegLL\":\n",
    "     # aggregate all the CI files\n",
    "    os.listdir(results_folder)\n",
    "    excels = []\n",
    "    for folder in os.listdir(results_folder):\n",
    "        glob_search = os.path.join(results_folder,folder,f\"{metric}_all.xlsx\")\n",
    "        excels.extend(glob.glob(glob_search))\n",
    "        \n",
    "    df = pd.DataFrame()\n",
    "    N_datasets = len(excels)\n",
    "    percentage_change = []\n",
    "    for excel_i in excels:\n",
    "    \n",
    "        temp_df = pd.read_excel(excel_i)\n",
    "        folder_name = excel_i.split(\"\\\\\")[-2]\n",
    "        temp_df.columns = [\"eps\"] + temp_df.columns[1:].to_list()\n",
    "        col_name = re.sub(\"results_\",\"\",folder_name)\n",
    "        df[col_name] = temp_df[\"%\"] #temp_df[\"Non Robust CI\"].round(3).astype(str) + \" / \" + temp_df[\"Robust CI\"].round(3).astype(str)\n",
    "    \n",
    "    df.index = temp_df.eps\n",
    "    df = df.reindex(columns=algorithms[1:], level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7391302-cb50-4eb4-bcd0-88ddfe363eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aafa024-7d1a-4669-bc64-4e5d8956a359",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_name = os.path.join(results_folder,f\"{metric}_all.xlsx\")\n",
    "with pd.ExcelWriter(excel_name) as writer:  \n",
    "    dfmi.applymap(lambda x: np.round(x,3)).to_excel(writer,sheet_name=metric)\n",
    "    best_per_dataset_rank.to_excel(writer,sheet_name=\"rank\")\n",
    "    best_per_dataset_avg_rank.to_excel(writer,sheet_name=\"average_rank\")\n",
    "    best_per_dataset.applymap(lambda x: x[1]).to_excel(writer,sheet_name=\"best\")\n",
    "    df.to_excel(writer,sheet_name=\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b0ed20-b49b-4eb3-9b39-8f4461207f01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_per_dataset_avg_rank.index = [\"{:.2f}\".format(float(x)) for x in np.round(best_per_dataset_avg_rank.index.tolist(),2)]\n",
    "best_per_dataset_avg_rank.index.name = r\"$\\epsilon$\"\n",
    "print(best_per_dataset_avg_rank.applymap(lambda x: str(np.round(x,2))).to_latex(index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5596d7-b858-4c23-9a08-e55ea6253690",
   "metadata": {},
   "outputs": [],
   "source": [
    "if metric == \"NegLL\":\n",
    "    dfmi.index = [\"{:.2f}\".format(float(x)) for x in np.round(dfmi.index.tolist(),2)]\n",
    "    dfmi.index.name = r\"$\\epsilon$\"\n",
    "    print(dfmi.applymap(lambda x: np.round(x,3)).applymap(lambda x: \"{:.2e}\".format(x)).to_latex(index=True,multicolumn_format=\"c\"))\n",
    "else:\n",
    "    dfmi.index = [\"{:.2f}\".format(float(x)) for x in np.round(dfmi.index.tolist(),2)]\n",
    "    dfmi.index.name = r\"$\\epsilon$\"\n",
    "    print(dfmi.applymap(lambda x: np.round(x,3)).applymap(str).to_latex(index=True,multicolumn_format=\"c\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82709563-3cca-48b1-813f-c7c6645ff89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = np.array(list(map(np.array,dfmi.columns)))[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58a1845-2539-4d08-9678-3340e4a4d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a5c57a-575f-438f-bc10-a535042e90e9",
   "metadata": {},
   "source": [
    "## LONG TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87b7428-767d-49a1-8c9e-d6fc4272b2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmi.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4427e52-2b65-45c5-9b2c-04843fc5b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if metric == \"NegLL\":\n",
    "    print(dfmi.T.applymap(lambda x: str(np.round(x,3))).applymap(lambda x: \"{:.2e}\".format(float(x))).to_latex(index=True,multicolumn_format=\"c\"))\n",
    "else:\n",
    "    print(dfmi.T.applymap(lambda x: str(np.round(x,3))).to_latex(index=True,multicolumn_format=\"c\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebfee1f-c465-4b77-994f-d326b8768e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dfmi.T.swaplevel(i=1,j=0,axis=0).groupby(level=0).mean().applymap(lambda x: str(np.round(x,3))).reindex(algorithms).to_latex(index=True,multicolumn_format=\"c\"))\n",
    "\n",
    "if metric == \"NegLL\":\n",
    "    print(dfmi.T.swaplevel(i=1,j=0,axis=0).groupby(level=0).mean().applymap(lambda x: \"{:.2e}\".format(float(x))).reindex(algorithms).to_latex(index=True,multicolumn_format=\"c\"))\n",
    "else:\n",
    "    print(dfmi.T.swaplevel(i=1,j=0,axis=0).groupby(level=0).mean().applymap(lambda x: str(np.round(x,3))).reindex(algorithms).to_latex(index=True,multicolumn_format=\"c\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a3e14e-487e-418b-b871-c913d308289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmi.T.swaplevel(i=1,j=0,axis=0).groupby(level=0).mean().reindex(algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e40bdb1-c6f5-41da-a61b-77f891fc0e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmi.T.groupby(level=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255dcaf5-9e8e-4b16-b0c8-2bdc19970a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)\n",
    "# print(dfmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db90803b-fdbd-4e00-ac7e-d43e178975e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_per_dataset.applymap(lambda x: x[1]).to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d096ee58-6555-4e03-bd18-222cfff1c7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = [\"{:.2f}\".format(float(x)) for x in np.round(df.index.tolist(),2)]\n",
    "df.index.name = r\"$\\epsilon$\"\n",
    "print(df.applymap(lambda x: str(np.round(x,3))).to_latex(index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f36df45-1687-42cb-8093-cd21437389e0",
   "metadata": {},
   "source": [
    "## PDF PICTURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8312dafc-d6c1-4c21-b40b-7b00e1c6337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4114dd05-aaf3-4754-90c2-9f4009228565",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = \"crownibp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a0c130-8994-49e5-8904-84c103076e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = rf\"results\\{attack}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265d7433-76f9-47cd-a0b5-832694f8aae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\"baseline\",\"noise\",\"fgsm\",\"pgd\",\"crownibp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8391462-5f05-4702-a027-f04934cec980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CI , IBS , NegLL\n",
    "img_name = \"population_curves_attacked_test\"\n",
    "\n",
    " # aggregate all the CI files\n",
    "os.listdir(results_folder)\n",
    "excels = []\n",
    "for folder in os.listdir(results_folder):\n",
    "    glob_search = os.path.join(results_folder,folder,\"*\",f\"{img_name}.xlsx\")\n",
    "    excels.extend(glob.glob(glob_search))\n",
    "\n",
    "for dataset in exclude_datasets:\n",
    "    for exceli in excels:\n",
    "        if dataset in exceli:\n",
    "            print(\"remove \",dataset)\n",
    "            excels.remove(exceli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7288c447-d28e-45d8-b91d-4133a921038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = 'eps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770f8e62-f2c4-4682-93f5-4e3fb9062d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = int(len(excels) / (len(algorithms)-1))\n",
    "n_cols = int(len(algorithms) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80835675-ddf2-4953-9107-b7b2d0c04155",
   "metadata": {},
   "outputs": [],
   "source": [
    "excels = np.sort(excels)\n",
    "files = pd.DataFrame(excels.reshape(-1,len(algorithms)-1,order=\"F\"),columns=[\"crownibp\",\"fgsm\",\"noise\",\"pgd\"]).reindex([\"noise\",\"fgsm\",\"pgd\",\"crownibp\"],axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e014551-4206-477a-adb8-4b2ef1232568",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_population = pd.read_excel(excels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cb7508-bbe0-49bc-b8c3-eee20f67739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b4fb45-437f-41a4-bd2d-dca843b3dcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = results_folder = os.path.join(fr\"C:\\Users\\lpott\\OneDrive\\Documents\\Northeastern University\\Classes\\EECE 7398 Verifiable Machine Learning\\EECE7398_Final_Project\\results\\{attack}\",\"perturb_curves.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ae4752-d436-48b5-8ace-2a484ba19bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27b37ce-32f4-4c5a-b27e-f59da29dbab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = results_folder = os.path.join(r\"C:\\Users\\lpott\\OneDrive\\Documents\\Northeastern University\\Classes\\EECE 7398 Verifiable Machine Learning\\EECE7398_Final_Project\\results\",attack,\"perturb_curves.pdf\")\n",
    "\n",
    "fig,axes = plt.subplots(n_rows,n_cols+1,figsize=(30,64),sharey=True)\n",
    "\n",
    "SMALL_SIZE = 80\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE//2)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE//2)  \n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=SMALL_SIZE)     # fontsize of the x and y labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=SMALL_SIZE)   # fontsize of the figure title\n",
    "\n",
    "\n",
    "for i in range(n_rows):\n",
    "    for j in range(n_cols):\n",
    "        print(i,j)\n",
    "        fileij = files[i][j]\n",
    "        algo,dataset = fileij.split(\"\\\\\")[-3:-1]\n",
    "        algo = re.sub(\"results_\",\"\",algo)\n",
    "\n",
    "        df_population = pd.read_excel(fileij)\n",
    "\n",
    "        t = df_population.pop(\"t\")\n",
    "        base_models = df_population.iloc[:,:3]\n",
    "        base_models.columns = [col.split(\"_\")[0] for col in base_models.columns]\n",
    "        \n",
    "        df_population= df_population.iloc[:,3:]\n",
    "\n",
    "        robust_idx = [\"robust\" in col for col in df_population.columns]\n",
    "        baseline_idx = [\"baseline\" in col for col in df_population.columns]\n",
    "        robust_df = df_population.iloc[:,robust_idx]\n",
    "        baseline_df = df_population.iloc[:,baseline_idx]\n",
    "        \n",
    "        robust_df.columns = [\"$\\epsilon$={:.2f}\".format(eval(col.split(\"=\")[1])) for col in robust_df.columns]\n",
    "        baseline_df.columns = [\"$\\epsilon$={:.2f}\".format(eval(col.split(\"=\")[1])) for col in baseline_df.columns]\n",
    "\n",
    "        # print(base_models)\n",
    "        base1 = axes[i][j+1].plot(t,base_models.iloc[:,0],linewidth=3,c=\"b\")\n",
    "        base2 = axes[i][j+1].plot(t,base_models.iloc[:,1],linewidth=3,c=\"r\")\n",
    "        base3 = axes[i][j+1].plot(t,base_models.iloc[:,2],linewidth=3,c=\"k\")\n",
    "\n",
    "  \n",
    "        robust1 = axes[i][j+1].plot(t,robust_df,'--',linewidth=3)\n",
    "  \n",
    "        if j == 0:\n",
    "            base1 = axes[i][j].plot(t,base_models.iloc[:,0],linewidth=3,c=\"b\")\n",
    "            base2 = axes[i][j].plot(t,base_models.iloc[:,1],linewidth=3,c=\"r\")\n",
    "            base3 = axes[i][j].plot(t,base_models.iloc[:,2],linewidth=3,c=\"k\")\n",
    "            baseline1 = axes[i][j].plot(t,baseline_df,'--',linewidth=3)\n",
    "\n",
    "            axes[i][j].set_ylabel(f\"{dataset}\\n S(t)\" ,fontsize=SMALL_SIZE//1.5)\n",
    "            axes[i][j].set_xlabel(\"t\",fontsize=SMALL_SIZE//1.5)\n",
    "\n",
    "        axes[i][j+1].set_xlabel(\"t\",fontsize=SMALL_SIZE//1.5)\n",
    "\n",
    "for ax, col in zip(axes[0], algorithms):\n",
    "    ax.set_title(col,fontsize=SMALL_SIZE//1.5)\n",
    "\n",
    "\n",
    "labels = base_models.columns.tolist() + robust_df.columns.tolist()\n",
    "fig.legend([base1, base2,base3,robust1], labels=labels, \n",
    "           loc=\"upper center\",ncols=5,fontsize=30,bbox_to_anchor=(.5,1.06),prop={'size':SMALL_SIZE//1.7}) \n",
    "\n",
    "# axes[0][3].legend(base_models.columns.tolist() + robust_df.columns.tolist(),fontsize=20,ncol=2,loc=1)\n",
    "\n",
    "# plt.legend(base_models.columns.tolist() + robust_df.columns.tolist(),loc='upper center',ncol=5)\n",
    "plt.tight_layout(pad=0)\n",
    "plt.savefig(save_folder,dpi=1600,bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78be9b9e-c377-4137-8bc0-b4e661a58de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "files[[-7,-2,-1],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e53bd72-e7cb-4122-b41f-757cb4c3d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = results_folder = os.path.join(r\"C:\\Users\\lpott\\OneDrive\\Documents\\Northeastern University\\Classes\\EECE 7398 Verifiable Machine Learning\\EECE7398_Final_Project\\results\",attack,\"perturb_curves_subset.pdf\")\n",
    "file_subset = files[[-7,-2,-1],:]\n",
    "\n",
    "fig,axes = plt.subplots(3,n_cols+1,figsize=(30,20),sharey=True)\n",
    "\n",
    "\n",
    "SMALL_SIZE = 80\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE//2)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE//2)  \n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=SMALL_SIZE)     # fontsize of the x and y labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=SMALL_SIZE)   # fontsize of the figure title\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(n_cols):\n",
    "        print(i,j)\n",
    "        fileij = file_subset[i][j]\n",
    "        algo,dataset = fileij.split(\"\\\\\")[-3:-1]\n",
    "        if dataset not in [\"TRACE\",\"stagec\",\"zinc\"]:\n",
    "            continue\n",
    "        algo = re.sub(\"results_\",\"\",algo)\n",
    "\n",
    "        df_population = pd.read_excel(fileij)\n",
    "\n",
    "        t = df_population.pop(\"t\")\n",
    "        base_models = df_population.iloc[:,:3]\n",
    "        base_models.columns = [col.split(\"_\")[0] for col in base_models.columns]\n",
    "        \n",
    "        df_population= df_population.iloc[:,3:]\n",
    "\n",
    "        robust_idx = [\"robust\" in col for col in df_population.columns]\n",
    "        baseline_idx = [\"baseline\" in col for col in df_population.columns]\n",
    "        robust_df = df_population.iloc[:,robust_idx]\n",
    "        baseline_df = df_population.iloc[:,baseline_idx]\n",
    "        \n",
    "        robust_df.columns = [\"$\\epsilon$={:.2f}\".format(eval(col.split(\"=\")[1])) for col in robust_df.columns]\n",
    "        baseline_df.columns = [\"$\\epsilon$={:.2f}\".format(eval(col.split(\"=\")[1])) for col in baseline_df.columns]\n",
    "        \n",
    "        base1 = axes[i][j+1].plot(t,base_models.iloc[:,0],linewidth=3,c=\"b\")\n",
    "        base2 = axes[i][j+1].plot(t,base_models.iloc[:,1],linewidth=3,c=\"r\")\n",
    "        base3 = axes[i][j+1].plot(t,base_models.iloc[:,2],linewidth=3,c=\"k\")\n",
    "\n",
    "  \n",
    "        robust1 = axes[i][j+1].plot(t,robust_df,'--',linewidth=3)\n",
    "  \n",
    "        if j == 0:\n",
    "            base1 = axes[i][j].plot(t,base_models.iloc[:,0],linewidth=3,c=\"b\")\n",
    "            base2 = axes[i][j].plot(t,base_models.iloc[:,1],linewidth=3,c=\"r\")\n",
    "            base3 = axes[i][j].plot(t,base_models.iloc[:,2],linewidth=3,c=\"k\")\n",
    "            baseline1 = axes[i][j].plot(t,baseline_df,'--',linewidth=3)\n",
    "\n",
    "            axes[i][j].set_ylabel(f\"S(t) {dataset}\" ,fontsize=SMALL_SIZE//1.5)\n",
    "            axes[i][j].set_xlabel(\"t\",fontsize=SMALL_SIZE//1.5)\n",
    "\n",
    "        axes[i][j+1].set_xlabel(\"t\",fontsize=SMALL_SIZE//1.5)\n",
    "\n",
    "for ax, col in zip(axes[0], algorithms):\n",
    "    ax.set_title(col,fontsize=SMALL_SIZE//1.5)\n",
    "\n",
    "\n",
    "labels = base_models.columns.tolist() + robust_df.columns.tolist()\n",
    "fig.legend([base1, base2,base3,robust1], labels=labels, \n",
    "           loc=\"upper center\",ncols=6,fontsize=30,bbox_to_anchor=(.5,1.11),prop={'size':SMALL_SIZE}) \n",
    "\n",
    "# axes[0][3].legend(base_models.columns.tolist() + robust_df.columns.tolist(),fontsize=20,ncol=2,loc=1)\n",
    "\n",
    "# plt.legend(base_models.columns.tolist() + robust_df.columns.tolist(),loc='upper center',ncol=5)\n",
    "plt.tight_layout(pad=0)\n",
    "plt.savefig(save_folder,dpi=1600,bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8920be2-d97b-46f2-9c8f-5e954b8f9850",
   "metadata": {},
   "source": [
    "### DIST PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11d0ea1-db71-4f38-8f33-583edbe94eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CI , IBS , NegLL\n",
    "results_folder = fr\"results\\{attack}\"\n",
    "img_name = \"curve_distributions_test\"\n",
    "\n",
    " # aggregate all the CI files\n",
    "os.listdir(results_folder)\n",
    "excels = []\n",
    "for folder in os.listdir(results_folder):\n",
    "    glob_search = os.path.join(results_folder,folder,\"*\",f\"{img_name}.xlsx\")\n",
    "    excels.extend(glob.glob(glob_search))\n",
    "\n",
    "for dataset in exclude_datasets:\n",
    "    for exceli in excels:\n",
    "        if dataset in exceli:\n",
    "            print(\"remove \",dataset)\n",
    "            excels.remove(exceli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b5d622-521a-4f21-9cfe-c1f795ec7027",
   "metadata": {},
   "outputs": [],
   "source": [
    "excels = np.sort(excels)\n",
    "files = pd.DataFrame(excels.reshape(-1,len(algorithms)-1,order=\"F\"),columns=[\"crownibp\",\"fgsm\",\"noise\",\"pgd\"]).reindex([\"noise\",\"fgsm\",\"pgd\",\"crownibp\"],axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8c3dde-a972-4de7-b060-3bb189abd278",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = results_folder = os.path.join(r\"results\",attack,\"dist_curves.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e32a9f-39c6-48ab-8dc3-5a1e7fd4efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca484e11-5e3b-46a9-91e9-473f93095284",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(n_rows,n_cols+1,figsize=(30,64),sharey=True)\n",
    "\n",
    "SMALL_SIZE = 80\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE//2)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE//2)  \n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=SMALL_SIZE)     # fontsize of the x and y labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=SMALL_SIZE)   # fontsize of the figure title\n",
    "\n",
    "\n",
    "for i in range(n_rows):\n",
    "    for j in range(n_cols):\n",
    "        print(i,j)\n",
    "        fileij = files[i][j]\n",
    "        algo,dataset = fileij.split(\"\\\\\")[-3:-1]\n",
    "        algo = re.sub(\"results_\",\"\",algo)\n",
    "\n",
    "        df_population = pd.read_excel(fileij)\n",
    "\n",
    "        t = df_population.pop(\"t\")\n",
    "        base_models = df_population.iloc[:,:3]\n",
    "        base_models.columns = [col.split(\"_\")[0] for col in base_models.columns]\n",
    "        \n",
    "        robust_idx = [\"robust\" in col for col in df_population.columns]\n",
    "        baseline_idx = [\"baseline\" in col for col in df_population.columns]\n",
    "        robust_df = df_population.iloc[:,robust_idx]\n",
    "        baseline_df = df_population.iloc[:,baseline_idx]\n",
    "        \n",
    "        robust_df.columns = [col.split(\"_\")[1] for col in robust_df.columns]\n",
    "        baseline_df.columns =[col.split(\"_\")[1] for col in baseline_df.columns]\n",
    "        \n",
    "        mu = sns.lineplot(x=t, y=robust_df.iloc[:,0], label='Average S(t)', linewidth=3.0, ax=axes[i][j+1],c='b',legend=False)\n",
    "        q95 = sns.lineplot(x=t, y=robust_df.iloc[:,1], label='Confidence', linewidth=3.0, ax=axes[i][j+1],c='r',legend=False)\n",
    "        q05 = sns.lineplot(x=t, y=robust_df.iloc[:,2], label='Confidence', linewidth=3.0, ax=axes[i][j+1],c='r',legend=False)\n",
    "\n",
    "        line = q05.get_lines()\n",
    "        axes[i][j+1].fill_between(line[0].get_xdata(), line[1].get_ydata(), line[2].get_ydata(), color='blue', alpha=.3)\n",
    "        axes[i][j+1].set_xlabel(\"t\",fontsize=SMALL_SIZE//1.5)\n",
    "\n",
    "        if j == 0:\n",
    "            mu = sns.lineplot(x=t, y=baseline_df.iloc[:,0], label='Average S(t)', linewidth=3.0, ax=axes[i][j],c='b',legend=False)\n",
    "            q95 = sns.lineplot(x=t, y=baseline_df.iloc[:,1], label='Confidence', linewidth=3.0, ax=axes[i][j],c='r',legend=False)\n",
    "            q05 = sns.lineplot(x=t, y=baseline_df.iloc[:,2], label='Confidence', linewidth=3.0, ax=axes[i][j],c='r',legend=False)\n",
    "\n",
    "            axes[i][j].set_ylabel(f\"{dataset}\\n S(t)\" ,fontsize=SMALL_SIZE//1.5)\n",
    "            axes[i][j].set_xlabel(\"t\",fontsize=SMALL_SIZE//1.5)\n",
    "            line = q05.get_lines()\n",
    "            axes[i][j].fill_between(line[0].get_xdata(), line[1].get_ydata(), line[2].get_ydata(), color='blue', alpha=.3)\n",
    "            axes[i][j].set_xlabel(\"t\",fontsize=SMALL_SIZE//1.5)\n",
    "\n",
    "for ax, col in zip(axes[0], algorithms):\n",
    "    ax.set_title(col,fontsize=SMALL_SIZE//1.5)\n",
    "\n",
    "labels = [\"S(t)\",\"Credible Interval\",\"$Q_{95},Q_{05}$\"]\n",
    "fig.legend([mu,q95,q05], labels=labels, \n",
    "           loc=\"upper center\",ncols=4,fontsize=30,bbox_to_anchor=(.5,1.05),prop={'size':SMALL_SIZE}) \n",
    "\n",
    "plt.tight_layout(pad=0)\n",
    "plt.savefig(save_folder,dpi=1600,bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5a8c8a-cf4a-45b5-9aa3-4ccd0d26524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = results_folder = os.path.join(r\"results\",attack,\"dist_curves_subset.pdf\")\n",
    "file_subset = files[[-7,-2,-1],:]\n",
    "\n",
    "fig,axes = plt.subplots(3,n_cols+1,figsize=(30,20),sharey=True)\n",
    "\n",
    "SMALL_SIZE = 20\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)  \n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(n_cols):\n",
    "        print(i,j)\n",
    "        fileij = file_subset[i][j]\n",
    "        algo,dataset = fileij.split(\"\\\\\")[-3:-1]\n",
    "        algo = re.sub(\"results_\",\"\",algo)\n",
    "\n",
    "        df_population = pd.read_excel(fileij)\n",
    "\n",
    "        t = df_population.pop(\"t\")\n",
    "        base_models = df_population.iloc[:,:3]\n",
    "        base_models.columns = [col.split(\"_\")[0] for col in base_models.columns]\n",
    "        \n",
    "        robust_idx = [\"robust\" in col for col in df_population.columns]\n",
    "        baseline_idx = [\"baseline\" in col for col in df_population.columns]\n",
    "        robust_df = df_population.iloc[:,robust_idx]\n",
    "        baseline_df = df_population.iloc[:,baseline_idx]\n",
    "        \n",
    "        robust_df.columns = [col.split(\"_\")[1] for col in robust_df.columns]\n",
    "        baseline_df.columns =[col.split(\"_\")[1] for col in baseline_df.columns]\n",
    "        \n",
    "        mu = sns.lineplot(x=t, y=robust_df.iloc[:,0], label='Average S(t)', linewidth=3.0, ax=axes[i][j+1],c='b',legend=False)\n",
    "        q95 = sns.lineplot(x=t, y=robust_df.iloc[:,1], label='Confidence', linewidth=3.0, ax=axes[i][j+1],c='r',legend=False)\n",
    "        q05 = sns.lineplot(x=t, y=robust_df.iloc[:,2], label='Confidence', linewidth=3.0, ax=axes[i][j+1],c='r',legend=False)\n",
    "        axes[i][j+1].set_xlabel(\"t\",fontsize=20)\n",
    "\n",
    "        line = q05.get_lines()\n",
    "        axes[i][j+1].fill_between(line[0].get_xdata(), line[1].get_ydata(), line[2].get_ydata(), color='blue', alpha=.3)\n",
    "        if j == 0:\n",
    "            mu = sns.lineplot(x=t, y=baseline_df.iloc[:,0], label='Average S(t)', linewidth=3.0, ax=axes[i][j],c='b',legend=False)\n",
    "            q95 = sns.lineplot(x=t, y=baseline_df.iloc[:,1], label='Confidence', linewidth=3.0, ax=axes[i][j],c='r',legend=False)\n",
    "            q05 = sns.lineplot(x=t, y=baseline_df.iloc[:,2], label='Confidence', linewidth=3.0, ax=axes[i][j],c='r',legend=False)\n",
    "\n",
    "            axes[i][j].set_ylabel(f\"S(t) {dataset}\" ,fontsize=30)\n",
    "            axes[i][j].set_xlabel(\"t\",fontsize=20)\n",
    "            line = q05.get_lines()\n",
    "            axes[i][j].fill_between(line[0].get_xdata(), line[1].get_ydata(), line[2].get_ydata(), color='blue', alpha=.3)\n",
    "            axes[i][j].set_xlabel(\"t\",fontsize=20)\n",
    "\n",
    "for ax, col in zip(axes[0], algorithms):\n",
    "    ax.set_title(col,fontsize=30)\n",
    "\n",
    "\n",
    "labels = [\"S(t)\",\"Credible Interval\",\"$Q_{95},Q_{05}$\"]\n",
    "fig.legend([mu,q95,q05], labels=labels, \n",
    "           loc=\"upper center\",ncols=4,fontsize=30,bbox_to_anchor=(.5,1.05)) \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_folder,dpi=1600,bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362f5e5b-c45f-40fb-a888-6560f28a82c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "survival",
   "language": "python",
   "name": "survival"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
